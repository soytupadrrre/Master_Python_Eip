{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning I\n",
    "Actividad Lección 13 || Programación Python para Machine Learning\n",
    "\n",
    "Objetivos:\n",
    "* Saber qué es el Deep Learning y en qué situaciones puede ser útil.\n",
    "* Identificar los requisitos software y hardware para desarrollar proyectos de Deep Learning.\n",
    "* Conocer los distintos modelos de Deep Learning existentes.\n",
    "* Dominar las técnicas de implementación de modelos de Deep Learning en Python.\n",
    "\n",
    "Datos del alumno:\n",
    "* Víctor Luque Martín\n",
    "* Máster Avanzado en Programación en Python para Hacking, BigData y Machine Learning\n",
    "\n",
    "Fecha: 17/01/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de Contenidos\n",
    "1. [Importes](#importes)\n",
    "2. [Instalaciones](#instalaciones)\n",
    "3. [Carga de datos](#carga-de-datos)\n",
    "4. [Red Neuronal Profunda](#dnn)\n",
    "5. [Conclusión](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importes <a class=\"anchor\" id=\"importes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random, time\n",
    "from matplotlib import ticker\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalaciones <a class=\"anchor\" id=\"instalaciones\"></a>\n",
    "Actualmente, desde la versión 2.0.0 de TensorFlow incluye Keras como API de alto nivel para la construcción de modelos de Deep Learning. Por tanto, no es necesario instalar Keras por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión Tensorflow: 2.11.0\n",
      "Versión Keras: 2.11.0\n",
      "Num GPUs Disponibles:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras #from tensorflow import keras\n",
    "\n",
    "print(f\"Versión Tensorflow: {tf.__version__}\")\n",
    "print(f\"Versión Keras: {keras.__version__}\")\n",
    "print(\"Num GPUs Disponibles: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al no disponer de GPUs, no es posible utilizar Tensorflow con GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos <a class=\"anchor\" id=\"carga-de-datos\"></a>\n",
    "Se cargarán los datos del dataset MNIST ([“Optical Recognition of Handwritten Digits\"](https://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits)) para trabajar con un modelo de Red Neuronal Profunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [f\"pixel{i}\" for i in range(1, 65)] + [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv(\"optdigits.tra\", header=None, names=col_names)\n",
    "mnist_test = pd.read_csv(\"optdigits.tes\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel56</th>\n",
       "      <th>pixel57</th>\n",
       "      <th>pixel58</th>\n",
       "      <th>pixel59</th>\n",
       "      <th>pixel60</th>\n",
       "      <th>pixel61</th>\n",
       "      <th>pixel62</th>\n",
       "      <th>pixel63</th>\n",
       "      <th>pixel64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       1       6      15      12       1       0       0       0   \n",
       "1       0       0      10      16       6       0       0       0       0   \n",
       "2       0       0       8      15      16      13       0       0       0   \n",
       "3       0       0       0       3      11      16       0       0       0   \n",
       "4       0       0       5      14       4       0       0       0       0   \n",
       "\n",
       "   pixel10  ...  pixel56  pixel57  pixel58  pixel59  pixel60  pixel61  \\\n",
       "0        7  ...        0        0        0        6       14        7   \n",
       "1        7  ...        0        0        0       10       16       15   \n",
       "2        1  ...        0        0        0        9       14        0   \n",
       "3        0  ...        0        0        0        0        1       15   \n",
       "4        0  ...        0        0        0        4       12       14   \n",
       "\n",
       "   pixel62  pixel63  pixel64  class  \n",
       "0        1        0        0      0  \n",
       "1        3        0        0      0  \n",
       "2        0        0        0      7  \n",
       "3        2        0        0      4  \n",
       "4        7        0        0      6  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel56</th>\n",
       "      <th>pixel57</th>\n",
       "      <th>pixel58</th>\n",
       "      <th>pixel59</th>\n",
       "      <th>pixel60</th>\n",
       "      <th>pixel61</th>\n",
       "      <th>pixel62</th>\n",
       "      <th>pixel63</th>\n",
       "      <th>pixel64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       0       5      13       9       1       0       0       0   \n",
       "1       0       0       0      12      13       5       0       0       0   \n",
       "2       0       0       0       4      15      12       0       0       0   \n",
       "3       0       0       7      15      13       1       0       0       0   \n",
       "4       0       0       0       1      11       0       0       0       0   \n",
       "\n",
       "   pixel10  ...  pixel56  pixel57  pixel58  pixel59  pixel60  pixel61  \\\n",
       "0        0  ...        0        0        0        6       13       10   \n",
       "1        0  ...        0        0        0        0       11       16   \n",
       "2        0  ...        0        0        0        0        3       11   \n",
       "3        8  ...        0        0        0        7       13       13   \n",
       "4        0  ...        0        0        0        0        2       16   \n",
       "\n",
       "   pixel62  pixel63  pixel64  class  \n",
       "0        0        0        0      0  \n",
       "1       10        0        0      1  \n",
       "2       16        9        0      2  \n",
       "3        9        0        0      3  \n",
       "4        4        0        0      4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la division de los dataset en variables independientes (X) y dependientes (y) y realizamos un escalado de datos sobre las X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División X_train, y_train, X_test, y_test\n",
    "X_train = mnist_train.drop(columns=['class'])\n",
    "X_test = mnist_test.drop(columns=['class'])\n",
    "y_train = mnist_train[\"class\"]\n",
    "y_test = mnist_test[\"class\"]\n",
    "\n",
    "# Normalización\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Profunda <a class=\"anchor\" id=\"dnn\"></a>\n",
    "Una red neuronal profunda son modelos que cuentan con múltiples capas ocultas ($\\text{capas ocultas} \\geq 2$) entre las capas de entrada y la de salida, que permiten resolver problemas que el Machine Learning Clásico no es capaz de alcanzar.\n",
    "\n",
    "A continuación, se implementará una red neuronal profunda con Keras y TensorFlow para resolver el problema de clasificación multiclase del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,538\n",
      "Trainable params: 22,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "seed = random.seed(time.time())\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    layers.Dropout(.3, seed=seed),\n",
    "    layers.Dense(32, activation='swish'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(64, activation='swish'),\n",
    "    layers.Dropout(.2, seed=seed),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(.2, seed=seed),\n",
    "    layers.Dense(64, activation='swish'),\n",
    "    layers.Dropout(.1, seed=seed),\n",
    "    layers.Dense(16, activation='swish'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "loss = SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida la neurona, se debe realizar un entrenamiento de la misma, donde se irá perfeccionando el modelo mediante un número de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "96/96 [==============================] - 1s 4ms/step - loss: 7.6325 - accuracy: 0.1177 - val_loss: 5.5620 - val_accuracy: 0.1908\n",
      "Epoch 2/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.8615 - accuracy: 0.1426 - val_loss: 3.9290 - val_accuracy: 0.2235\n",
      "Epoch 3/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.0262 - accuracy: 0.1629 - val_loss: 3.0786 - val_accuracy: 0.2261\n",
      "Epoch 4/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.5699 - accuracy: 0.1661 - val_loss: 2.6817 - val_accuracy: 0.2458\n",
      "Epoch 5/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.9974 - accuracy: 0.1815 - val_loss: 2.5590 - val_accuracy: 0.2418\n",
      "Epoch 6/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.8118 - accuracy: 0.1857 - val_loss: 2.3756 - val_accuracy: 0.2706\n",
      "Epoch 7/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.3981 - accuracy: 0.1939 - val_loss: 2.2789 - val_accuracy: 0.2928\n",
      "Epoch 8/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.2962 - accuracy: 0.1884 - val_loss: 2.2448 - val_accuracy: 0.3046\n",
      "Epoch 9/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.1276 - accuracy: 0.1956 - val_loss: 2.1962 - val_accuracy: 0.3046\n",
      "Epoch 10/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.0578 - accuracy: 0.1900 - val_loss: 2.1709 - val_accuracy: 0.3268\n",
      "Epoch 11/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.8856 - accuracy: 0.2086 - val_loss: 2.1487 - val_accuracy: 0.3451\n",
      "Epoch 12/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.8193 - accuracy: 0.2155 - val_loss: 2.1425 - val_accuracy: 0.3542\n",
      "Epoch 13/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.7577 - accuracy: 0.2077 - val_loss: 2.1433 - val_accuracy: 0.3595\n",
      "Epoch 14/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.6591 - accuracy: 0.2155 - val_loss: 2.1327 - val_accuracy: 0.3399\n",
      "Epoch 15/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.6232 - accuracy: 0.2237 - val_loss: 2.1139 - val_accuracy: 0.3647\n",
      "Epoch 16/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.4837 - accuracy: 0.2240 - val_loss: 2.0824 - val_accuracy: 0.3843\n",
      "Epoch 17/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.4767 - accuracy: 0.2417 - val_loss: 2.0895 - val_accuracy: 0.3869\n",
      "Epoch 18/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.4778 - accuracy: 0.2305 - val_loss: 2.0405 - val_accuracy: 0.3961\n",
      "Epoch 19/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.4216 - accuracy: 0.2381 - val_loss: 1.9632 - val_accuracy: 0.4052\n",
      "Epoch 20/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.3925 - accuracy: 0.2394 - val_loss: 1.9515 - val_accuracy: 0.4144\n",
      "Epoch 21/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.3581 - accuracy: 0.2420 - val_loss: 1.9398 - val_accuracy: 0.4196\n",
      "Epoch 22/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.3128 - accuracy: 0.2351 - val_loss: 1.9284 - val_accuracy: 0.4209\n",
      "Epoch 23/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.2531 - accuracy: 0.2430 - val_loss: 1.9188 - val_accuracy: 0.4301\n",
      "Epoch 24/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.2790 - accuracy: 0.2613 - val_loss: 1.9229 - val_accuracy: 0.4431\n",
      "Epoch 25/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.3296 - accuracy: 0.2737 - val_loss: 1.9196 - val_accuracy: 0.4484\n",
      "Epoch 26/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.2211 - accuracy: 0.2763 - val_loss: 1.9029 - val_accuracy: 0.4575\n",
      "Epoch 27/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.2403 - accuracy: 0.2662 - val_loss: 1.8865 - val_accuracy: 0.4641\n",
      "Epoch 28/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1857 - accuracy: 0.2606 - val_loss: 1.8926 - val_accuracy: 0.4614\n",
      "Epoch 29/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.2057 - accuracy: 0.2812 - val_loss: 1.8734 - val_accuracy: 0.4706\n",
      "Epoch 30/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1529 - accuracy: 0.2930 - val_loss: 1.8623 - val_accuracy: 0.4797\n",
      "Epoch 31/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1128 - accuracy: 0.2888 - val_loss: 1.8622 - val_accuracy: 0.4876\n",
      "Epoch 32/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1445 - accuracy: 0.2914 - val_loss: 1.8563 - val_accuracy: 0.4758\n",
      "Epoch 33/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1401 - accuracy: 0.2986 - val_loss: 1.8170 - val_accuracy: 0.4837\n",
      "Epoch 34/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1168 - accuracy: 0.2901 - val_loss: 1.8043 - val_accuracy: 0.4850\n",
      "Epoch 35/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0679 - accuracy: 0.2966 - val_loss: 1.8040 - val_accuracy: 0.4980\n",
      "Epoch 36/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1005 - accuracy: 0.2888 - val_loss: 1.8352 - val_accuracy: 0.4928\n",
      "Epoch 37/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0998 - accuracy: 0.2999 - val_loss: 1.8163 - val_accuracy: 0.5007\n",
      "Epoch 38/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0832 - accuracy: 0.2995 - val_loss: 1.8044 - val_accuracy: 0.5137\n",
      "Epoch 39/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0578 - accuracy: 0.3025 - val_loss: 1.7919 - val_accuracy: 0.5176\n",
      "Epoch 40/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0420 - accuracy: 0.3208 - val_loss: 1.7759 - val_accuracy: 0.5255\n",
      "Epoch 41/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0529 - accuracy: 0.3215 - val_loss: 1.7716 - val_accuracy: 0.5242\n",
      "Epoch 42/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0127 - accuracy: 0.3355 - val_loss: 1.7486 - val_accuracy: 0.5386\n",
      "Epoch 43/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0072 - accuracy: 0.3417 - val_loss: 1.7451 - val_accuracy: 0.5464\n",
      "Epoch 44/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0025 - accuracy: 0.3319 - val_loss: 1.7315 - val_accuracy: 0.5490\n",
      "Epoch 45/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9659 - accuracy: 0.3473 - val_loss: 1.7287 - val_accuracy: 0.5516\n",
      "Epoch 46/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0008 - accuracy: 0.3613 - val_loss: 1.7220 - val_accuracy: 0.5516\n",
      "Epoch 47/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9783 - accuracy: 0.3617 - val_loss: 1.7042 - val_accuracy: 0.5608\n",
      "Epoch 48/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9684 - accuracy: 0.3617 - val_loss: 1.6977 - val_accuracy: 0.5503\n",
      "Epoch 49/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9585 - accuracy: 0.3636 - val_loss: 1.6765 - val_accuracy: 0.5529\n",
      "Epoch 50/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9481 - accuracy: 0.3597 - val_loss: 1.6525 - val_accuracy: 0.5373\n",
      "Epoch 51/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.8962 - accuracy: 0.3692 - val_loss: 1.6351 - val_accuracy: 0.5425\n",
      "Epoch 52/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9055 - accuracy: 0.3748 - val_loss: 1.6482 - val_accuracy: 0.5595\n",
      "Epoch 53/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9274 - accuracy: 0.4012 - val_loss: 1.6080 - val_accuracy: 0.5621\n",
      "Epoch 54/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.8361 - accuracy: 0.4019 - val_loss: 1.5937 - val_accuracy: 0.5804\n",
      "Epoch 55/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.8425 - accuracy: 0.4045 - val_loss: 1.5889 - val_accuracy: 0.5830\n",
      "Epoch 56/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.8615 - accuracy: 0.4055 - val_loss: 1.5636 - val_accuracy: 0.5739\n",
      "Epoch 57/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.8428 - accuracy: 0.4173 - val_loss: 1.5666 - val_accuracy: 0.5804\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 3ms/step - loss: 1.9062 - accuracy: 0.4156 - val_loss: 1.5672 - val_accuracy: 0.5843\n",
      "Epoch 59/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.8237 - accuracy: 0.4137 - val_loss: 1.5827 - val_accuracy: 0.5895\n",
      "Epoch 60/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.7951 - accuracy: 0.4251 - val_loss: 1.5843 - val_accuracy: 0.6013\n",
      "Epoch 61/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.8072 - accuracy: 0.4379 - val_loss: 1.5707 - val_accuracy: 0.5974\n",
      "Epoch 62/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7993 - accuracy: 0.4487 - val_loss: 1.5597 - val_accuracy: 0.6013\n",
      "Epoch 63/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7755 - accuracy: 0.4454 - val_loss: 1.5306 - val_accuracy: 0.6039\n",
      "Epoch 64/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 1.8332 - accuracy: 0.4493 - val_loss: 1.5037 - val_accuracy: 0.6118\n",
      "Epoch 65/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.8081 - accuracy: 0.4447 - val_loss: 1.5054 - val_accuracy: 0.6144\n",
      "Epoch 66/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7620 - accuracy: 0.4637 - val_loss: 1.5452 - val_accuracy: 0.6118\n",
      "Epoch 67/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7945 - accuracy: 0.4650 - val_loss: 1.5169 - val_accuracy: 0.6144\n",
      "Epoch 68/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7843 - accuracy: 0.4630 - val_loss: 1.5075 - val_accuracy: 0.6222\n",
      "Epoch 69/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7394 - accuracy: 0.4738 - val_loss: 1.4839 - val_accuracy: 0.6288\n",
      "Epoch 70/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7547 - accuracy: 0.4683 - val_loss: 1.4756 - val_accuracy: 0.6261\n",
      "Epoch 71/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7274 - accuracy: 0.4853 - val_loss: 1.4575 - val_accuracy: 0.6340\n",
      "Epoch 72/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7319 - accuracy: 0.4784 - val_loss: 1.4525 - val_accuracy: 0.6275\n",
      "Epoch 73/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.6974 - accuracy: 0.4863 - val_loss: 1.4522 - val_accuracy: 0.6458\n",
      "Epoch 74/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.6596 - accuracy: 0.5043 - val_loss: 1.4414 - val_accuracy: 0.6431\n",
      "Epoch 75/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7125 - accuracy: 0.5003 - val_loss: 1.4281 - val_accuracy: 0.6261\n",
      "Epoch 76/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.6734 - accuracy: 0.5121 - val_loss: 1.4251 - val_accuracy: 0.6431\n",
      "Epoch 77/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.7136 - accuracy: 0.4987 - val_loss: 1.4063 - val_accuracy: 0.6379\n",
      "Epoch 78/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.6672 - accuracy: 0.5196 - val_loss: 1.3814 - val_accuracy: 0.6444\n",
      "Epoch 79/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6467 - accuracy: 0.5203 - val_loss: 1.3722 - val_accuracy: 0.6575\n",
      "Epoch 80/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6559 - accuracy: 0.5062 - val_loss: 1.3519 - val_accuracy: 0.6562\n",
      "Epoch 81/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5388 - accuracy: 0.5088 - val_loss: 1.3356 - val_accuracy: 0.6549\n",
      "Epoch 82/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5997 - accuracy: 0.5118 - val_loss: 1.3653 - val_accuracy: 0.6288\n",
      "Epoch 83/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6862 - accuracy: 0.5082 - val_loss: 1.3480 - val_accuracy: 0.6366\n",
      "Epoch 84/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.7111 - accuracy: 0.4967 - val_loss: 1.3443 - val_accuracy: 0.6510\n",
      "Epoch 85/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6443 - accuracy: 0.5255 - val_loss: 1.3076 - val_accuracy: 0.6510\n",
      "Epoch 86/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6468 - accuracy: 0.5147 - val_loss: 1.3079 - val_accuracy: 0.6523\n",
      "Epoch 87/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6350 - accuracy: 0.5271 - val_loss: 1.2978 - val_accuracy: 0.6614\n",
      "Epoch 88/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5722 - accuracy: 0.5186 - val_loss: 1.2893 - val_accuracy: 0.6654\n",
      "Epoch 89/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5539 - accuracy: 0.5281 - val_loss: 1.2947 - val_accuracy: 0.6706\n",
      "Epoch 90/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5805 - accuracy: 0.5477 - val_loss: 1.2790 - val_accuracy: 0.6771\n",
      "Epoch 91/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6301 - accuracy: 0.5389 - val_loss: 1.3242 - val_accuracy: 0.6575\n",
      "Epoch 92/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6342 - accuracy: 0.5121 - val_loss: 1.3157 - val_accuracy: 0.6601\n",
      "Epoch 93/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5673 - accuracy: 0.5311 - val_loss: 1.3046 - val_accuracy: 0.6745\n",
      "Epoch 94/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5736 - accuracy: 0.5343 - val_loss: 1.2817 - val_accuracy: 0.6797\n",
      "Epoch 95/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5141 - accuracy: 0.5441 - val_loss: 1.2866 - val_accuracy: 0.6771\n",
      "Epoch 96/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5743 - accuracy: 0.5370 - val_loss: 1.3138 - val_accuracy: 0.6667\n",
      "Epoch 97/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6459 - accuracy: 0.5056 - val_loss: 1.3676 - val_accuracy: 0.6275\n",
      "Epoch 98/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5655 - accuracy: 0.5177 - val_loss: 1.3376 - val_accuracy: 0.6366\n",
      "Epoch 99/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6067 - accuracy: 0.5059 - val_loss: 1.3306 - val_accuracy: 0.6484\n",
      "Epoch 100/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5782 - accuracy: 0.5278 - val_loss: 1.3182 - val_accuracy: 0.6549\n",
      "Epoch 101/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6270 - accuracy: 0.5245 - val_loss: 1.3167 - val_accuracy: 0.6549\n",
      "Epoch 102/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5473 - accuracy: 0.5337 - val_loss: 1.2990 - val_accuracy: 0.6575\n",
      "Epoch 103/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5871 - accuracy: 0.5327 - val_loss: 1.3029 - val_accuracy: 0.6575\n",
      "Epoch 104/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5338 - accuracy: 0.5363 - val_loss: 1.3058 - val_accuracy: 0.6588\n",
      "Epoch 105/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5217 - accuracy: 0.5510 - val_loss: 1.2708 - val_accuracy: 0.6667\n",
      "Epoch 106/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5231 - accuracy: 0.5513 - val_loss: 1.2796 - val_accuracy: 0.6719\n",
      "Epoch 107/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5099 - accuracy: 0.5513 - val_loss: 1.2730 - val_accuracy: 0.6758\n",
      "Epoch 108/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5344 - accuracy: 0.5451 - val_loss: 1.2704 - val_accuracy: 0.6719\n",
      "Epoch 109/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5458 - accuracy: 0.5412 - val_loss: 1.2758 - val_accuracy: 0.6693\n",
      "Epoch 110/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4989 - accuracy: 0.5455 - val_loss: 1.2650 - val_accuracy: 0.6758\n",
      "Epoch 111/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4800 - accuracy: 0.5628 - val_loss: 1.2537 - val_accuracy: 0.6810\n",
      "Epoch 112/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4792 - accuracy: 0.5605 - val_loss: 1.2449 - val_accuracy: 0.6810\n",
      "Epoch 113/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4547 - accuracy: 0.5657 - val_loss: 1.2266 - val_accuracy: 0.6850\n",
      "Epoch 114/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4810 - accuracy: 0.5582 - val_loss: 1.2210 - val_accuracy: 0.6902\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4912 - accuracy: 0.5713 - val_loss: 1.2149 - val_accuracy: 0.6850\n",
      "Epoch 116/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5253 - accuracy: 0.5827 - val_loss: 1.2130 - val_accuracy: 0.7098\n",
      "Epoch 117/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4719 - accuracy: 0.5746 - val_loss: 1.2073 - val_accuracy: 0.7163\n",
      "Epoch 118/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4865 - accuracy: 0.5697 - val_loss: 1.2001 - val_accuracy: 0.7190\n",
      "Epoch 119/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4978 - accuracy: 0.5746 - val_loss: 1.2029 - val_accuracy: 0.7098\n",
      "Epoch 120/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4958 - accuracy: 0.5634 - val_loss: 1.1986 - val_accuracy: 0.7124\n",
      "Epoch 121/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4765 - accuracy: 0.5952 - val_loss: 1.2004 - val_accuracy: 0.7150\n",
      "Epoch 122/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4849 - accuracy: 0.5840 - val_loss: 1.2098 - val_accuracy: 0.7137\n",
      "Epoch 123/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4732 - accuracy: 0.5729 - val_loss: 1.1761 - val_accuracy: 0.7098\n",
      "Epoch 124/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4146 - accuracy: 0.5811 - val_loss: 1.1819 - val_accuracy: 0.7098\n",
      "Epoch 125/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4079 - accuracy: 0.5795 - val_loss: 1.1587 - val_accuracy: 0.7137\n",
      "Epoch 126/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4152 - accuracy: 0.5853 - val_loss: 1.1421 - val_accuracy: 0.7203\n",
      "Epoch 127/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4204 - accuracy: 0.5899 - val_loss: 1.1392 - val_accuracy: 0.7229\n",
      "Epoch 128/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4289 - accuracy: 0.5850 - val_loss: 1.1439 - val_accuracy: 0.7255\n",
      "Epoch 129/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4753 - accuracy: 0.5801 - val_loss: 1.1398 - val_accuracy: 0.7281\n",
      "Epoch 130/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4582 - accuracy: 0.5844 - val_loss: 1.1368 - val_accuracy: 0.7281\n",
      "Epoch 131/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4268 - accuracy: 0.5831 - val_loss: 1.1260 - val_accuracy: 0.7320\n",
      "Epoch 132/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4567 - accuracy: 0.5906 - val_loss: 1.1197 - val_accuracy: 0.7333\n",
      "Epoch 133/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4686 - accuracy: 0.5804 - val_loss: 1.1242 - val_accuracy: 0.7255\n",
      "Epoch 134/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4318 - accuracy: 0.5889 - val_loss: 1.1125 - val_accuracy: 0.7294\n",
      "Epoch 135/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4338 - accuracy: 0.5883 - val_loss: 1.0984 - val_accuracy: 0.7373\n",
      "Epoch 136/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4579 - accuracy: 0.5824 - val_loss: 1.0943 - val_accuracy: 0.7386\n",
      "Epoch 137/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4230 - accuracy: 0.5916 - val_loss: 1.0908 - val_accuracy: 0.7373\n",
      "Epoch 138/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4064 - accuracy: 0.5785 - val_loss: 1.1231 - val_accuracy: 0.7216\n",
      "Epoch 139/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4166 - accuracy: 0.5994 - val_loss: 1.1122 - val_accuracy: 0.7190\n",
      "Epoch 140/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4231 - accuracy: 0.5968 - val_loss: 1.0886 - val_accuracy: 0.7229\n",
      "Epoch 141/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4104 - accuracy: 0.5912 - val_loss: 1.0699 - val_accuracy: 0.7359\n",
      "Epoch 142/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3584 - accuracy: 0.6060 - val_loss: 1.0564 - val_accuracy: 0.7346\n",
      "Epoch 143/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3960 - accuracy: 0.6027 - val_loss: 1.0631 - val_accuracy: 0.7373\n",
      "Epoch 144/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3991 - accuracy: 0.5906 - val_loss: 1.0653 - val_accuracy: 0.7490\n",
      "Epoch 145/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3803 - accuracy: 0.6099 - val_loss: 1.0901 - val_accuracy: 0.7333\n",
      "Epoch 146/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3722 - accuracy: 0.5997 - val_loss: 1.0738 - val_accuracy: 0.7359\n",
      "Epoch 147/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3685 - accuracy: 0.6089 - val_loss: 1.0144 - val_accuracy: 0.7425\n",
      "Epoch 148/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3331 - accuracy: 0.6007 - val_loss: 1.0394 - val_accuracy: 0.7477\n",
      "Epoch 149/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.6014 - val_loss: 1.0473 - val_accuracy: 0.7595\n",
      "Epoch 150/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3773 - accuracy: 0.6148 - val_loss: 1.0414 - val_accuracy: 0.7582\n",
      "Epoch 151/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3773 - accuracy: 0.6024 - val_loss: 1.0306 - val_accuracy: 0.7621\n",
      "Epoch 152/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.4047 - accuracy: 0.6099 - val_loss: 1.0216 - val_accuracy: 0.7647\n",
      "Epoch 153/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3852 - accuracy: 0.6148 - val_loss: 1.0266 - val_accuracy: 0.7725\n",
      "Epoch 154/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.5988 - val_loss: 1.0098 - val_accuracy: 0.7673\n",
      "Epoch 155/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3729 - accuracy: 0.6069 - val_loss: 1.0095 - val_accuracy: 0.7673\n",
      "Epoch 156/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3751 - accuracy: 0.6099 - val_loss: 0.9870 - val_accuracy: 0.7712\n",
      "Epoch 157/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3533 - accuracy: 0.6089 - val_loss: 1.0019 - val_accuracy: 0.7712\n",
      "Epoch 158/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3046 - accuracy: 0.6305 - val_loss: 1.0098 - val_accuracy: 0.7725\n",
      "Epoch 159/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3138 - accuracy: 0.6194 - val_loss: 0.9888 - val_accuracy: 0.7791\n",
      "Epoch 160/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3068 - accuracy: 0.6154 - val_loss: 0.9741 - val_accuracy: 0.7673\n",
      "Epoch 161/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2892 - accuracy: 0.6230 - val_loss: 0.9718 - val_accuracy: 0.7634\n",
      "Epoch 162/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3136 - accuracy: 0.6141 - val_loss: 0.9649 - val_accuracy: 0.7673\n",
      "Epoch 163/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3879 - accuracy: 0.6210 - val_loss: 1.0138 - val_accuracy: 0.7516\n",
      "Epoch 164/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3513 - accuracy: 0.6256 - val_loss: 0.9847 - val_accuracy: 0.7765\n",
      "Epoch 165/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3219 - accuracy: 0.6400 - val_loss: 0.9766 - val_accuracy: 0.7804\n",
      "Epoch 166/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3292 - accuracy: 0.6181 - val_loss: 0.9710 - val_accuracy: 0.7778\n",
      "Epoch 167/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2949 - accuracy: 0.6436 - val_loss: 0.9433 - val_accuracy: 0.7752\n",
      "Epoch 168/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3047 - accuracy: 0.6455 - val_loss: 0.9438 - val_accuracy: 0.7882\n",
      "Epoch 169/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2901 - accuracy: 0.6239 - val_loss: 0.9638 - val_accuracy: 0.7935\n",
      "Epoch 170/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2447 - accuracy: 0.6337 - val_loss: 1.0079 - val_accuracy: 0.7778\n",
      "Epoch 171/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3291 - accuracy: 0.6308 - val_loss: 1.0504 - val_accuracy: 0.7569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3261 - accuracy: 0.6171 - val_loss: 1.0197 - val_accuracy: 0.7686\n",
      "Epoch 173/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3337 - accuracy: 0.6187 - val_loss: 1.0041 - val_accuracy: 0.7725\n",
      "Epoch 174/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3213 - accuracy: 0.6328 - val_loss: 0.9786 - val_accuracy: 0.7647\n",
      "Epoch 175/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3022 - accuracy: 0.6246 - val_loss: 0.9669 - val_accuracy: 0.7712\n",
      "Epoch 176/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3107 - accuracy: 0.6308 - val_loss: 0.9525 - val_accuracy: 0.7725\n",
      "Epoch 177/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3134 - accuracy: 0.6380 - val_loss: 0.9418 - val_accuracy: 0.7765\n",
      "Epoch 178/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3139 - accuracy: 0.6328 - val_loss: 0.9380 - val_accuracy: 0.7778\n",
      "Epoch 179/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2778 - accuracy: 0.6154 - val_loss: 0.9359 - val_accuracy: 0.7830\n",
      "Epoch 180/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2627 - accuracy: 0.6436 - val_loss: 0.9376 - val_accuracy: 0.7830\n",
      "Epoch 181/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2876 - accuracy: 0.6364 - val_loss: 0.9297 - val_accuracy: 0.7843\n",
      "Epoch 182/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2490 - accuracy: 0.6341 - val_loss: 0.9189 - val_accuracy: 0.7856\n",
      "Epoch 183/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2940 - accuracy: 0.6426 - val_loss: 0.9061 - val_accuracy: 0.7869\n",
      "Epoch 184/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3118 - accuracy: 0.6262 - val_loss: 0.9237 - val_accuracy: 0.7961\n",
      "Epoch 185/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2779 - accuracy: 0.6547 - val_loss: 0.9142 - val_accuracy: 0.7961\n",
      "Epoch 186/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2169 - accuracy: 0.6475 - val_loss: 0.9055 - val_accuracy: 0.8105\n",
      "Epoch 187/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2321 - accuracy: 0.6367 - val_loss: 0.8932 - val_accuracy: 0.8131\n",
      "Epoch 188/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2452 - accuracy: 0.6521 - val_loss: 0.8800 - val_accuracy: 0.8052\n",
      "Epoch 189/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2239 - accuracy: 0.6455 - val_loss: 0.8678 - val_accuracy: 0.8052\n",
      "Epoch 190/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1894 - accuracy: 0.6485 - val_loss: 0.8601 - val_accuracy: 0.8039\n",
      "Epoch 191/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2229 - accuracy: 0.6602 - val_loss: 0.8497 - val_accuracy: 0.8065\n",
      "Epoch 192/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2022 - accuracy: 0.6498 - val_loss: 0.8411 - val_accuracy: 0.8105\n",
      "Epoch 193/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2168 - accuracy: 0.6537 - val_loss: 0.8457 - val_accuracy: 0.8222\n",
      "Epoch 194/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2299 - accuracy: 0.6537 - val_loss: 0.8372 - val_accuracy: 0.8170\n",
      "Epoch 195/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2639 - accuracy: 0.6360 - val_loss: 0.8258 - val_accuracy: 0.8222\n",
      "Epoch 196/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2263 - accuracy: 0.6409 - val_loss: 0.8244 - val_accuracy: 0.8222\n",
      "Epoch 197/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2094 - accuracy: 0.6498 - val_loss: 0.8197 - val_accuracy: 0.8118\n",
      "Epoch 198/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2494 - accuracy: 0.6475 - val_loss: 0.8200 - val_accuracy: 0.8235\n",
      "Epoch 199/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2140 - accuracy: 0.6494 - val_loss: 0.8030 - val_accuracy: 0.8261\n",
      "Epoch 200/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2614 - accuracy: 0.6468 - val_loss: 0.7875 - val_accuracy: 0.8288\n",
      "Epoch 201/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2143 - accuracy: 0.6560 - val_loss: 0.7793 - val_accuracy: 0.8340\n",
      "Epoch 202/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1895 - accuracy: 0.6609 - val_loss: 0.7780 - val_accuracy: 0.8392\n",
      "Epoch 203/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2145 - accuracy: 0.6625 - val_loss: 0.7920 - val_accuracy: 0.8261\n",
      "Epoch 204/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2265 - accuracy: 0.6498 - val_loss: 0.7903 - val_accuracy: 0.8248\n",
      "Epoch 205/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2096 - accuracy: 0.6658 - val_loss: 0.7822 - val_accuracy: 0.8261\n",
      "Epoch 206/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1829 - accuracy: 0.6651 - val_loss: 0.7758 - val_accuracy: 0.8379\n",
      "Epoch 207/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2118 - accuracy: 0.6625 - val_loss: 0.7660 - val_accuracy: 0.8431\n",
      "Epoch 208/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1859 - accuracy: 0.6648 - val_loss: 0.7663 - val_accuracy: 0.8431\n",
      "Epoch 209/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1741 - accuracy: 0.6730 - val_loss: 0.7594 - val_accuracy: 0.8484\n",
      "Epoch 210/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1198 - accuracy: 0.6691 - val_loss: 0.7413 - val_accuracy: 0.8405\n",
      "Epoch 211/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1992 - accuracy: 0.6619 - val_loss: 0.7221 - val_accuracy: 0.8353\n",
      "Epoch 212/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1792 - accuracy: 0.6756 - val_loss: 0.7365 - val_accuracy: 0.8458\n",
      "Epoch 213/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2025 - accuracy: 0.6579 - val_loss: 0.7210 - val_accuracy: 0.8379\n",
      "Epoch 214/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1692 - accuracy: 0.6593 - val_loss: 0.7251 - val_accuracy: 0.8379\n",
      "Epoch 215/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1350 - accuracy: 0.6629 - val_loss: 0.7278 - val_accuracy: 0.8366\n",
      "Epoch 216/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1297 - accuracy: 0.6920 - val_loss: 0.6949 - val_accuracy: 0.8366\n",
      "Epoch 217/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1561 - accuracy: 0.6769 - val_loss: 0.7018 - val_accuracy: 0.8431\n",
      "Epoch 218/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2319 - accuracy: 0.6687 - val_loss: 0.7175 - val_accuracy: 0.8497\n",
      "Epoch 219/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2230 - accuracy: 0.6782 - val_loss: 0.7110 - val_accuracy: 0.8458\n",
      "Epoch 220/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1697 - accuracy: 0.6648 - val_loss: 0.7122 - val_accuracy: 0.8471\n",
      "Epoch 221/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1563 - accuracy: 0.6812 - val_loss: 0.7000 - val_accuracy: 0.8484\n",
      "Epoch 222/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1804 - accuracy: 0.6795 - val_loss: 0.6903 - val_accuracy: 0.8523\n",
      "Epoch 223/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1549 - accuracy: 0.6965 - val_loss: 0.7024 - val_accuracy: 0.8601\n",
      "Epoch 224/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1489 - accuracy: 0.6848 - val_loss: 0.6790 - val_accuracy: 0.8536\n",
      "Epoch 225/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1143 - accuracy: 0.6903 - val_loss: 0.6770 - val_accuracy: 0.8549\n",
      "Epoch 226/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2081 - accuracy: 0.6851 - val_loss: 0.6749 - val_accuracy: 0.8732\n",
      "Epoch 227/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1616 - accuracy: 0.6812 - val_loss: 0.6733 - val_accuracy: 0.8758\n",
      "Epoch 228/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.2062 - accuracy: 0.6848 - val_loss: 0.6652 - val_accuracy: 0.8719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1251 - accuracy: 0.6998 - val_loss: 0.6578 - val_accuracy: 0.8719\n",
      "Epoch 230/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1463 - accuracy: 0.6923 - val_loss: 0.6748 - val_accuracy: 0.8523\n",
      "Epoch 231/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1185 - accuracy: 0.6969 - val_loss: 0.7001 - val_accuracy: 0.8510\n",
      "Epoch 232/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.6893 - val_loss: 0.6958 - val_accuracy: 0.8706\n",
      "Epoch 233/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.6910 - val_loss: 0.6790 - val_accuracy: 0.8706\n",
      "Epoch 234/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1225 - accuracy: 0.6942 - val_loss: 0.6597 - val_accuracy: 0.8654\n",
      "Epoch 235/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1589 - accuracy: 0.6933 - val_loss: 0.6600 - val_accuracy: 0.8523\n",
      "Epoch 236/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1449 - accuracy: 0.6923 - val_loss: 0.6713 - val_accuracy: 0.8601\n",
      "Epoch 237/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1606 - accuracy: 0.6772 - val_loss: 0.7539 - val_accuracy: 0.8144\n",
      "Epoch 238/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1459 - accuracy: 0.6828 - val_loss: 0.6975 - val_accuracy: 0.8353\n",
      "Epoch 239/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1411 - accuracy: 0.6942 - val_loss: 0.6870 - val_accuracy: 0.8288\n",
      "Epoch 240/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1185 - accuracy: 0.6910 - val_loss: 0.6813 - val_accuracy: 0.8340\n",
      "Epoch 241/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0784 - accuracy: 0.6939 - val_loss: 0.6877 - val_accuracy: 0.8510\n",
      "Epoch 242/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.7152 - val_loss: 0.6758 - val_accuracy: 0.8575\n",
      "Epoch 243/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1189 - accuracy: 0.6923 - val_loss: 0.6888 - val_accuracy: 0.8601\n",
      "Epoch 244/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0818 - accuracy: 0.6972 - val_loss: 0.6794 - val_accuracy: 0.8601\n",
      "Epoch 245/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.7096 - val_loss: 0.6587 - val_accuracy: 0.8549\n",
      "Epoch 246/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0670 - accuracy: 0.7096 - val_loss: 0.6501 - val_accuracy: 0.8510\n",
      "Epoch 247/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0455 - accuracy: 0.7037 - val_loss: 0.6458 - val_accuracy: 0.8641\n",
      "Epoch 248/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0690 - accuracy: 0.6972 - val_loss: 0.6350 - val_accuracy: 0.8575\n",
      "Epoch 249/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0309 - accuracy: 0.7060 - val_loss: 0.6287 - val_accuracy: 0.8575\n",
      "Epoch 250/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0950 - accuracy: 0.6946 - val_loss: 0.6142 - val_accuracy: 0.8627\n",
      "Epoch 251/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1317 - accuracy: 0.7041 - val_loss: 0.6043 - val_accuracy: 0.8641\n",
      "Epoch 252/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0816 - accuracy: 0.7103 - val_loss: 0.6122 - val_accuracy: 0.8627\n",
      "Epoch 253/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0775 - accuracy: 0.7011 - val_loss: 0.6040 - val_accuracy: 0.8680\n",
      "Epoch 254/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0339 - accuracy: 0.7024 - val_loss: 0.6087 - val_accuracy: 0.8627\n",
      "Epoch 255/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0910 - accuracy: 0.7119 - val_loss: 0.5969 - val_accuracy: 0.8758\n",
      "Epoch 256/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.7132 - val_loss: 0.5955 - val_accuracy: 0.8797\n",
      "Epoch 257/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0753 - accuracy: 0.7112 - val_loss: 0.5825 - val_accuracy: 0.8824\n",
      "Epoch 258/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0767 - accuracy: 0.7099 - val_loss: 0.6177 - val_accuracy: 0.8771\n",
      "Epoch 259/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0159 - accuracy: 0.7191 - val_loss: 0.6024 - val_accuracy: 0.8784\n",
      "Epoch 260/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0637 - accuracy: 0.7077 - val_loss: 0.5885 - val_accuracy: 0.8889\n",
      "Epoch 261/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9880 - accuracy: 0.7361 - val_loss: 0.5716 - val_accuracy: 0.8915\n",
      "Epoch 262/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0471 - accuracy: 0.7243 - val_loss: 0.5676 - val_accuracy: 0.8928\n",
      "Epoch 263/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0261 - accuracy: 0.7181 - val_loss: 0.5688 - val_accuracy: 0.8889\n",
      "Epoch 264/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0129 - accuracy: 0.7148 - val_loss: 0.5830 - val_accuracy: 0.8889\n",
      "Epoch 265/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0465 - accuracy: 0.7237 - val_loss: 0.6043 - val_accuracy: 0.8484\n",
      "Epoch 266/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1006 - accuracy: 0.7001 - val_loss: 0.5956 - val_accuracy: 0.8667\n",
      "Epoch 267/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0972 - accuracy: 0.7148 - val_loss: 0.5823 - val_accuracy: 0.8667\n",
      "Epoch 268/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.7217 - val_loss: 0.5720 - val_accuracy: 0.8784\n",
      "Epoch 269/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0313 - accuracy: 0.7273 - val_loss: 0.5940 - val_accuracy: 0.8980\n",
      "Epoch 270/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0512 - accuracy: 0.7171 - val_loss: 0.6009 - val_accuracy: 0.9007\n",
      "Epoch 271/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0490 - accuracy: 0.7227 - val_loss: 0.6067 - val_accuracy: 0.9033\n",
      "Epoch 272/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0449 - accuracy: 0.7240 - val_loss: 0.5953 - val_accuracy: 0.9059\n",
      "Epoch 273/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9845 - accuracy: 0.7237 - val_loss: 0.5889 - val_accuracy: 0.9046\n",
      "Epoch 274/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.7390 - val_loss: 0.5680 - val_accuracy: 0.9176\n",
      "Epoch 275/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0361 - accuracy: 0.7237 - val_loss: 0.5636 - val_accuracy: 0.9216\n",
      "Epoch 276/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0190 - accuracy: 0.7374 - val_loss: 0.5641 - val_accuracy: 0.9163\n",
      "Epoch 277/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9431 - accuracy: 0.7345 - val_loss: 0.5523 - val_accuracy: 0.9190\n",
      "Epoch 278/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9976 - accuracy: 0.7377 - val_loss: 0.5738 - val_accuracy: 0.9059\n",
      "Epoch 279/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.7511 - val_loss: 0.5575 - val_accuracy: 0.9137\n",
      "Epoch 280/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9902 - accuracy: 0.7341 - val_loss: 0.5413 - val_accuracy: 0.9124\n",
      "Epoch 281/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.7459 - val_loss: 0.5459 - val_accuracy: 0.9111\n",
      "Epoch 282/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.7384 - val_loss: 0.5590 - val_accuracy: 0.8993\n",
      "Epoch 283/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.7305 - val_loss: 0.5514 - val_accuracy: 0.8980\n",
      "Epoch 284/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0298 - accuracy: 0.7312 - val_loss: 0.5507 - val_accuracy: 0.8928\n",
      "Epoch 285/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9799 - accuracy: 0.7417 - val_loss: 0.5571 - val_accuracy: 0.8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.7410 - val_loss: 0.5765 - val_accuracy: 0.8876\n",
      "Epoch 287/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9511 - accuracy: 0.7322 - val_loss: 0.5640 - val_accuracy: 0.9033\n",
      "Epoch 288/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9105 - accuracy: 0.7538 - val_loss: 0.5534 - val_accuracy: 0.9124\n",
      "Epoch 289/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9450 - accuracy: 0.7505 - val_loss: 0.5395 - val_accuracy: 0.9124\n",
      "Epoch 290/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9995 - accuracy: 0.7269 - val_loss: 0.5391 - val_accuracy: 0.9176\n",
      "Epoch 291/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.7456 - val_loss: 0.5358 - val_accuracy: 0.9203\n",
      "Epoch 292/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0152 - accuracy: 0.7400 - val_loss: 0.5391 - val_accuracy: 0.9203\n",
      "Epoch 293/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9444 - accuracy: 0.7443 - val_loss: 0.5322 - val_accuracy: 0.9150\n",
      "Epoch 294/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8978 - accuracy: 0.7564 - val_loss: 0.5161 - val_accuracy: 0.9150\n",
      "Epoch 295/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.7479 - val_loss: 0.5176 - val_accuracy: 0.9150\n",
      "Epoch 296/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9362 - accuracy: 0.7387 - val_loss: 0.5099 - val_accuracy: 0.9176\n",
      "Epoch 297/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9975 - accuracy: 0.7557 - val_loss: 0.5314 - val_accuracy: 0.9059\n",
      "Epoch 298/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9275 - accuracy: 0.7319 - val_loss: 0.5339 - val_accuracy: 0.9111\n",
      "Epoch 299/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9840 - accuracy: 0.7368 - val_loss: 0.5283 - val_accuracy: 0.9216\n",
      "Epoch 300/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9482 - accuracy: 0.7469 - val_loss: 0.5646 - val_accuracy: 0.9098\n",
      "Epoch 301/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.7440 - val_loss: 0.5554 - val_accuracy: 0.9124\n",
      "Epoch 302/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9932 - accuracy: 0.7456 - val_loss: 0.5363 - val_accuracy: 0.9176\n",
      "Epoch 303/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.7495 - val_loss: 0.5273 - val_accuracy: 0.9229\n",
      "Epoch 304/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9137 - accuracy: 0.7498 - val_loss: 0.5318 - val_accuracy: 0.9229\n",
      "Epoch 305/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0183 - accuracy: 0.7394 - val_loss: 0.5423 - val_accuracy: 0.9176\n",
      "Epoch 306/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9694 - accuracy: 0.7534 - val_loss: 0.5406 - val_accuracy: 0.9203\n",
      "Epoch 307/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9703 - accuracy: 0.7567 - val_loss: 0.5282 - val_accuracy: 0.9203\n",
      "Epoch 308/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0086 - accuracy: 0.7531 - val_loss: 0.5272 - val_accuracy: 0.9216\n",
      "Epoch 309/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9221 - accuracy: 0.7518 - val_loss: 0.5089 - val_accuracy: 0.9216\n",
      "Epoch 310/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9325 - accuracy: 0.7551 - val_loss: 0.5139 - val_accuracy: 0.9229\n",
      "Epoch 311/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9869 - accuracy: 0.7681 - val_loss: 0.5041 - val_accuracy: 0.9216\n",
      "Epoch 312/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9332 - accuracy: 0.7623 - val_loss: 0.5154 - val_accuracy: 0.9229\n",
      "Epoch 313/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9485 - accuracy: 0.7639 - val_loss: 0.5057 - val_accuracy: 0.9242\n",
      "Epoch 314/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9681 - accuracy: 0.7538 - val_loss: 0.4980 - val_accuracy: 0.9242\n",
      "Epoch 315/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8653 - accuracy: 0.7731 - val_loss: 0.4668 - val_accuracy: 0.9203\n",
      "Epoch 316/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.7577 - val_loss: 0.4612 - val_accuracy: 0.9229\n",
      "Epoch 317/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9460 - accuracy: 0.7711 - val_loss: 0.4595 - val_accuracy: 0.9242\n",
      "Epoch 318/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9073 - accuracy: 0.7659 - val_loss: 0.4542 - val_accuracy: 0.9255\n",
      "Epoch 319/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9232 - accuracy: 0.7681 - val_loss: 0.4512 - val_accuracy: 0.9216\n",
      "Epoch 320/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.7799 - val_loss: 0.4386 - val_accuracy: 0.9281\n",
      "Epoch 321/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9215 - accuracy: 0.7616 - val_loss: 0.4335 - val_accuracy: 0.9242\n",
      "Epoch 322/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.7727 - val_loss: 0.4292 - val_accuracy: 0.9190\n",
      "Epoch 323/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9563 - accuracy: 0.7668 - val_loss: 0.4451 - val_accuracy: 0.9242\n",
      "Epoch 324/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.7649 - val_loss: 0.4965 - val_accuracy: 0.9124\n",
      "Epoch 325/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9171 - accuracy: 0.7681 - val_loss: 0.4813 - val_accuracy: 0.9176\n",
      "Epoch 326/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9130 - accuracy: 0.7714 - val_loss: 0.4814 - val_accuracy: 0.9150\n",
      "Epoch 327/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8985 - accuracy: 0.7606 - val_loss: 0.5107 - val_accuracy: 0.9150\n",
      "Epoch 328/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8748 - accuracy: 0.7564 - val_loss: 0.5031 - val_accuracy: 0.9216\n",
      "Epoch 329/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9923 - accuracy: 0.7587 - val_loss: 0.5103 - val_accuracy: 0.9190\n",
      "Epoch 330/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9523 - accuracy: 0.7639 - val_loss: 0.4993 - val_accuracy: 0.9190\n",
      "Epoch 331/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.0020 - accuracy: 0.7554 - val_loss: 0.5298 - val_accuracy: 0.9150\n",
      "Epoch 332/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8968 - accuracy: 0.7544 - val_loss: 0.5235 - val_accuracy: 0.9190\n",
      "Epoch 333/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8617 - accuracy: 0.7642 - val_loss: 0.5179 - val_accuracy: 0.9190\n",
      "Epoch 334/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8980 - accuracy: 0.7659 - val_loss: 0.5129 - val_accuracy: 0.9190\n",
      "Epoch 335/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9116 - accuracy: 0.7668 - val_loss: 0.5123 - val_accuracy: 0.9176\n",
      "Epoch 336/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8266 - accuracy: 0.7685 - val_loss: 0.5047 - val_accuracy: 0.9163\n",
      "Epoch 337/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9221 - accuracy: 0.7610 - val_loss: 0.4977 - val_accuracy: 0.9163\n",
      "Epoch 338/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9563 - accuracy: 0.7662 - val_loss: 0.4959 - val_accuracy: 0.9176\n",
      "Epoch 339/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9340 - accuracy: 0.7724 - val_loss: 0.4907 - val_accuracy: 0.9216\n",
      "Epoch 340/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8899 - accuracy: 0.7750 - val_loss: 0.5008 - val_accuracy: 0.9229\n",
      "Epoch 341/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9043 - accuracy: 0.7646 - val_loss: 0.5080 - val_accuracy: 0.9268\n",
      "Epoch 342/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9244 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.9268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8516 - accuracy: 0.7619 - val_loss: 0.4879 - val_accuracy: 0.9281\n",
      "Epoch 344/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8902 - accuracy: 0.7734 - val_loss: 0.4887 - val_accuracy: 0.9294\n",
      "Epoch 345/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8552 - accuracy: 0.7750 - val_loss: 0.4866 - val_accuracy: 0.9294\n",
      "Epoch 346/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8436 - accuracy: 0.7691 - val_loss: 0.4811 - val_accuracy: 0.9294\n",
      "Epoch 347/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8863 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.9281\n",
      "Epoch 348/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8340 - accuracy: 0.7711 - val_loss: 0.4896 - val_accuracy: 0.9307\n",
      "Epoch 349/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.7802 - val_loss: 0.4841 - val_accuracy: 0.9294\n",
      "Epoch 350/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8872 - accuracy: 0.7698 - val_loss: 0.4688 - val_accuracy: 0.9281\n",
      "Epoch 351/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.7747 - val_loss: 0.4736 - val_accuracy: 0.9281\n",
      "Epoch 352/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8940 - accuracy: 0.7855 - val_loss: 0.4563 - val_accuracy: 0.9307\n",
      "Epoch 353/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.7802 - val_loss: 0.4597 - val_accuracy: 0.9268\n",
      "Epoch 354/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.7727 - val_loss: 0.4724 - val_accuracy: 0.9255\n",
      "Epoch 355/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.7744 - val_loss: 0.4726 - val_accuracy: 0.9268\n",
      "Epoch 356/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8217 - accuracy: 0.7796 - val_loss: 0.4770 - val_accuracy: 0.9281\n",
      "Epoch 357/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7905 - accuracy: 0.7714 - val_loss: 0.4713 - val_accuracy: 0.9281\n",
      "Epoch 358/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.7757 - val_loss: 0.4669 - val_accuracy: 0.9281\n",
      "Epoch 359/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8358 - accuracy: 0.7825 - val_loss: 0.4633 - val_accuracy: 0.9294\n",
      "Epoch 360/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8224 - accuracy: 0.7819 - val_loss: 0.4610 - val_accuracy: 0.9281\n",
      "Epoch 361/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9143 - accuracy: 0.7704 - val_loss: 0.4545 - val_accuracy: 0.9294\n",
      "Epoch 362/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8175 - accuracy: 0.7786 - val_loss: 0.4565 - val_accuracy: 0.9281\n",
      "Epoch 363/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8527 - accuracy: 0.7731 - val_loss: 0.4639 - val_accuracy: 0.9242\n",
      "Epoch 364/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8669 - accuracy: 0.7796 - val_loss: 0.4637 - val_accuracy: 0.9229\n",
      "Epoch 365/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8550 - accuracy: 0.7659 - val_loss: 0.4600 - val_accuracy: 0.9255\n",
      "Epoch 366/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.7717 - val_loss: 0.4596 - val_accuracy: 0.9190\n",
      "Epoch 367/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8871 - accuracy: 0.7897 - val_loss: 0.4528 - val_accuracy: 0.9242\n",
      "Epoch 368/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7998 - accuracy: 0.7858 - val_loss: 0.4486 - val_accuracy: 0.9268\n",
      "Epoch 369/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.7757 - val_loss: 0.4439 - val_accuracy: 0.9281\n",
      "Epoch 370/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8127 - accuracy: 0.7868 - val_loss: 0.4374 - val_accuracy: 0.9255\n",
      "Epoch 371/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8619 - accuracy: 0.7943 - val_loss: 0.4289 - val_accuracy: 0.9255\n",
      "Epoch 372/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.7861 - val_loss: 0.4273 - val_accuracy: 0.9216\n",
      "Epoch 373/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.7757 - val_loss: 0.4369 - val_accuracy: 0.9229\n",
      "Epoch 374/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.7825 - val_loss: 0.4367 - val_accuracy: 0.9242\n",
      "Epoch 375/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.7874 - val_loss: 0.4339 - val_accuracy: 0.9255\n",
      "Epoch 376/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8198 - accuracy: 0.7789 - val_loss: 0.4441 - val_accuracy: 0.9216\n",
      "Epoch 377/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8562 - accuracy: 0.7727 - val_loss: 0.4402 - val_accuracy: 0.9255\n",
      "Epoch 378/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8810 - accuracy: 0.7927 - val_loss: 0.4386 - val_accuracy: 0.9242\n",
      "Epoch 379/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.7809 - val_loss: 0.4401 - val_accuracy: 0.9307\n",
      "Epoch 380/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9107 - accuracy: 0.7848 - val_loss: 0.4441 - val_accuracy: 0.9268\n",
      "Epoch 381/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8332 - accuracy: 0.7894 - val_loss: 0.4323 - val_accuracy: 0.9307\n",
      "Epoch 382/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7921 - accuracy: 0.7953 - val_loss: 0.4431 - val_accuracy: 0.9294\n",
      "Epoch 383/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8458 - accuracy: 0.7816 - val_loss: 0.4227 - val_accuracy: 0.9281\n",
      "Epoch 384/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8141 - accuracy: 0.7943 - val_loss: 0.4321 - val_accuracy: 0.9307\n",
      "Epoch 385/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8543 - accuracy: 0.7930 - val_loss: 0.4164 - val_accuracy: 0.9294\n",
      "Epoch 386/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8815 - accuracy: 0.7888 - val_loss: 0.4281 - val_accuracy: 0.9307\n",
      "Epoch 387/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8277 - accuracy: 0.7842 - val_loss: 0.4242 - val_accuracy: 0.9281\n",
      "Epoch 388/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9315 - accuracy: 0.7816 - val_loss: 0.4267 - val_accuracy: 0.9294\n",
      "Epoch 389/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8272 - accuracy: 0.7881 - val_loss: 0.4149 - val_accuracy: 0.9359\n",
      "Epoch 390/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8050 - accuracy: 0.8005 - val_loss: 0.4209 - val_accuracy: 0.9359\n",
      "Epoch 391/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.7901 - val_loss: 0.4234 - val_accuracy: 0.9307\n",
      "Epoch 392/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7864 - accuracy: 0.7907 - val_loss: 0.4157 - val_accuracy: 0.9307\n",
      "Epoch 393/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8496 - accuracy: 0.7891 - val_loss: 0.4060 - val_accuracy: 0.9333\n",
      "Epoch 394/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8179 - accuracy: 0.7897 - val_loss: 0.4101 - val_accuracy: 0.9333\n",
      "Epoch 395/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7568 - accuracy: 0.7943 - val_loss: 0.4102 - val_accuracy: 0.9320\n",
      "Epoch 396/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8301 - accuracy: 0.7927 - val_loss: 0.4000 - val_accuracy: 0.9359\n",
      "Epoch 397/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.7852 - val_loss: 0.4037 - val_accuracy: 0.9359\n",
      "Epoch 398/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7743 - accuracy: 0.7995 - val_loss: 0.4154 - val_accuracy: 0.9373\n",
      "Epoch 399/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.9124 - accuracy: 0.7874 - val_loss: 0.4079 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8003 - accuracy: 0.8028 - val_loss: 0.4246 - val_accuracy: 0.9307\n",
      "Epoch 401/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8692 - accuracy: 0.7894 - val_loss: 0.4600 - val_accuracy: 0.9333\n",
      "Epoch 402/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7797 - accuracy: 0.7950 - val_loss: 0.4615 - val_accuracy: 0.9294\n",
      "Epoch 403/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7903 - accuracy: 0.8015 - val_loss: 0.4483 - val_accuracy: 0.9320\n",
      "Epoch 404/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8406 - accuracy: 0.7806 - val_loss: 0.4335 - val_accuracy: 0.9359\n",
      "Epoch 405/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8597 - accuracy: 0.7871 - val_loss: 0.4261 - val_accuracy: 0.9386\n",
      "Epoch 406/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7693 - accuracy: 0.8002 - val_loss: 0.4232 - val_accuracy: 0.9373\n",
      "Epoch 407/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8039 - accuracy: 0.7969 - val_loss: 0.4661 - val_accuracy: 0.9346\n",
      "Epoch 408/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8163 - accuracy: 0.7845 - val_loss: 0.4587 - val_accuracy: 0.9373\n",
      "Epoch 409/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7988 - accuracy: 0.7966 - val_loss: 0.4460 - val_accuracy: 0.9399\n",
      "Epoch 410/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.8103 - val_loss: 0.4518 - val_accuracy: 0.9359\n",
      "Epoch 411/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7961 - accuracy: 0.7982 - val_loss: 0.4471 - val_accuracy: 0.9333\n",
      "Epoch 412/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8152 - accuracy: 0.7992 - val_loss: 0.4352 - val_accuracy: 0.9333\n",
      "Epoch 413/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7429 - accuracy: 0.8028 - val_loss: 0.5236 - val_accuracy: 0.9294\n",
      "Epoch 414/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8173 - accuracy: 0.7976 - val_loss: 0.4968 - val_accuracy: 0.9307\n",
      "Epoch 415/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.8094 - val_loss: 0.4734 - val_accuracy: 0.9307\n",
      "Epoch 416/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.8074 - val_loss: 0.4592 - val_accuracy: 0.9320\n",
      "Epoch 417/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7918 - accuracy: 0.7917 - val_loss: 0.4483 - val_accuracy: 0.9320\n",
      "Epoch 418/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8202 - accuracy: 0.8015 - val_loss: 0.4377 - val_accuracy: 0.9359\n",
      "Epoch 419/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.7959 - val_loss: 0.4449 - val_accuracy: 0.9359\n",
      "Epoch 420/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7733 - accuracy: 0.8080 - val_loss: 0.4212 - val_accuracy: 0.9373\n",
      "Epoch 421/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7980 - accuracy: 0.7995 - val_loss: 0.4526 - val_accuracy: 0.9229\n",
      "Epoch 422/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7903 - accuracy: 0.7966 - val_loss: 0.4587 - val_accuracy: 0.9294\n",
      "Epoch 423/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.8058 - val_loss: 0.4593 - val_accuracy: 0.9294\n",
      "Epoch 424/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7957 - accuracy: 0.8044 - val_loss: 0.4650 - val_accuracy: 0.9294\n",
      "Epoch 425/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7944 - accuracy: 0.8018 - val_loss: 0.4649 - val_accuracy: 0.9307\n",
      "Epoch 426/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.8097 - val_loss: 0.4707 - val_accuracy: 0.9359\n",
      "Epoch 427/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.8051 - val_loss: 0.4462 - val_accuracy: 0.9359\n",
      "Epoch 428/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7425 - accuracy: 0.8067 - val_loss: 0.4503 - val_accuracy: 0.9346\n",
      "Epoch 429/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7555 - accuracy: 0.8074 - val_loss: 0.4443 - val_accuracy: 0.9320\n",
      "Epoch 430/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.8120 - val_loss: 0.4407 - val_accuracy: 0.9307\n",
      "Epoch 431/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7445 - accuracy: 0.8064 - val_loss: 0.4406 - val_accuracy: 0.9294\n",
      "Epoch 432/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7379 - accuracy: 0.8097 - val_loss: 0.4384 - val_accuracy: 0.9281\n",
      "Epoch 433/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.8067 - val_loss: 0.4472 - val_accuracy: 0.9281\n",
      "Epoch 434/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7643 - accuracy: 0.8136 - val_loss: 0.4421 - val_accuracy: 0.9307\n",
      "Epoch 435/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8132 - accuracy: 0.8080 - val_loss: 0.4381 - val_accuracy: 0.9294\n",
      "Epoch 436/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.8113 - val_loss: 0.4364 - val_accuracy: 0.9294\n",
      "Epoch 437/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.8113 - val_loss: 0.4303 - val_accuracy: 0.9307\n",
      "Epoch 438/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.8031 - val_loss: 0.4137 - val_accuracy: 0.9268\n",
      "Epoch 439/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7802 - accuracy: 0.8090 - val_loss: 0.4250 - val_accuracy: 0.9320\n",
      "Epoch 440/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.8080 - val_loss: 0.4393 - val_accuracy: 0.9281\n",
      "Epoch 441/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7695 - accuracy: 0.8028 - val_loss: 0.4407 - val_accuracy: 0.9268\n",
      "Epoch 442/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7620 - accuracy: 0.8087 - val_loss: 0.4259 - val_accuracy: 0.9255\n",
      "Epoch 443/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.8100 - val_loss: 0.4307 - val_accuracy: 0.9281\n",
      "Epoch 444/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.8195 - val_loss: 0.4100 - val_accuracy: 0.9320\n",
      "Epoch 445/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7847 - accuracy: 0.8071 - val_loss: 0.3902 - val_accuracy: 0.9320\n",
      "Epoch 446/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7742 - accuracy: 0.7995 - val_loss: 0.3892 - val_accuracy: 0.9320\n",
      "Epoch 447/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.8074 - val_loss: 0.3901 - val_accuracy: 0.9307\n",
      "Epoch 448/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.8133 - val_loss: 0.3991 - val_accuracy: 0.9346\n",
      "Epoch 449/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7376 - accuracy: 0.8182 - val_loss: 0.4000 - val_accuracy: 0.9307\n",
      "Epoch 450/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.8080 - val_loss: 0.4106 - val_accuracy: 0.9307\n",
      "Epoch 451/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8308 - accuracy: 0.8048 - val_loss: 0.3880 - val_accuracy: 0.9320\n",
      "Epoch 452/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7766 - accuracy: 0.8080 - val_loss: 0.3932 - val_accuracy: 0.9373\n",
      "Epoch 453/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8102 - accuracy: 0.7959 - val_loss: 0.3871 - val_accuracy: 0.9359\n",
      "Epoch 454/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7678 - accuracy: 0.8071 - val_loss: 0.3877 - val_accuracy: 0.9359\n",
      "Epoch 455/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.8185 - val_loss: 0.3880 - val_accuracy: 0.9333\n",
      "Epoch 456/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7510 - accuracy: 0.8175 - val_loss: 0.3634 - val_accuracy: 0.9373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7745 - accuracy: 0.8113 - val_loss: 0.3600 - val_accuracy: 0.9373\n",
      "Epoch 458/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7737 - accuracy: 0.7969 - val_loss: 0.3692 - val_accuracy: 0.9386\n",
      "Epoch 459/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7077 - accuracy: 0.8169 - val_loss: 0.3868 - val_accuracy: 0.9373\n",
      "Epoch 460/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.8244 - val_loss: 0.3846 - val_accuracy: 0.9346\n",
      "Epoch 461/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.8182 - val_loss: 0.3837 - val_accuracy: 0.9320\n",
      "Epoch 462/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7558 - accuracy: 0.8015 - val_loss: 0.3734 - val_accuracy: 0.9346\n",
      "Epoch 463/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8275 - accuracy: 0.8152 - val_loss: 0.3678 - val_accuracy: 0.9346\n",
      "Epoch 464/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7816 - accuracy: 0.8149 - val_loss: 0.3689 - val_accuracy: 0.9346\n",
      "Epoch 465/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7641 - accuracy: 0.8051 - val_loss: 0.3975 - val_accuracy: 0.9281\n",
      "Epoch 466/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7626 - accuracy: 0.8113 - val_loss: 0.4527 - val_accuracy: 0.9098\n",
      "Epoch 467/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.7838 - val_loss: 0.4437 - val_accuracy: 0.9137\n",
      "Epoch 468/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.8043 - accuracy: 0.7995 - val_loss: 0.4193 - val_accuracy: 0.9203\n",
      "Epoch 469/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7434 - accuracy: 0.8051 - val_loss: 0.4135 - val_accuracy: 0.9203\n",
      "Epoch 470/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7631 - accuracy: 0.8100 - val_loss: 0.4190 - val_accuracy: 0.9268\n",
      "Epoch 471/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7643 - accuracy: 0.8048 - val_loss: 0.4018 - val_accuracy: 0.9294\n",
      "Epoch 472/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.8018 - val_loss: 0.3914 - val_accuracy: 0.9346\n",
      "Epoch 473/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.8152 - val_loss: 0.3954 - val_accuracy: 0.9438\n",
      "Epoch 474/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.8031 - val_loss: 0.4156 - val_accuracy: 0.9373\n",
      "Epoch 475/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.8018 - val_loss: 0.4196 - val_accuracy: 0.9320\n",
      "Epoch 476/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7082 - accuracy: 0.8097 - val_loss: 0.4138 - val_accuracy: 0.9373\n",
      "Epoch 477/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.8143 - val_loss: 0.4366 - val_accuracy: 0.9359\n",
      "Epoch 478/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.8123 - val_loss: 0.4265 - val_accuracy: 0.9373\n",
      "Epoch 479/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.8038 - val_loss: 0.4315 - val_accuracy: 0.9333\n",
      "Epoch 480/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.8097 - val_loss: 0.4402 - val_accuracy: 0.9333\n",
      "Epoch 481/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.8116 - val_loss: 0.4360 - val_accuracy: 0.9307\n",
      "Epoch 482/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7615 - accuracy: 0.8084 - val_loss: 0.4285 - val_accuracy: 0.9307\n",
      "Epoch 483/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7359 - accuracy: 0.8051 - val_loss: 0.4228 - val_accuracy: 0.9307\n",
      "Epoch 484/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.8080 - val_loss: 0.4197 - val_accuracy: 0.9333\n",
      "Epoch 485/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.8349 - val_loss: 0.4219 - val_accuracy: 0.9333\n",
      "Epoch 486/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.8188 - val_loss: 0.4190 - val_accuracy: 0.9333\n",
      "Epoch 487/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.8139 - val_loss: 0.4171 - val_accuracy: 0.9307\n",
      "Epoch 488/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.8195 - val_loss: 0.4115 - val_accuracy: 0.9307\n",
      "Epoch 489/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7446 - accuracy: 0.8283 - val_loss: 0.4069 - val_accuracy: 0.9346\n",
      "Epoch 490/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.8107 - val_loss: 0.4002 - val_accuracy: 0.9346\n",
      "Epoch 491/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.8146 - val_loss: 0.4088 - val_accuracy: 0.9320\n",
      "Epoch 492/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.8198 - val_loss: 0.4090 - val_accuracy: 0.9281\n",
      "Epoch 493/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.8074 - val_loss: 0.4054 - val_accuracy: 0.9268\n",
      "Epoch 494/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7366 - accuracy: 0.8061 - val_loss: 0.4219 - val_accuracy: 0.9294\n",
      "Epoch 495/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.8071 - val_loss: 0.4195 - val_accuracy: 0.9281\n",
      "Epoch 496/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7577 - accuracy: 0.8097 - val_loss: 0.4126 - val_accuracy: 0.9294\n",
      "Epoch 497/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.8084 - val_loss: 0.4081 - val_accuracy: 0.9333\n",
      "Epoch 498/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7327 - accuracy: 0.8084 - val_loss: 0.4017 - val_accuracy: 0.9333\n",
      "Epoch 499/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.8120 - val_loss: 0.4097 - val_accuracy: 0.9333\n",
      "Epoch 500/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7538 - accuracy: 0.8028 - val_loss: 0.4045 - val_accuracy: 0.9320\n",
      "Epoch 501/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7331 - accuracy: 0.8064 - val_loss: 0.3896 - val_accuracy: 0.9320\n",
      "Epoch 502/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.8133 - val_loss: 0.3988 - val_accuracy: 0.9346\n",
      "Epoch 503/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.8152 - val_loss: 0.4104 - val_accuracy: 0.9333\n",
      "Epoch 504/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7311 - accuracy: 0.8097 - val_loss: 0.4177 - val_accuracy: 0.9307\n",
      "Epoch 505/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.8237 - val_loss: 0.4218 - val_accuracy: 0.9307\n",
      "Epoch 506/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.8280 - val_loss: 0.4155 - val_accuracy: 0.9320\n",
      "Epoch 507/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.8182 - val_loss: 0.4078 - val_accuracy: 0.9346\n",
      "Epoch 508/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.8182 - val_loss: 0.4021 - val_accuracy: 0.9346\n",
      "Epoch 509/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 0.8332 - val_loss: 0.3763 - val_accuracy: 0.9373\n",
      "Epoch 510/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.8221 - val_loss: 0.3723 - val_accuracy: 0.9346\n",
      "Epoch 511/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.8090 - val_loss: 0.3866 - val_accuracy: 0.9294\n",
      "Epoch 512/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.8185 - val_loss: 0.3825 - val_accuracy: 0.9320\n",
      "Epoch 513/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.8152 - val_loss: 0.3668 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7221 - accuracy: 0.8280 - val_loss: 0.4034 - val_accuracy: 0.9307\n",
      "Epoch 515/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.8159 - val_loss: 0.3793 - val_accuracy: 0.9346\n",
      "Epoch 516/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.8270 - val_loss: 0.3708 - val_accuracy: 0.9373\n",
      "Epoch 517/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.8172 - val_loss: 0.3667 - val_accuracy: 0.9359\n",
      "Epoch 518/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7743 - accuracy: 0.8162 - val_loss: 0.3722 - val_accuracy: 0.9373\n",
      "Epoch 519/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.8165 - val_loss: 0.3682 - val_accuracy: 0.9359\n",
      "Epoch 520/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7320 - accuracy: 0.8201 - val_loss: 0.3649 - val_accuracy: 0.9333\n",
      "Epoch 521/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7321 - accuracy: 0.8201 - val_loss: 0.3731 - val_accuracy: 0.9346\n",
      "Epoch 522/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.8231 - val_loss: 0.3712 - val_accuracy: 0.9333\n",
      "Epoch 523/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7325 - accuracy: 0.8123 - val_loss: 0.3935 - val_accuracy: 0.9294\n",
      "Epoch 524/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.8175 - val_loss: 0.3662 - val_accuracy: 0.9359\n",
      "Epoch 525/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.8306 - val_loss: 0.3715 - val_accuracy: 0.9438\n",
      "Epoch 526/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.8329 - val_loss: 0.3790 - val_accuracy: 0.9399\n",
      "Epoch 527/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.8267 - val_loss: 0.3845 - val_accuracy: 0.9373\n",
      "Epoch 528/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7399 - accuracy: 0.8054 - val_loss: 0.4427 - val_accuracy: 0.9111\n",
      "Epoch 529/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7598 - accuracy: 0.8139 - val_loss: 0.4424 - val_accuracy: 0.9124\n",
      "Epoch 530/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.8071 - val_loss: 0.4351 - val_accuracy: 0.9190\n",
      "Epoch 531/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.8162 - val_loss: 0.3990 - val_accuracy: 0.9294\n",
      "Epoch 532/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.8257 - val_loss: 0.3826 - val_accuracy: 0.9346\n",
      "Epoch 533/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.8165 - val_loss: 0.3833 - val_accuracy: 0.9386\n",
      "Epoch 534/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.8339 - val_loss: 0.3782 - val_accuracy: 0.9373\n",
      "Epoch 535/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.8280 - val_loss: 0.3748 - val_accuracy: 0.9373\n",
      "Epoch 536/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.8192 - val_loss: 0.3840 - val_accuracy: 0.9373\n",
      "Epoch 537/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.8205 - val_loss: 0.3659 - val_accuracy: 0.9399\n",
      "Epoch 538/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.8260 - val_loss: 0.3660 - val_accuracy: 0.9386\n",
      "Epoch 539/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.8280 - val_loss: 0.3635 - val_accuracy: 0.9386\n",
      "Epoch 540/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.8201 - val_loss: 0.3602 - val_accuracy: 0.9399\n",
      "Epoch 541/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.8205 - val_loss: 0.3554 - val_accuracy: 0.9399\n",
      "Epoch 542/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.8120 - val_loss: 0.3517 - val_accuracy: 0.9399\n",
      "Epoch 543/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.8129 - val_loss: 0.3492 - val_accuracy: 0.9438\n",
      "Epoch 544/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.8257 - val_loss: 0.3657 - val_accuracy: 0.9425\n",
      "Epoch 545/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.8264 - val_loss: 0.3619 - val_accuracy: 0.9412\n",
      "Epoch 546/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.8273 - val_loss: 0.3620 - val_accuracy: 0.9386\n",
      "Epoch 547/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7115 - accuracy: 0.8241 - val_loss: 0.3583 - val_accuracy: 0.9412\n",
      "Epoch 548/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.8270 - val_loss: 0.3421 - val_accuracy: 0.9412\n",
      "Epoch 549/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.8339 - val_loss: 0.3495 - val_accuracy: 0.9412\n",
      "Epoch 550/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.8309 - val_loss: 0.3531 - val_accuracy: 0.9412\n",
      "Epoch 551/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.8228 - val_loss: 0.3504 - val_accuracy: 0.9438\n",
      "Epoch 552/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.8300 - val_loss: 0.3553 - val_accuracy: 0.9412\n",
      "Epoch 553/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.8300 - val_loss: 0.3609 - val_accuracy: 0.9386\n",
      "Epoch 554/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.8398 - val_loss: 0.3558 - val_accuracy: 0.9386\n",
      "Epoch 555/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.8280 - val_loss: 0.3519 - val_accuracy: 0.9438\n",
      "Epoch 556/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.8296 - val_loss: 0.3468 - val_accuracy: 0.9451\n",
      "Epoch 557/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.8293 - val_loss: 0.3604 - val_accuracy: 0.9373\n",
      "Epoch 558/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.8267 - val_loss: 0.3703 - val_accuracy: 0.9386\n",
      "Epoch 559/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7658 - accuracy: 0.8175 - val_loss: 0.3660 - val_accuracy: 0.9386\n",
      "Epoch 560/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.8329 - val_loss: 0.3565 - val_accuracy: 0.9386\n",
      "Epoch 561/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.8309 - val_loss: 0.3512 - val_accuracy: 0.9399\n",
      "Epoch 562/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.8345 - val_loss: 0.3508 - val_accuracy: 0.9399\n",
      "Epoch 563/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.8407 - val_loss: 0.3579 - val_accuracy: 0.9412\n",
      "Epoch 564/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.8329 - val_loss: 0.3549 - val_accuracy: 0.9412\n",
      "Epoch 565/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.8352 - val_loss: 0.3514 - val_accuracy: 0.9425\n",
      "Epoch 566/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.8296 - val_loss: 0.3571 - val_accuracy: 0.9386\n",
      "Epoch 567/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.8309 - val_loss: 0.3535 - val_accuracy: 0.9412\n",
      "Epoch 568/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.8342 - val_loss: 0.3535 - val_accuracy: 0.9386\n",
      "Epoch 569/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.8316 - val_loss: 0.3522 - val_accuracy: 0.9386\n",
      "Epoch 570/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.8273 - val_loss: 0.3490 - val_accuracy: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.8273 - val_loss: 0.3435 - val_accuracy: 0.9386\n",
      "Epoch 572/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.8195 - val_loss: 0.3460 - val_accuracy: 0.9399\n",
      "Epoch 573/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.8257 - val_loss: 0.3485 - val_accuracy: 0.9412\n",
      "Epoch 574/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.8300 - val_loss: 0.3539 - val_accuracy: 0.9425\n",
      "Epoch 575/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.8349 - val_loss: 0.3525 - val_accuracy: 0.9346\n",
      "Epoch 576/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.8273 - val_loss: 0.3483 - val_accuracy: 0.9373\n",
      "Epoch 577/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7157 - accuracy: 0.8211 - val_loss: 0.3619 - val_accuracy: 0.9386\n",
      "Epoch 578/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.8365 - val_loss: 0.3674 - val_accuracy: 0.9346\n",
      "Epoch 579/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.8192 - val_loss: 0.3688 - val_accuracy: 0.9359\n",
      "Epoch 580/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.8273 - val_loss: 0.3758 - val_accuracy: 0.9359\n",
      "Epoch 581/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.8234 - val_loss: 0.3729 - val_accuracy: 0.9359\n",
      "Epoch 582/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.8329 - val_loss: 0.3671 - val_accuracy: 0.9359\n",
      "Epoch 583/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.8228 - val_loss: 0.3689 - val_accuracy: 0.9359\n",
      "Epoch 584/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.8277 - val_loss: 0.3748 - val_accuracy: 0.9359\n",
      "Epoch 585/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.8309 - val_loss: 0.3721 - val_accuracy: 0.9359\n",
      "Epoch 586/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7160 - accuracy: 0.8319 - val_loss: 0.3834 - val_accuracy: 0.9386\n",
      "Epoch 587/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.8316 - val_loss: 0.3760 - val_accuracy: 0.9359\n",
      "Epoch 588/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.8342 - val_loss: 0.3756 - val_accuracy: 0.9359\n",
      "Epoch 589/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.8260 - val_loss: 0.3769 - val_accuracy: 0.9386\n",
      "Epoch 590/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.8303 - val_loss: 0.3477 - val_accuracy: 0.9412\n",
      "Epoch 591/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.8218 - val_loss: 0.3418 - val_accuracy: 0.9412\n",
      "Epoch 592/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.8371 - val_loss: 0.3450 - val_accuracy: 0.9425\n",
      "Epoch 593/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.8375 - val_loss: 0.3712 - val_accuracy: 0.9464\n",
      "Epoch 594/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.8280 - val_loss: 0.3648 - val_accuracy: 0.9438\n",
      "Epoch 595/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.8250 - val_loss: 0.3676 - val_accuracy: 0.9503\n",
      "Epoch 596/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.8280 - val_loss: 0.3448 - val_accuracy: 0.9490\n",
      "Epoch 597/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.8430 - val_loss: 0.3514 - val_accuracy: 0.9490\n",
      "Epoch 598/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.8352 - val_loss: 0.3535 - val_accuracy: 0.9425\n",
      "Epoch 599/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.8398 - val_loss: 0.3531 - val_accuracy: 0.9425\n",
      "Epoch 600/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.8322 - val_loss: 0.3534 - val_accuracy: 0.9412\n",
      "Epoch 601/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.8443 - val_loss: 0.3529 - val_accuracy: 0.9451\n",
      "Epoch 602/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.8296 - val_loss: 0.3279 - val_accuracy: 0.9451\n",
      "Epoch 603/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.8169 - val_loss: 0.3424 - val_accuracy: 0.9451\n",
      "Epoch 604/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.8306 - val_loss: 0.3643 - val_accuracy: 0.9438\n",
      "Epoch 605/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.8355 - val_loss: 0.3609 - val_accuracy: 0.9438\n",
      "Epoch 606/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.8345 - val_loss: 0.3580 - val_accuracy: 0.9477\n",
      "Epoch 607/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.8264 - val_loss: 0.3548 - val_accuracy: 0.9425\n",
      "Epoch 608/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.8254 - val_loss: 0.3529 - val_accuracy: 0.9503\n",
      "Epoch 609/1000\n",
      "96/96 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.8424 - val_loss: 0.3487 - val_accuracy: 0.9451\n",
      "Epoch 610/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.8257 - val_loss: 0.3561 - val_accuracy: 0.9464\n",
      "Epoch 611/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.8411 - val_loss: 0.3380 - val_accuracy: 0.9516\n",
      "Epoch 612/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.8280 - val_loss: 0.3863 - val_accuracy: 0.9359\n",
      "Epoch 613/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.8241 - val_loss: 0.3827 - val_accuracy: 0.9346\n",
      "Epoch 614/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.8326 - val_loss: 0.3764 - val_accuracy: 0.9346\n",
      "Epoch 615/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.8329 - val_loss: 0.3683 - val_accuracy: 0.9386\n",
      "Epoch 616/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.8313 - val_loss: 0.3763 - val_accuracy: 0.9399\n",
      "Epoch 617/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.8336 - val_loss: 0.3513 - val_accuracy: 0.9464\n",
      "Epoch 618/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.8293 - val_loss: 0.3468 - val_accuracy: 0.9464\n",
      "Epoch 619/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.8411 - val_loss: 0.3459 - val_accuracy: 0.9451\n",
      "Epoch 620/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.8319 - val_loss: 0.3411 - val_accuracy: 0.9464\n",
      "Epoch 621/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.8319 - val_loss: 0.3361 - val_accuracy: 0.9438\n",
      "Epoch 622/1000\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.8332 - val_loss: 0.3413 - val_accuracy: 0.9464\n",
      "Epoch 623/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.8492 - val_loss: 0.3386 - val_accuracy: 0.9464\n",
      "Epoch 624/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.8411 - val_loss: 0.3373 - val_accuracy: 0.9412\n",
      "Epoch 625/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.8306 - val_loss: 0.3246 - val_accuracy: 0.9399\n",
      "Epoch 626/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.8342 - val_loss: 0.3195 - val_accuracy: 0.9412\n",
      "Epoch 627/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.8316 - val_loss: 0.3185 - val_accuracy: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.8427 - val_loss: 0.3214 - val_accuracy: 0.9412\n",
      "Epoch 629/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.8339 - val_loss: 0.3327 - val_accuracy: 0.9399\n",
      "Epoch 630/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.8401 - val_loss: 0.3257 - val_accuracy: 0.9425\n",
      "Epoch 631/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.8381 - val_loss: 0.3302 - val_accuracy: 0.9451\n",
      "Epoch 632/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.8391 - val_loss: 0.3294 - val_accuracy: 0.9412\n",
      "Epoch 633/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.8381 - val_loss: 0.3151 - val_accuracy: 0.9451\n",
      "Epoch 634/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.8466 - val_loss: 0.3337 - val_accuracy: 0.9412\n",
      "Epoch 635/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.8368 - val_loss: 0.3110 - val_accuracy: 0.9412\n",
      "Epoch 636/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.8421 - val_loss: 0.3318 - val_accuracy: 0.9451\n",
      "Epoch 637/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.8411 - val_loss: 0.3284 - val_accuracy: 0.9464\n",
      "Epoch 638/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.8453 - val_loss: 0.3359 - val_accuracy: 0.9438\n",
      "Epoch 639/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.8450 - val_loss: 0.3365 - val_accuracy: 0.9438\n",
      "Epoch 640/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.8542 - val_loss: 0.3337 - val_accuracy: 0.9477\n",
      "Epoch 641/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.8421 - val_loss: 0.3694 - val_accuracy: 0.9477\n",
      "Epoch 642/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.8388 - val_loss: 0.3582 - val_accuracy: 0.9451\n",
      "Epoch 643/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.8430 - val_loss: 0.3645 - val_accuracy: 0.9477\n",
      "Epoch 644/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.8375 - val_loss: 0.3434 - val_accuracy: 0.9503\n",
      "Epoch 645/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.8424 - val_loss: 0.3553 - val_accuracy: 0.9438\n",
      "Epoch 646/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.8368 - val_loss: 0.3488 - val_accuracy: 0.9425\n",
      "Epoch 647/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.8358 - val_loss: 0.3617 - val_accuracy: 0.9438\n",
      "Epoch 648/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.8352 - val_loss: 0.3643 - val_accuracy: 0.9425\n",
      "Epoch 649/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.8391 - val_loss: 0.3538 - val_accuracy: 0.9438\n",
      "Epoch 650/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.8424 - val_loss: 0.3504 - val_accuracy: 0.9438\n",
      "Epoch 651/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.8443 - val_loss: 0.3448 - val_accuracy: 0.9451\n",
      "Epoch 652/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.8358 - val_loss: 0.3382 - val_accuracy: 0.9451\n",
      "Epoch 653/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.8332 - val_loss: 0.3649 - val_accuracy: 0.9333\n",
      "Epoch 654/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.8499 - val_loss: 0.3440 - val_accuracy: 0.9451\n",
      "Epoch 655/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.8391 - val_loss: 0.3514 - val_accuracy: 0.9503\n",
      "Epoch 656/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.8322 - val_loss: 0.3483 - val_accuracy: 0.9490\n",
      "Epoch 657/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.8460 - val_loss: 0.3489 - val_accuracy: 0.9529\n",
      "Epoch 658/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.8342 - val_loss: 0.3506 - val_accuracy: 0.9464\n",
      "Epoch 659/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.8466 - val_loss: 0.3456 - val_accuracy: 0.9529\n",
      "Epoch 660/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.8453 - val_loss: 0.3396 - val_accuracy: 0.9477\n",
      "Epoch 661/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.8515 - val_loss: 0.3339 - val_accuracy: 0.9503\n",
      "Epoch 662/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.8528 - val_loss: 0.3317 - val_accuracy: 0.9477\n",
      "Epoch 663/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.8450 - val_loss: 0.3300 - val_accuracy: 0.9477\n",
      "Epoch 664/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.8457 - val_loss: 0.3276 - val_accuracy: 0.9477\n",
      "Epoch 665/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.8499 - val_loss: 0.3334 - val_accuracy: 0.9464\n",
      "Epoch 666/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.8417 - val_loss: 0.3280 - val_accuracy: 0.9490\n",
      "Epoch 667/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.8437 - val_loss: 0.3241 - val_accuracy: 0.9516\n",
      "Epoch 668/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.8470 - val_loss: 0.3232 - val_accuracy: 0.9503\n",
      "Epoch 669/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.8424 - val_loss: 0.3277 - val_accuracy: 0.9490\n",
      "Epoch 670/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.8430 - val_loss: 0.3334 - val_accuracy: 0.9529\n",
      "Epoch 671/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.8476 - val_loss: 0.3503 - val_accuracy: 0.9503\n",
      "Epoch 672/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.8303 - val_loss: 0.3469 - val_accuracy: 0.9503\n",
      "Epoch 673/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.8466 - val_loss: 0.3403 - val_accuracy: 0.9490\n",
      "Epoch 674/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.8460 - val_loss: 0.3257 - val_accuracy: 0.9490\n",
      "Epoch 675/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.8479 - val_loss: 0.3216 - val_accuracy: 0.9503\n",
      "Epoch 676/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.8421 - val_loss: 0.3296 - val_accuracy: 0.9490\n",
      "Epoch 677/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.8381 - val_loss: 0.3395 - val_accuracy: 0.9451\n",
      "Epoch 678/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.8506 - val_loss: 0.3331 - val_accuracy: 0.9464\n",
      "Epoch 679/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.8499 - val_loss: 0.3253 - val_accuracy: 0.9477\n",
      "Epoch 680/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.8561 - val_loss: 0.3260 - val_accuracy: 0.9542\n",
      "Epoch 681/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.8381 - val_loss: 0.3161 - val_accuracy: 0.9516\n",
      "Epoch 682/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.8492 - val_loss: 0.3243 - val_accuracy: 0.9490\n",
      "Epoch 683/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.8542 - val_loss: 0.3217 - val_accuracy: 0.9490\n",
      "Epoch 684/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.8492 - val_loss: 0.3343 - val_accuracy: 0.9464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.8594 - val_loss: 0.3279 - val_accuracy: 0.9451\n",
      "Epoch 686/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.8574 - val_loss: 0.3413 - val_accuracy: 0.9386\n",
      "Epoch 687/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.8476 - val_loss: 0.3365 - val_accuracy: 0.9425\n",
      "Epoch 688/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.8430 - val_loss: 0.3279 - val_accuracy: 0.9438\n",
      "Epoch 689/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.8479 - val_loss: 0.3358 - val_accuracy: 0.9425\n",
      "Epoch 690/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.8545 - val_loss: 0.3318 - val_accuracy: 0.9438\n",
      "Epoch 691/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.8627 - val_loss: 0.3284 - val_accuracy: 0.9425\n",
      "Epoch 692/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.8404 - val_loss: 0.3296 - val_accuracy: 0.9477\n",
      "Epoch 693/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.8440 - val_loss: 0.3294 - val_accuracy: 0.9451\n",
      "Epoch 694/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.8385 - val_loss: 0.3565 - val_accuracy: 0.9399\n",
      "Epoch 695/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.8453 - val_loss: 0.3435 - val_accuracy: 0.9412\n",
      "Epoch 696/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.8538 - val_loss: 0.3210 - val_accuracy: 0.9451\n",
      "Epoch 697/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.8453 - val_loss: 0.3374 - val_accuracy: 0.9464\n",
      "Epoch 698/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.8460 - val_loss: 0.2999 - val_accuracy: 0.9529\n",
      "Epoch 699/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.8492 - val_loss: 0.2964 - val_accuracy: 0.9529\n",
      "Epoch 700/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.8499 - val_loss: 0.3017 - val_accuracy: 0.9542\n",
      "Epoch 701/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.8571 - val_loss: 0.3100 - val_accuracy: 0.9503\n",
      "Epoch 702/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.8483 - val_loss: 0.2979 - val_accuracy: 0.9529\n",
      "Epoch 703/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8535 - val_loss: 0.2961 - val_accuracy: 0.9542\n",
      "Epoch 704/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.8470 - val_loss: 0.2972 - val_accuracy: 0.9516\n",
      "Epoch 705/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.8515 - val_loss: 0.3066 - val_accuracy: 0.9503\n",
      "Epoch 706/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.8440 - val_loss: 0.3112 - val_accuracy: 0.9503\n",
      "Epoch 707/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.8519 - val_loss: 0.3080 - val_accuracy: 0.9490\n",
      "Epoch 708/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.8568 - val_loss: 0.3243 - val_accuracy: 0.9464\n",
      "Epoch 709/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.8528 - val_loss: 0.3307 - val_accuracy: 0.9490\n",
      "Epoch 710/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.8682 - val_loss: 0.3337 - val_accuracy: 0.9516\n",
      "Epoch 711/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.8568 - val_loss: 0.3284 - val_accuracy: 0.9490\n",
      "Epoch 712/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.8574 - val_loss: 0.3270 - val_accuracy: 0.9451\n",
      "Epoch 713/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.8555 - val_loss: 0.3248 - val_accuracy: 0.9477\n",
      "Epoch 714/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.8649 - val_loss: 0.3203 - val_accuracy: 0.9503\n",
      "Epoch 715/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.8506 - val_loss: 0.3291 - val_accuracy: 0.9516\n",
      "Epoch 716/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.8492 - val_loss: 0.3404 - val_accuracy: 0.9464\n",
      "Epoch 717/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.8617 - val_loss: 0.3477 - val_accuracy: 0.9490\n",
      "Epoch 718/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.8597 - val_loss: 0.3440 - val_accuracy: 0.9451\n",
      "Epoch 719/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.8640 - val_loss: 0.3427 - val_accuracy: 0.9451\n",
      "Epoch 720/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.8542 - val_loss: 0.3417 - val_accuracy: 0.9464\n",
      "Epoch 721/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.8581 - val_loss: 0.3347 - val_accuracy: 0.9477\n",
      "Epoch 722/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.8525 - val_loss: 0.3275 - val_accuracy: 0.9490\n",
      "Epoch 723/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.8600 - val_loss: 0.3263 - val_accuracy: 0.9503\n",
      "Epoch 724/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.8561 - val_loss: 0.3255 - val_accuracy: 0.9490\n",
      "Epoch 725/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.8587 - val_loss: 0.3253 - val_accuracy: 0.9490\n",
      "Epoch 726/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.8499 - val_loss: 0.3228 - val_accuracy: 0.9503\n",
      "Epoch 727/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.8453 - val_loss: 0.3210 - val_accuracy: 0.9516\n",
      "Epoch 728/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.8555 - val_loss: 0.3201 - val_accuracy: 0.9529\n",
      "Epoch 729/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.8558 - val_loss: 0.3273 - val_accuracy: 0.9503\n",
      "Epoch 730/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.8617 - val_loss: 0.3410 - val_accuracy: 0.9516\n",
      "Epoch 731/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.8519 - val_loss: 0.3377 - val_accuracy: 0.9529\n",
      "Epoch 732/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.8561 - val_loss: 0.2978 - val_accuracy: 0.9569\n",
      "Epoch 733/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.8600 - val_loss: 0.2940 - val_accuracy: 0.9556\n",
      "Epoch 734/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8499 - val_loss: 0.2906 - val_accuracy: 0.9569\n",
      "Epoch 735/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.8509 - val_loss: 0.2859 - val_accuracy: 0.9556\n",
      "Epoch 736/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.8473 - val_loss: 0.2925 - val_accuracy: 0.9569\n",
      "Epoch 737/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.8528 - val_loss: 0.2884 - val_accuracy: 0.9556\n",
      "Epoch 738/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.8591 - val_loss: 0.2842 - val_accuracy: 0.9595\n",
      "Epoch 739/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.8564 - val_loss: 0.2893 - val_accuracy: 0.9608\n",
      "Epoch 740/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.8545 - val_loss: 0.2873 - val_accuracy: 0.9556\n",
      "Epoch 741/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.8519 - val_loss: 0.3078 - val_accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.8630 - val_loss: 0.3036 - val_accuracy: 0.9569\n",
      "Epoch 743/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.8512 - val_loss: 0.2930 - val_accuracy: 0.9595\n",
      "Epoch 744/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.8551 - val_loss: 0.3076 - val_accuracy: 0.9529\n",
      "Epoch 745/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.8538 - val_loss: 0.2961 - val_accuracy: 0.9542\n",
      "Epoch 746/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.8610 - val_loss: 0.3163 - val_accuracy: 0.9529\n",
      "Epoch 747/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.8555 - val_loss: 0.2976 - val_accuracy: 0.9529\n",
      "Epoch 748/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.8440 - val_loss: 0.3239 - val_accuracy: 0.9490\n",
      "Epoch 749/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.8532 - val_loss: 0.3430 - val_accuracy: 0.9451\n",
      "Epoch 750/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.8564 - val_loss: 0.3425 - val_accuracy: 0.9477\n",
      "Epoch 751/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.8437 - val_loss: 0.3362 - val_accuracy: 0.9490\n",
      "Epoch 752/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.8476 - val_loss: 0.3307 - val_accuracy: 0.9516\n",
      "Epoch 753/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.8571 - val_loss: 0.3279 - val_accuracy: 0.9490\n",
      "Epoch 754/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.8457 - val_loss: 0.3042 - val_accuracy: 0.9582\n",
      "Epoch 755/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.8479 - val_loss: 0.2989 - val_accuracy: 0.9582\n",
      "Epoch 756/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.8470 - val_loss: 0.2971 - val_accuracy: 0.9569\n",
      "Epoch 757/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8581 - val_loss: 0.2937 - val_accuracy: 0.9556\n",
      "Epoch 758/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.8623 - val_loss: 0.3056 - val_accuracy: 0.9582\n",
      "Epoch 759/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.8532 - val_loss: 0.3040 - val_accuracy: 0.9556\n",
      "Epoch 760/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.8698 - val_loss: 0.3030 - val_accuracy: 0.9569\n",
      "Epoch 761/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.8627 - val_loss: 0.3036 - val_accuracy: 0.9556\n",
      "Epoch 762/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.8591 - val_loss: 0.3031 - val_accuracy: 0.9556\n",
      "Epoch 763/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.8561 - val_loss: 0.3013 - val_accuracy: 0.9556\n",
      "Epoch 764/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.8525 - val_loss: 0.3102 - val_accuracy: 0.9556\n",
      "Epoch 765/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.8551 - val_loss: 0.3202 - val_accuracy: 0.9556\n",
      "Epoch 766/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.8512 - val_loss: 0.3156 - val_accuracy: 0.9556\n",
      "Epoch 767/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.8633 - val_loss: 0.3108 - val_accuracy: 0.9556\n",
      "Epoch 768/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.8571 - val_loss: 0.3053 - val_accuracy: 0.9556\n",
      "Epoch 769/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.8610 - val_loss: 0.2937 - val_accuracy: 0.9542\n",
      "Epoch 770/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8581 - val_loss: 0.3149 - val_accuracy: 0.9556\n",
      "Epoch 771/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.8506 - val_loss: 0.3350 - val_accuracy: 0.9503\n",
      "Epoch 772/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.8391 - val_loss: 0.3320 - val_accuracy: 0.9516\n",
      "Epoch 773/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.8457 - val_loss: 0.3247 - val_accuracy: 0.9516\n",
      "Epoch 774/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.8564 - val_loss: 0.3195 - val_accuracy: 0.9529\n",
      "Epoch 775/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8528 - val_loss: 0.3141 - val_accuracy: 0.9503\n",
      "Epoch 776/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.8528 - val_loss: 0.2988 - val_accuracy: 0.9503\n",
      "Epoch 777/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.8548 - val_loss: 0.2974 - val_accuracy: 0.9503\n",
      "Epoch 778/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.8574 - val_loss: 0.2977 - val_accuracy: 0.9490\n",
      "Epoch 779/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.8551 - val_loss: 0.2928 - val_accuracy: 0.9490\n",
      "Epoch 780/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.8604 - val_loss: 0.2885 - val_accuracy: 0.9490\n",
      "Epoch 781/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.8610 - val_loss: 0.2851 - val_accuracy: 0.9490\n",
      "Epoch 782/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.8558 - val_loss: 0.2897 - val_accuracy: 0.9503\n",
      "Epoch 783/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.8627 - val_loss: 0.2861 - val_accuracy: 0.9516\n",
      "Epoch 784/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.8584 - val_loss: 0.2842 - val_accuracy: 0.9503\n",
      "Epoch 785/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.8646 - val_loss: 0.2819 - val_accuracy: 0.9490\n",
      "Epoch 786/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.8623 - val_loss: 0.2793 - val_accuracy: 0.9490\n",
      "Epoch 787/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.8607 - val_loss: 0.2791 - val_accuracy: 0.9490\n",
      "Epoch 788/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.8564 - val_loss: 0.2893 - val_accuracy: 0.9490\n",
      "Epoch 789/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8617 - val_loss: 0.2784 - val_accuracy: 0.9477\n",
      "Epoch 790/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.8597 - val_loss: 0.2880 - val_accuracy: 0.9477\n",
      "Epoch 791/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.8613 - val_loss: 0.2752 - val_accuracy: 0.9477\n",
      "Epoch 792/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.8574 - val_loss: 0.2848 - val_accuracy: 0.9477\n",
      "Epoch 793/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.8532 - val_loss: 0.2890 - val_accuracy: 0.9490\n",
      "Epoch 794/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.8587 - val_loss: 0.2916 - val_accuracy: 0.9477\n",
      "Epoch 795/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.8450 - val_loss: 0.2882 - val_accuracy: 0.9503\n",
      "Epoch 796/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.8538 - val_loss: 0.2877 - val_accuracy: 0.9477\n",
      "Epoch 797/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.8555 - val_loss: 0.2872 - val_accuracy: 0.9464\n",
      "Epoch 798/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.8466 - val_loss: 0.2887 - val_accuracy: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.8672 - val_loss: 0.3140 - val_accuracy: 0.9516\n",
      "Epoch 800/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.8574 - val_loss: 0.3230 - val_accuracy: 0.9529\n",
      "Epoch 801/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.8685 - val_loss: 0.3197 - val_accuracy: 0.9516\n",
      "Epoch 802/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.8571 - val_loss: 0.3304 - val_accuracy: 0.9529\n",
      "Epoch 803/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.8584 - val_loss: 0.3108 - val_accuracy: 0.9529\n",
      "Epoch 804/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8486 - val_loss: 0.3175 - val_accuracy: 0.9516\n",
      "Epoch 805/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8640 - val_loss: 0.3139 - val_accuracy: 0.9516\n",
      "Epoch 806/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.8643 - val_loss: 0.3105 - val_accuracy: 0.9529\n",
      "Epoch 807/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.8672 - val_loss: 0.3080 - val_accuracy: 0.9516\n",
      "Epoch 808/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.8574 - val_loss: 0.3054 - val_accuracy: 0.9503\n",
      "Epoch 809/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.8685 - val_loss: 0.3037 - val_accuracy: 0.9556\n",
      "Epoch 810/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.8584 - val_loss: 0.3150 - val_accuracy: 0.9542\n",
      "Epoch 811/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.8640 - val_loss: 0.3050 - val_accuracy: 0.9516\n",
      "Epoch 812/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.8607 - val_loss: 0.3071 - val_accuracy: 0.9542\n",
      "Epoch 813/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.8617 - val_loss: 0.3017 - val_accuracy: 0.9503\n",
      "Epoch 814/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.8656 - val_loss: 0.3082 - val_accuracy: 0.9516\n",
      "Epoch 815/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.8666 - val_loss: 0.3211 - val_accuracy: 0.9438\n",
      "Epoch 816/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8617 - val_loss: 0.3212 - val_accuracy: 0.9477\n",
      "Epoch 817/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8545 - val_loss: 0.3330 - val_accuracy: 0.9477\n",
      "Epoch 818/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8708 - val_loss: 0.3266 - val_accuracy: 0.9490\n",
      "Epoch 819/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.8627 - val_loss: 0.3127 - val_accuracy: 0.9503\n",
      "Epoch 820/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.8610 - val_loss: 0.2912 - val_accuracy: 0.9569\n",
      "Epoch 821/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.8568 - val_loss: 0.3093 - val_accuracy: 0.9542\n",
      "Epoch 822/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.8672 - val_loss: 0.3055 - val_accuracy: 0.9569\n",
      "Epoch 823/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.8574 - val_loss: 0.3057 - val_accuracy: 0.9529\n",
      "Epoch 824/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.8659 - val_loss: 0.3090 - val_accuracy: 0.9516\n",
      "Epoch 825/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.8581 - val_loss: 0.3052 - val_accuracy: 0.9503\n",
      "Epoch 826/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.8548 - val_loss: 0.3007 - val_accuracy: 0.9542\n",
      "Epoch 827/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.8594 - val_loss: 0.3018 - val_accuracy: 0.9516\n",
      "Epoch 828/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.8607 - val_loss: 0.3031 - val_accuracy: 0.9503\n",
      "Epoch 829/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.8607 - val_loss: 0.2999 - val_accuracy: 0.9516\n",
      "Epoch 830/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8685 - val_loss: 0.2787 - val_accuracy: 0.9556\n",
      "Epoch 831/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.8663 - val_loss: 0.3007 - val_accuracy: 0.9516\n",
      "Epoch 832/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8591 - val_loss: 0.2934 - val_accuracy: 0.9529\n",
      "Epoch 833/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8728 - val_loss: 0.2904 - val_accuracy: 0.9529\n",
      "Epoch 834/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.8679 - val_loss: 0.2903 - val_accuracy: 0.9477\n",
      "Epoch 835/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.8636 - val_loss: 0.2843 - val_accuracy: 0.9529\n",
      "Epoch 836/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.8692 - val_loss: 0.2844 - val_accuracy: 0.9529\n",
      "Epoch 837/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.8617 - val_loss: 0.2846 - val_accuracy: 0.9503\n",
      "Epoch 838/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8764 - val_loss: 0.2830 - val_accuracy: 0.9490\n",
      "Epoch 839/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.8698 - val_loss: 0.2824 - val_accuracy: 0.9477\n",
      "Epoch 840/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.8793 - val_loss: 0.2928 - val_accuracy: 0.9529\n",
      "Epoch 841/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.8633 - val_loss: 0.2880 - val_accuracy: 0.9542\n",
      "Epoch 842/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.8636 - val_loss: 0.2897 - val_accuracy: 0.9503\n",
      "Epoch 843/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.8646 - val_loss: 0.2883 - val_accuracy: 0.9503\n",
      "Epoch 844/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8689 - val_loss: 0.2945 - val_accuracy: 0.9516\n",
      "Epoch 845/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.8600 - val_loss: 0.3153 - val_accuracy: 0.9464\n",
      "Epoch 846/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.8646 - val_loss: 0.3120 - val_accuracy: 0.9451\n",
      "Epoch 847/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.8767 - val_loss: 0.3230 - val_accuracy: 0.9464\n",
      "Epoch 848/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.8738 - val_loss: 0.3117 - val_accuracy: 0.9477\n",
      "Epoch 849/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.8698 - val_loss: 0.3155 - val_accuracy: 0.9516\n",
      "Epoch 850/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.8574 - val_loss: 0.3091 - val_accuracy: 0.9503\n",
      "Epoch 851/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.8718 - val_loss: 0.2919 - val_accuracy: 0.9490\n",
      "Epoch 852/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.8738 - val_loss: 0.3261 - val_accuracy: 0.9451\n",
      "Epoch 853/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.8620 - val_loss: 0.3234 - val_accuracy: 0.9464\n",
      "Epoch 854/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.8646 - val_loss: 0.3138 - val_accuracy: 0.9438\n",
      "Epoch 855/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.8712 - val_loss: 0.2897 - val_accuracy: 0.9464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.8731 - val_loss: 0.3094 - val_accuracy: 0.9438\n",
      "Epoch 857/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.8702 - val_loss: 0.3156 - val_accuracy: 0.9477\n",
      "Epoch 858/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.8617 - val_loss: 0.2972 - val_accuracy: 0.9490\n",
      "Epoch 859/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.8780 - val_loss: 0.2972 - val_accuracy: 0.9503\n",
      "Epoch 860/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.8591 - val_loss: 0.3050 - val_accuracy: 0.9516\n",
      "Epoch 861/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.8659 - val_loss: 0.3033 - val_accuracy: 0.9516\n",
      "Epoch 862/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8731 - val_loss: 0.2992 - val_accuracy: 0.9490\n",
      "Epoch 863/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8725 - val_loss: 0.2965 - val_accuracy: 0.9516\n",
      "Epoch 864/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.8698 - val_loss: 0.2980 - val_accuracy: 0.9516\n",
      "Epoch 865/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8656 - val_loss: 0.2994 - val_accuracy: 0.9529\n",
      "Epoch 866/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.8728 - val_loss: 0.2958 - val_accuracy: 0.9556\n",
      "Epoch 867/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8777 - val_loss: 0.2919 - val_accuracy: 0.9542\n",
      "Epoch 868/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.8761 - val_loss: 0.2843 - val_accuracy: 0.9529\n",
      "Epoch 869/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8797 - val_loss: 0.2839 - val_accuracy: 0.9516\n",
      "Epoch 870/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8731 - val_loss: 0.2848 - val_accuracy: 0.9516\n",
      "Epoch 871/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8682 - val_loss: 0.2903 - val_accuracy: 0.9556\n",
      "Epoch 872/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8715 - val_loss: 0.2865 - val_accuracy: 0.9516\n",
      "Epoch 873/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8767 - val_loss: 0.2913 - val_accuracy: 0.9477\n",
      "Epoch 874/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.8676 - val_loss: 0.2889 - val_accuracy: 0.9542\n",
      "Epoch 875/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8770 - val_loss: 0.2839 - val_accuracy: 0.9529\n",
      "Epoch 876/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8757 - val_loss: 0.2802 - val_accuracy: 0.9516\n",
      "Epoch 877/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.8728 - val_loss: 0.2839 - val_accuracy: 0.9477\n",
      "Epoch 878/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8708 - val_loss: 0.2862 - val_accuracy: 0.9503\n",
      "Epoch 879/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.8813 - val_loss: 0.2946 - val_accuracy: 0.9477\n",
      "Epoch 880/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8679 - val_loss: 0.2839 - val_accuracy: 0.9477\n",
      "Epoch 881/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8669 - val_loss: 0.2917 - val_accuracy: 0.9477\n",
      "Epoch 882/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8712 - val_loss: 0.3012 - val_accuracy: 0.9477\n",
      "Epoch 883/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8728 - val_loss: 0.2998 - val_accuracy: 0.9490\n",
      "Epoch 884/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.8754 - val_loss: 0.2964 - val_accuracy: 0.9503\n",
      "Epoch 885/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8770 - val_loss: 0.2918 - val_accuracy: 0.9490\n",
      "Epoch 886/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8780 - val_loss: 0.2910 - val_accuracy: 0.9516\n",
      "Epoch 887/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8734 - val_loss: 0.2896 - val_accuracy: 0.9490\n",
      "Epoch 888/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8744 - val_loss: 0.2869 - val_accuracy: 0.9490\n",
      "Epoch 889/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.8708 - val_loss: 0.2785 - val_accuracy: 0.9503\n",
      "Epoch 890/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8718 - val_loss: 0.2762 - val_accuracy: 0.9516\n",
      "Epoch 891/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.8636 - val_loss: 0.2775 - val_accuracy: 0.9503\n",
      "Epoch 892/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.8764 - val_loss: 0.2908 - val_accuracy: 0.9529\n",
      "Epoch 893/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8715 - val_loss: 0.2865 - val_accuracy: 0.9542\n",
      "Epoch 894/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8721 - val_loss: 0.3028 - val_accuracy: 0.9503\n",
      "Epoch 895/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.8705 - val_loss: 0.2987 - val_accuracy: 0.9516\n",
      "Epoch 896/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.8698 - val_loss: 0.2955 - val_accuracy: 0.9438\n",
      "Epoch 897/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8721 - val_loss: 0.2917 - val_accuracy: 0.9477\n",
      "Epoch 898/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8793 - val_loss: 0.2943 - val_accuracy: 0.9464\n",
      "Epoch 899/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8672 - val_loss: 0.2965 - val_accuracy: 0.9490\n",
      "Epoch 900/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8659 - val_loss: 0.2965 - val_accuracy: 0.9477\n",
      "Epoch 901/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.8734 - val_loss: 0.3039 - val_accuracy: 0.9464\n",
      "Epoch 902/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8780 - val_loss: 0.3127 - val_accuracy: 0.9490\n",
      "Epoch 903/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.8627 - val_loss: 0.3170 - val_accuracy: 0.9503\n",
      "Epoch 904/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8698 - val_loss: 0.3202 - val_accuracy: 0.9464\n",
      "Epoch 905/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8757 - val_loss: 0.3192 - val_accuracy: 0.9451\n",
      "Epoch 906/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8810 - val_loss: 0.3163 - val_accuracy: 0.9477\n",
      "Epoch 907/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8738 - val_loss: 0.3154 - val_accuracy: 0.9451\n",
      "Epoch 908/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8653 - val_loss: 0.3151 - val_accuracy: 0.9477\n",
      "Epoch 909/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8728 - val_loss: 0.2964 - val_accuracy: 0.9516\n",
      "Epoch 910/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8784 - val_loss: 0.2874 - val_accuracy: 0.9529\n",
      "Epoch 911/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8800 - val_loss: 0.2854 - val_accuracy: 0.9503\n",
      "Epoch 912/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8734 - val_loss: 0.2949 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8751 - val_loss: 0.2918 - val_accuracy: 0.9529\n",
      "Epoch 914/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.8708 - val_loss: 0.2879 - val_accuracy: 0.9542\n",
      "Epoch 915/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8869 - val_loss: 0.3070 - val_accuracy: 0.9490\n",
      "Epoch 916/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8784 - val_loss: 0.3095 - val_accuracy: 0.9464\n",
      "Epoch 917/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8734 - val_loss: 0.3104 - val_accuracy: 0.9490\n",
      "Epoch 918/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8816 - val_loss: 0.3075 - val_accuracy: 0.9477\n",
      "Epoch 919/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8695 - val_loss: 0.3042 - val_accuracy: 0.9464\n",
      "Epoch 920/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8767 - val_loss: 0.3006 - val_accuracy: 0.9503\n",
      "Epoch 921/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.8754 - val_loss: 0.2627 - val_accuracy: 0.9569\n",
      "Epoch 922/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8790 - val_loss: 0.2721 - val_accuracy: 0.9542\n",
      "Epoch 923/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.8712 - val_loss: 0.2858 - val_accuracy: 0.9569\n",
      "Epoch 924/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8708 - val_loss: 0.2996 - val_accuracy: 0.9503\n",
      "Epoch 925/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8627 - val_loss: 0.3022 - val_accuracy: 0.9464\n",
      "Epoch 926/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8744 - val_loss: 0.2989 - val_accuracy: 0.9438\n",
      "Epoch 927/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8751 - val_loss: 0.2951 - val_accuracy: 0.9425\n",
      "Epoch 928/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8682 - val_loss: 0.3128 - val_accuracy: 0.9386\n",
      "Epoch 929/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8656 - val_loss: 0.3083 - val_accuracy: 0.9425\n",
      "Epoch 930/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8718 - val_loss: 0.3047 - val_accuracy: 0.9425\n",
      "Epoch 931/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8744 - val_loss: 0.3016 - val_accuracy: 0.9412\n",
      "Epoch 932/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8708 - val_loss: 0.3049 - val_accuracy: 0.9451\n",
      "Epoch 933/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.8731 - val_loss: 0.3031 - val_accuracy: 0.9438\n",
      "Epoch 934/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.8685 - val_loss: 0.3019 - val_accuracy: 0.9425\n",
      "Epoch 935/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8777 - val_loss: 0.2975 - val_accuracy: 0.9451\n",
      "Epoch 936/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8741 - val_loss: 0.2990 - val_accuracy: 0.9451\n",
      "Epoch 937/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.8718 - val_loss: 0.2967 - val_accuracy: 0.9451\n",
      "Epoch 938/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8836 - val_loss: 0.2971 - val_accuracy: 0.9451\n",
      "Epoch 939/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8689 - val_loss: 0.2964 - val_accuracy: 0.9477\n",
      "Epoch 940/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8810 - val_loss: 0.3003 - val_accuracy: 0.9503\n",
      "Epoch 941/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8816 - val_loss: 0.2981 - val_accuracy: 0.9477\n",
      "Epoch 942/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8790 - val_loss: 0.2934 - val_accuracy: 0.9477\n",
      "Epoch 943/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8865 - val_loss: 0.2909 - val_accuracy: 0.9490\n",
      "Epoch 944/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.8767 - val_loss: 0.2900 - val_accuracy: 0.9503\n",
      "Epoch 945/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8748 - val_loss: 0.2893 - val_accuracy: 0.9516\n",
      "Epoch 946/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8767 - val_loss: 0.2920 - val_accuracy: 0.9503\n",
      "Epoch 947/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.8810 - val_loss: 0.2879 - val_accuracy: 0.9529\n",
      "Epoch 948/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8800 - val_loss: 0.2873 - val_accuracy: 0.9542\n",
      "Epoch 949/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8751 - val_loss: 0.2851 - val_accuracy: 0.9529\n",
      "Epoch 950/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.8842 - val_loss: 0.2810 - val_accuracy: 0.9516\n",
      "Epoch 951/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8787 - val_loss: 0.2811 - val_accuracy: 0.9503\n",
      "Epoch 952/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8816 - val_loss: 0.2835 - val_accuracy: 0.9503\n",
      "Epoch 953/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.8767 - val_loss: 0.2820 - val_accuracy: 0.9490\n",
      "Epoch 954/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8777 - val_loss: 0.2827 - val_accuracy: 0.9477\n",
      "Epoch 955/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8790 - val_loss: 0.2804 - val_accuracy: 0.9477\n",
      "Epoch 956/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8784 - val_loss: 0.2824 - val_accuracy: 0.9464\n",
      "Epoch 957/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.8734 - val_loss: 0.2792 - val_accuracy: 0.9529\n",
      "Epoch 958/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8800 - val_loss: 0.2856 - val_accuracy: 0.9529\n",
      "Epoch 959/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8819 - val_loss: 0.2830 - val_accuracy: 0.9529\n",
      "Epoch 960/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8924 - val_loss: 0.2793 - val_accuracy: 0.9542\n",
      "Epoch 961/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8734 - val_loss: 0.2767 - val_accuracy: 0.9556\n",
      "Epoch 962/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.8823 - val_loss: 0.2794 - val_accuracy: 0.9516\n",
      "Epoch 963/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8898 - val_loss: 0.2777 - val_accuracy: 0.9529\n",
      "Epoch 964/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8842 - val_loss: 0.2734 - val_accuracy: 0.9582\n",
      "Epoch 965/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.8810 - val_loss: 0.2802 - val_accuracy: 0.9516\n",
      "Epoch 966/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8833 - val_loss: 0.2847 - val_accuracy: 0.9516\n",
      "Epoch 967/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8810 - val_loss: 0.2871 - val_accuracy: 0.9503\n",
      "Epoch 968/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8885 - val_loss: 0.2851 - val_accuracy: 0.9503\n",
      "Epoch 969/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8905 - val_loss: 0.2871 - val_accuracy: 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8721 - val_loss: 0.3033 - val_accuracy: 0.9464\n",
      "Epoch 971/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8689 - val_loss: 0.3015 - val_accuracy: 0.9477\n",
      "Epoch 972/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8734 - val_loss: 0.2906 - val_accuracy: 0.9490\n",
      "Epoch 973/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.8852 - val_loss: 0.2881 - val_accuracy: 0.9503\n",
      "Epoch 974/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8842 - val_loss: 0.2833 - val_accuracy: 0.9503\n",
      "Epoch 975/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8836 - val_loss: 0.3006 - val_accuracy: 0.9516\n",
      "Epoch 976/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.8738 - val_loss: 0.2828 - val_accuracy: 0.9516\n",
      "Epoch 977/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.8803 - val_loss: 0.2690 - val_accuracy: 0.9542\n",
      "Epoch 978/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8784 - val_loss: 0.2814 - val_accuracy: 0.9542\n",
      "Epoch 979/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.8800 - val_loss: 0.2773 - val_accuracy: 0.9542\n",
      "Epoch 980/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8829 - val_loss: 0.2744 - val_accuracy: 0.9542\n",
      "Epoch 981/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8751 - val_loss: 0.2767 - val_accuracy: 0.9516\n",
      "Epoch 982/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8872 - val_loss: 0.2739 - val_accuracy: 0.9516\n",
      "Epoch 983/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8852 - val_loss: 0.2910 - val_accuracy: 0.9529\n",
      "Epoch 984/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8774 - val_loss: 0.2664 - val_accuracy: 0.9582\n",
      "Epoch 985/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.8656 - val_loss: 0.2697 - val_accuracy: 0.9516\n",
      "Epoch 986/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8810 - val_loss: 0.2730 - val_accuracy: 0.9503\n",
      "Epoch 987/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8741 - val_loss: 0.2813 - val_accuracy: 0.9477\n",
      "Epoch 988/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.8770 - val_loss: 0.2741 - val_accuracy: 0.9503\n",
      "Epoch 989/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.8784 - val_loss: 0.2721 - val_accuracy: 0.9516\n",
      "Epoch 990/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8731 - val_loss: 0.2708 - val_accuracy: 0.9556\n",
      "Epoch 991/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8888 - val_loss: 0.2726 - val_accuracy: 0.9529\n",
      "Epoch 992/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8882 - val_loss: 0.2786 - val_accuracy: 0.9503\n",
      "Epoch 993/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8911 - val_loss: 0.2782 - val_accuracy: 0.9516\n",
      "Epoch 994/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8921 - val_loss: 0.2746 - val_accuracy: 0.9516\n",
      "Epoch 995/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8829 - val_loss: 0.2772 - val_accuracy: 0.9569\n",
      "Epoch 996/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8950 - val_loss: 0.2777 - val_accuracy: 0.9556\n",
      "Epoch 997/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8914 - val_loss: 0.2759 - val_accuracy: 0.9582\n",
      "Epoch 998/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8764 - val_loss: 0.2738 - val_accuracy: 0.9569\n",
      "Epoch 999/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8826 - val_loss: 0.2730 - val_accuracy: 0.9582\n",
      "Epoch 1000/1000\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8878 - val_loss: 0.2766 - val_accuracy: 0.9529\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.632517</td>\n",
       "      <td>0.117724</td>\n",
       "      <td>5.561979</td>\n",
       "      <td>0.190850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.861509</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>3.928951</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.026229</td>\n",
       "      <td>0.162852</td>\n",
       "      <td>3.078578</td>\n",
       "      <td>0.226144</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.569860</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>2.681707</td>\n",
       "      <td>0.245752</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.997368</td>\n",
       "      <td>0.181491</td>\n",
       "      <td>2.559048</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.450754</td>\n",
       "      <td>0.895029</td>\n",
       "      <td>0.277729</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.455457</td>\n",
       "      <td>0.891432</td>\n",
       "      <td>0.275896</td>\n",
       "      <td>0.958170</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.455572</td>\n",
       "      <td>0.876390</td>\n",
       "      <td>0.273849</td>\n",
       "      <td>0.956863</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.498347</td>\n",
       "      <td>0.882603</td>\n",
       "      <td>0.272981</td>\n",
       "      <td>0.958170</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.445781</td>\n",
       "      <td>0.887835</td>\n",
       "      <td>0.276603</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0    7.632517  0.117724  5.561979      0.190850      0\n",
       "1    5.861509  0.142577  3.928951      0.223529      1\n",
       "2    5.026229  0.162852  3.078578      0.226144      2\n",
       "3    4.569860  0.166122  2.681707      0.245752      3\n",
       "4    3.997368  0.181491  2.559048      0.241830      4\n",
       "..        ...       ...       ...           ...    ...\n",
       "995  0.450754  0.895029  0.277729      0.955556    995\n",
       "996  0.455457  0.891432  0.275896      0.958170    996\n",
       "997  0.455572  0.876390  0.273849      0.956863    997\n",
       "998  0.498347  0.882603  0.272981      0.958170    998\n",
       "999  0.445781  0.887835  0.276603      0.952941    999\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2)\n",
    "model_history = pd.DataFrame(history.history)\n",
    "model_history['epoch'] = history.epoch\n",
    "model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar la fase de entrenamiento, es posible visualizar la evolución del rendimiento de la red neuronal profunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNEAAAHWCAYAAABZkR9hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD3BElEQVR4nOzdd1hURxcG8HfpTUARUSygiAr2HrtGjb13jWKPXaMmttgL0cQSNbGXJHaNmsSOLfYSe+wFxY4VRKQt9/tjPha2we6yywL7/p5nH7lz586dBdTL4cwZmSRJEoiIiIiIiIiIiEgrK3NPgIiIiIiIiIiIKLNjEI2IiIiIiIiIiCgNDKIRERERERERERGlgUE0IiIiIiIiIiKiNDCIRkRERERERERElAYG0YiIiIiIiIiIiNLAIBoREREREREREVEaGEQjIiIiIiIiIiJKA4NoREREREREREREaWAQjciEevbsCV9fX4OunTJlCmQymXEnlMk8fPgQMpkMa9euzfB7y2QyTJkyRXG8du1ayGQyPHz4MM1rfX190bNnT6POJz3fK0RERERZiepzWEZRfYY7evQoZDIZjh49mua1devWRd26dY06H0t43ifKbhhEI4skk8l0eunyHyqZ1rBhwyCTyXDv3j2tfSZMmACZTIarV69m4Mz09+zZM0yZMgWXL18291Q0unnzJmQyGRwcHPD+/XtzT4eIiChbSPpF3b///mvuqWQZ8+bNg0wmw8GDB7X2WbFiBWQyGf76668MnJn+oqOjMWXKlEz3c4VMJsOQIUPMPQ2iLIdBNLJIv//+u9KrYcOGGtsDAgLSdZ8VK1bg9u3bBl373Xff4dOnT+m6f3bQrVs3AMCGDRu09tm4cSNKly6NMmXKGHyf7t2749OnT/Dx8TF4jLQ8e/YMU6dO1RhES8/3irGsW7cOefPmBQBs27bNrHMhIiIiy9W5c2dYWVml+vy3YcMGeHh4oEmTJgbfp3bt2vj06RNq165t8BhpiY6OxtSpUzUG0fi8T5T12Jh7AkTm8OWXXyodnzlzBiEhIWrtqqKjo+Hk5KTzfWxtbQ2aHwDY2NjAxoZ/RatWrYqiRYti48aNmDRpktr506dPIzQ0FN9//3267mNtbQ1ra+t0jZEe6fleMQZJkrBhwwZ07doVoaGhWL9+Pfr27WvWOWnz8eNHODs7m3saREREZCLe3t6oV68etm/fjiVLlsDe3l7p/NOnT3Hs2DH0798/Xc9QVlZWcHBwSO90DcbnfaKsh5loRFrUrVsXpUqVwoULF1C7dm04OTlh/PjxAIA///wTzZo1g7e3N+zt7eHn54fp06dDLpcrjaFa5yqpBtiPP/6I5cuXw8/PD/b29qhcuTLOnz+vdK2mGglJadc7d+5EqVKlYG9vj5IlS2Lfvn1q8z969CgqVaoEBwcH+Pn5YdmyZTrXXTh+/Dg6dOiAQoUKwd7eHgULFsTXX3+t9puynj17wsXFBU+fPkXr1q3h4uICT09PjB49Wu1z8f79e/Ts2RNubm5wd3dHUFCQzksGu3Xrhlu3buHixYtq5zZs2ACZTIYuXbogLi4OkyZNQsWKFeHm5gZnZ2fUqlULR44cSfMemmqiSZKEGTNmoECBAnByckK9evVw/fp1tWvfvn2L0aNHo3Tp0nBxcYGrqyuaNGmCK1euKPocPXoUlStXBgD06tVLsWQ4qR6cpppoHz9+xKhRo1CwYEHY29ujePHi+PHHHyFJklI/fb4vtDl58iQePnyIzp07o3Pnzjh27BiePHmi1i8xMRE//fQTSpcuDQcHB3h6eqJx48ZqS1TWrVuHKlWqwMnJCTlz5kTt2rVx4MABpTlrqoWiWqsk6evyzz//YNCgQciTJw8KFCgAAHj06BEGDRqE4sWLw9HRER4eHujQoYPGunbv37/H119/DV9fX9jb26NAgQLo0aMHXr9+jaioKDg7O2P48OFq1z158gTW1tYIDg7W8TNJRERkmEuXLqFJkyZwdXWFi4sL6tevjzNnzij1iY+Px9SpU+Hv7w8HBwd4eHigZs2aCAkJUfR58eIFevXqhQIFCsDe3h758uVDq1at0qz7evXqVfTs2RNFihSBg4MD8ubNi969e+PNmzdK/ZKeJ+/du4eePXvC3d0dbm5u6NWrF6Kjo5X6xsbG4uuvv4anpydy5MiBli1bany+0OTLL79EREQEdu/erXZu06ZNSExMVKxY+PHHH1G9enV4eHjA0dERFStW1CmrXltNtKTndEdHR1SpUgXHjx9Xu1aX586HDx/C09MTADB16lTF81/SM5CmZ/OEhARMnz5d8XOCr68vxo8fj9jYWKV+vr6+aN68OU6cOIEqVarAwcEBRYoUwW+//Zbm+9aVrs+iISEhqFmzJtzd3eHi4oLixYsrfm5KsmjRIpQsWVLxbFipUqVUMw2JMiuGvYlS8ebNGzRp0gSdO3fGl19+CS8vLwDiB3sXFxeMHDkSLi4uOHz4MCZNmoTIyEj88MMPaY67YcMGfPjwAV999RVkMhnmzJmDtm3b4sGDB2n+Nu3EiRPYvn07Bg0ahBw5cmDhwoVo164dwsLC4OHhAUA8hDVu3Bj58uXD1KlTIZfLMW3aNMV/4mnZunUroqOjMXDgQHh4eODcuXNYtGgRnjx5gq1btyr1lcvlaNSoEapWrYoff/wRBw8exNy5c+Hn54eBAwcCEMGoVq1a4cSJExgwYAACAgKwY8cOBAUF6TSfbt26YerUqdiwYQMqVKigdO8tW7agVq1aKFSoEF6/fo2VK1eiS5cu6NevHz58+IBVq1ahUaNGOHfuHMqVK6fT/ZJMmjQJM2bMQNOmTdG0aVNcvHgRX3zxBeLi4pT6PXjwADt37kSHDh1QuHBhvHz5EsuWLUOdOnVw48YNeHt7IyAgANOmTcOkSZPQv39/1KpVCwBQvXp1jfeWJAktW7bEkSNH0KdPH5QrVw779+/HN998g6dPn2L+/PlK/XX5vkjN+vXr4efnh8qVK6NUqVJwcnLCxo0b8c033yj169OnD9auXYsmTZqgb9++SEhIwPHjx3HmzBlUqlQJgHhInDJlCqpXr45p06bBzs4OZ8+exeHDh/HFF1/o/PlPadCgQfD09MSkSZPw8eNHAMD58+dx6tQpdO7cGQUKFMDDhw+xZMkS1K1bFzdu3FBkjUZFRaFWrVq4efMmevfujQoVKuD169f466+/8OTJE5QrVw5t2rTB5s2bMW/ePKWMxI0bN0KSJMVDOhERkSlcv34dtWrVgqurK7799lvY2tpi2bJlqFu3Lv755x9UrVoVgAi6BAcHo2/fvqhSpQoiIyPx77//4uLFi4ryJO3atcP169cxdOhQ+Pr6Ijw8HCEhIQgLC0t1E6OQkBA8ePAAvXr1Qt68eXH9+nUsX74c169fx5kzZ9SCPR07dkThwoURHByMixcvYuXKlciTJw9mz56t6NO3b1+sW7cOXbt2RfXq1XH48GE0a9ZMp89J27ZtMXDgQGzYsAFt27ZVOrdhwwb4+PigRo0aAICffvoJLVu2RLdu3RAXF4dNmzahQ4cO2LVrl873S7Jq1Sp89dVXqF69OkaMGIEHDx6gZcuWyJUrFwoWLKjoFxkZmeZzp6enJ5YsWYKBAweiTZs2iveRWgmSvn374tdff0X79u0xatQonD17FsHBwbh58yZ27Nih1PfevXto3749+vTpg6CgIKxevRo9e/ZExYoVUbJkSb3etypdn0WvX7+O5s2bo0yZMpg2bRrs7e1x7949nDx5UjHWihUrMGzYMLRv3x7Dhw9HTEwMrl69irNnz6Jr167pmidRhpOISBo8eLCk+tehTp06EgBp6dKlav2jo6PV2r766ivJyclJiomJUbQFBQVJPj4+iuPQ0FAJgOTh4SG9fftW0f7nn39KAKS///5b0TZ58mS1OQGQ7OzspHv37inarly5IgGQFi1apGhr0aKF5OTkJD19+lTRdvfuXcnGxkZtTE00vb/g4GBJJpNJjx49Unp/AKRp06Yp9S1fvrxUsWJFxfHOnTslANKcOXMUbQkJCVKtWrUkANKaNWvSnFPlypWlAgUKSHK5XNG2b98+CYC0bNkyxZixsbFK1717907y8vKSevfurdQOQJo8ebLieM2aNRIAKTQ0VJIkSQoPD5fs7OykZs2aSYmJiYp+48ePlwBIQUFBiraYmBileUmS+Frb29srfW7Onz+v9f2qfq8kfc5mzJih1K99+/aSTCZT+h7Q9ftCm7i4OMnDw0OaMGGCoq1r165S2bJllfodPnxYAiANGzZMbYykz9Hdu3clKysrqU2bNmqfk5SfR9XPfxIfHx+lz23S16VmzZpSQkKCUl9N36enT5+WAEi//fabom3SpEkSAGn79u1a571//34JgLR3716l82XKlJHq1Kmjdh0REZGukv4vO3/+vNY+rVu3luzs7KT79+8r2p49eyblyJFDql27tqKtbNmyUrNmzbSO8+7dOwmA9MMPP+g9T03/r27cuFECIB07dkzRlvSMqvps1aZNG8nDw0NxfPnyZQmANGjQIKV+Xbt21focoKpDhw6Sg4ODFBERoWi7deuWBEAaN26c1rnHxcVJpUqVkj7//HOldtXnjCNHjkgApCNHjiiuy5Mnj1SuXDmlZ8rly5dLAJSeCXR97nz16pXW96v6vJ/0Oevbt69Sv9GjR0sApMOHDyu9F9WvTXh4uGRvby+NGjVK7V6qAEiDBw/Wel7XZ9H58+dLAKRXr15pHatVq1ZSyZIl05wTUVbA5ZxEqbC3t0evXr3U2h0dHRUff/jwAa9fv0atWrUQHR2NW7dupTlup06dkDNnTsVxUlbSgwcP0ry2QYMG8PPzUxyXKVMGrq6uimvlcjkOHjyI1q1bw9vbW9GvaNGiOhdeTfn+Pn78iNevX6N69eqQJAmXLl1S6z9gwACl41q1aim9lz179sDGxkaRmQaIGmRDhw7VaT6ASOl/8uQJjh07pmjbsGED7Ozs0KFDB8WYdnZ2AMSyw7dv3yIhIQGVKlXSuBQ0NQcPHkRcXByGDh2q9JvXESNGqPW1t7eHlZX451Qul+PNmzeKVHZ975tkz549sLa2xrBhw5TaR40aBUmSsHfvXqX2tL4vUrN37168efMGXbp0UbR16dIFV65cUVq++scff0Amk2Hy5MlqYyR9jnbu3InExERMmjRJ8TlR7WOIfv36qdWsS/l9Gh8fjzdv3qBo0aJwd3dX+rz/8ccfKFu2LNq0aaN13g0aNIC3tzfWr1+vOPfff//h6tWradZKJCIiSg+5XI4DBw6gdevWKFKkiKI9X7586Nq1K06cOIHIyEgAgLu7O65fv467d+9qHMvR0RF2dnY4evQo3r17p9c8Uv6/GhMTg9evX+Ozzz4DAI3PM5qe/968eaOY6549ewBA7VlG07OUNl9++SViYmKwfft2RVvSEsCUWeIp5/7u3TtERESgVq1aej+H/fvvvwgPD8eAAQMUz5QAFCVJUjLmc2eSpM/ZyJEjldpHjRoFAGpLWwMDAxU/RwCAp6cnihcvrtPzny5z0eVZ1N3dHYAod5OYmKhxLHd3dzx58kStfA1RVsQgGlEq8ufPr/QfaJLr16+jTZs2cHNzg6urKzw9PRU/aEdERKQ5bqFChZSOkwJqujzsqF6bdH3SteHh4fj06ROKFi2q1k9TmyZhYWHo2bMncuXKpahzVqdOHQDq7y+pLpa2+QCidlW+fPng4uKi1K948eI6zQcQuzRZW1srHpxiYmKwY8cONGnSRCkg+euvv6JMmTKKOiGenp7YvXu3Tl+XlB49egQA8Pf3V2r39PRUuh8gHpzmz58Pf39/2NvbI3fu3PD09MTVq1f1vm/K+3t7eyNHjhxK7Uk7xibNL0la3xepWbduHQoXLqxIv7937x78/Pzg5OSkFFS6f/8+vL29kStXLq1j3b9/H1ZWVggMDEzzvvooXLiwWtunT58wadIkRZ2OpM/7+/fvlT7v9+/fR6lSpVId38rKCt26dcPOnTsV9VzWr18PBwcHRZCWiIjIFF69eoXo6GiNz0UBAQFITEzE48ePAQDTpk3D+/fvUaxYMZQuXRrffPMNrl69quhvb2+P2bNnY+/evfDy8kLt2rUxZ84cvHjxIs15vH37FsOHD4eXlxccHR3h6emp+P9X0/NMWs+zjx49gpWVldIv+QD9nv+aNGmCXLlyKdXO2rhxI8qWLau0XHHXrl347LPP4ODggFy5cimWURrr+c/W1lYpwJnEWM+dKe9vZWWl9syeN29euLu7G/X5T5e56PIs2qlTJ9SoUQN9+/aFl5cXOnfujC1btigF1MaMGQMXFxdUqVIF/v7+GDx4sNJyT6KshEE0olSk/K1Wkvfv36NOnTq4cuUKpk2bhr///hshISGK+g/afgOTkrZdICWVIp3GvlYXcrkcDRs2xO7duzFmzBjs3LkTISEhigL4qu8vo3a0zJMnDxo2bIg//vgD8fHx+Pvvv/Hhwwel30KuW7cOPXv2hJ+fH1atWoV9+/YhJCQEn3/+uU5fF0PNmjULI0eORO3atbFu3Trs378fISEhKFmypEnvm5Kh3xeRkZH4+++/ERoaCn9/f8UrMDAQ0dHR2LBhg9G+t3ShuiFFEk1/F4cOHYqZM2eiY8eO2LJlCw4cOICQkBB4eHgY9Hnv0aMHoqKisHPnTsVupc2bN1f7zTMREZG51K5dG/fv38fq1atRqlQprFy5EhUqVMDKlSsVfUaMGIE7d+4gODgYDg4OmDhxIgICAjSuJkipY8eOWLFiBQYMGIDt27fjwIEDik2KNP2/aupnUkAErzp27IjDhw/j5cuXOH/+PO7evav0/Hf8+HG0bNkSDg4O+OWXX7Bnzx6EhISga9euJn2GMeVzp67Z+xnxNUiLo6Mjjh07hoMHD6J79+64evUqOnXqhIYNGyqe6wICAnD79m1s2rQJNWvWxB9//IGaNWtqXN1AlNlxYwEiPR09ehRv3rzB9u3bUbt2bUV7aGioGWeVLE+ePHBwcMC9e/fUzmlqU3Xt2jXcuXMHv/76K3r06KFoT7nrk758fHxw6NAhREVFKWWj3b59W69xunXrhn379mHv3r3YsGEDXF1d0aJFC8X5bdu2oUiRIti+fbvSw4ch/0H7+PgAAO7evav0m8dXr16p/XZv27ZtqFevHlatWqXU/v79e+TOnVtxrM9yRh8fHxw8eBAfPnxQ+g1g0nLhpPml1/bt2xETE4MlS5YozRUQX5/vvvsOJ0+eRM2aNeHn54f9+/fj7du3WrPR/Pz8kJiYiBs3bqS6kUPOnDnVdmeNi4vD8+fPdZ77tm3bEBQUhLlz5yraYmJi1Mb18/PDf//9l+Z4pUqVQvny5bF+/XoUKFAAYWFhWLRokc7zISIiMoSnpyecnJw0PhfdunULVlZWSgXtc+XKhV69eqFXr16IiopC7dq1MWXKFPTt21fRx8/PD6NGjcKoUaNw9+5dlCtXDnPnzsW6des0zuHdu3c4dOgQpk6dikmTJinatS0b1YWPjw8SExNx//59pewzQ57/li5dis2bNyM0NFSxK3uSP/74Aw4ODti/fz/s7e0V7WvWrDFozoB4359//rmiPT4+HqGhoShbtqyiTdfnTn2f/xITE3H37l1FxhcAvHz5Eu/fvzfa85+uc9H1WdTKygr169dH/fr1MW/ePMyaNQsTJkzAkSNH0KBBAwCAs7MzOnXqhE6dOiEuLg5t27bFzJkzMW7cODg4OGTY+yJKL2aiEekp6Tc+KX/DExcXh19++cVcU1JibW2NBg0aYOfOnXj27Jmi/d69e2p1tLRdDyi/P0mS8NNPPxk8p6ZNmyIhIQFLlixRtMnlcr0DFK1bt4aTkxN++eUX7N27F23btlX6T1fT3M+ePYvTp0/rPecGDRrA1tYWixYtUhpvwYIFan2tra3VfuO3detWPH36VKnN2dkZANSCPJo0bdoUcrkcixcvVmqfP38+ZDKZzvXt0rJu3ToUKVIEAwYMQPv27ZVeo0ePhouLi2JJZ7t27SBJEqZOnao2TtL7b926NaysrDBt2jS138Km/Bz5+fkp1bcDxHby2jLRNNH0eV+0aJHaGO3atcOVK1fUdrRSnRMAdO/eHQcOHMCCBQvg4eFhtM8zERGRNtbW1vjiiy/w559/4uHDh4r2ly9fYsOGDahZsyZcXV0BiJ3jU3JxcUHRokURGxsLAIiOjkZMTIxSHz8/P+TIkUPRR9scAPX/FzU99+gq6f/QhQsXpmvMGjVqwNfXF+vWrcPmzZtRp04dFChQQHHe2toaMplM6f//hw8fYufOnXrPuVKlSvD09MTSpUuVdmNfu3at2vObrs+dSbuF6/r8B6h/jubNmwcAeu80mh66Pou+fftW7dqkX6Qmfc+pft/a2dkhMDAQkiQhPj7eBLMnMh1mohHpqXr16siZMyeCgoIwbNgwyGQy/P777xmaNp2WKVOm4MCBA6hRowYGDhyo+A+wVKlSuHz5cqrXlihRAn5+fhg9ejSePn0KV1dX/PHHH+mqrdCiRQvUqFEDY8eOxcOHDxEYGIjt27frXS/CxcUFrVu31lhQFgCaN2+O7du3o02bNmjWrBlCQ0OxdOlSBAYGIioqSq97eXp6YvTo0QgODkbz5s3RtGlTXLp0CXv37lXL2GrevDmmTZuGXr16oXr16rh27RrWr1+vVjvDz88P7u7uWLp0KXLkyAFnZ2dUrVpVY72vFi1aoF69epgwYQIePnyIsmXL4sCBA/jzzz8xYsQItfoihnj27BmOHDmiVjA2ib29PRo1aoStW7di4cKFqFevHrp3746FCxfi7t27aNy4MRITE3H8+HHUq1cPQ4YMQdGiRTFhwgRMnz4dtWrVQtu2bWFvb4/z58/D29sbwcHBAMT27QMGDEC7du3QsGFDXLlyBfv371f73KamefPm+P333+Hm5obAwECcPn0aBw8ehIeHh1K/b775Btu2bUOHDh3Qu3dvVKxYEW/fvsVff/2FpUuXKv1WuWvXrvj222+xY8cODBw4ELa2tgZ8ZomIiNStXr1asTwypeHDh2PGjBkICQlBzZo1MWjQINjY2GDZsmWIjY3FnDlzFH0DAwNRt25dVKxYEbly5cK///6Lbdu2YciQIQCAO3fuoH79+ujYsSMCAwNhY2ODHTt24OXLl+jcubPWubm6uirqp8XHxyN//vw4cOBAulZalCtXDl26dMEvv/yCiIgIVK9eHYcOHdJpZURKMpkMXbt2xaxZswCIunApNWvWDPPmzUPjxo3RtWtXhIeH4+eff0bRokWV6sXpwtbWFjNmzMBXX32Fzz//HJ06dUJoaCjWrFmj9lyn63Ono6MjAgMDsXnzZhQrVgy5cuVCqVKlNNZrLVu2LIKCgrB8+XJFCZlz587h119/RevWrVGvXj293k9a/v33X8yYMUOtvW7dujo/i06bNg3Hjh1Ds2bN4OPjg/DwcPzyyy8oUKAAatasCQD44osvkDdvXtSoUQNeXl64efMmFi9ejGbNmqnVXCPK9DJqG1CizGzw4MGS6l+HOnXqaN2K+eTJk9Jnn30mOTo6St7e3tK3334r7d+/X2mLbEmSpKCgIMnHx0dxHBoaqnXbcahsfa265XVSH01bUatu1y1JknTo0CGpfPnykp2dneTn5yetXLlSGjVqlOTg4KDls5Dsxo0bUoMGDSQXFxcpd+7cUr9+/aQrV65IAKQ1a9YovT9nZ2e16zXN/c2bN1L37t0lV1dXyc3NTerevbt06dIltTHTsnv3bgmAlC9fPkkulyudS0xMlGbNmiX5+PhI9vb2Uvny5aVdu3apfR0kSf3znbT9fGhoqKJNLpdLU6dOlfLlyyc5OjpKdevWlf777z+1z3dMTIw0atQoRb8aNWpIp0+flurUqaO0FbokSdKff/4pBQYGSjY2NkrvXdMcP3z4IH399deSt7e3ZGtrK/n7+0s//PCDlJiYqPZedP2+SGnu3LkSAOnQoUNa+6xdu1YCIP3555+SJInt3H/44QepRIkSkp2dneTp6Sk1adJEunDhgtJ1q1evlsqXLy/Z29tLOXPmlOrUqSOFhIQozsvlcmnMmDFS7ty5JScnJ6lRo0bSvXv31Oac9HU5f/682tzevXsn9erVS8qdO7fk4uIiNWrUSLp165bG9/3mzRtpyJAhUv78+SU7OzupQIECUlBQkPT69Wu1cZs2bSoBkE6dOqX180JERKSrpP/LtL0eP34sSZIkXbx4UWrUqJHk4uIiOTk5SfXq1VP7v2jGjBlSlSpVJHd3d8nR0VEqUaKENHPmTCkuLk6SJEl6/fq1NHjwYKlEiRKSs7Oz5ObmJlWtWlXasmVLmvN88uSJ1KZNG8nd3V1yc3OTOnToID179kzrM+qrV680vs+Uz1KfPn2Shg0bJnl4eEjOzs5SixYtpMePH6uNmZbr169LACR7e3vp3bt3audXrVol+fv7S/b29lKJEiWkNWvWaHweVX1GOHLkiNrzuyRJ0i+//CIVLlxYsre3lypVqiQdO3ZM7blOn+fOU6dOSRUrVpTs7OyU3rumOcbHx0tTp06VChcuLNna2koFCxaUxo0bJ8XExKi9l2bNmql9LjQ9f2qS2vfk9OnTJUnS7Vn00KFDUqtWrSRvb2/Jzs5O8vb2lrp06SLduXNH0WfZsmVS7dq1JQ8PD8ne3l7y8/OTvvnmGykiIiLNeRJlNjJJykTpM0RkUq1bt051W3QiAtq0aYNr167p/ZtyIiIiIiLK3lgTjSib+vTpk9Lx3bt3sWfPHtStW9c8EyLKAp4/f47du3eje/fu5p4KERERERFlMsxEI8qm8uXLh549e6JIkSJ49OgRlixZgtjYWFy6dAn+/v7mnh5RphIaGoqTJ09i5cqVOH/+PO7fv4+8efOae1pERERERJSJcGMBomyqcePG2LhxI168eAF7e3tUq1YNs2bNYgCNSIN//vkHvXr1QqFChfDrr78ygEZERERERGqYiUZEREREmYJcLseUKVOwbt06vHjxAt7e3ujZsye+++47yGQyc0+PiIiILJxZa6IdO3YMLVq0gLe3N2QyGXbu3JnmNUePHkWFChVgb2+PokWLYu3atSafJxERERGZ3uzZs7FkyRIsXrwYN2/exOzZszFnzhwsWrTI3FMjIiIiMm8Q7ePHjyhbtix+/vlnnfqHhoaiWbNmqFevHi5fvowRI0agb9++2L9/v4lnSkRERESmdurUKbRq1QrNmjWDr68v2rdvjy+++ALnzp0z99SIiIiIzFsTrUmTJmjSpInO/ZcuXYrChQtj7ty5AICAgACcOHEC8+fPR6NGjXQaIzExEc+ePUOOHDm4LICIiIh0JkkSPnz4AG9vb1hZcYNzU6hevTqWL1+OO3fuoFixYrhy5QpOnDiBefPmaewfGxuL2NhYxXFiYiLevn0LDw8PPucRERGRznR9zstSGwucPn0aDRo0UGpr1KgRRowYofUa1Yerp0+fIjAw0FRTJCIiomzu8ePHKFCggLmnkS2NHTsWkZGRKFGiBKytrSGXyzFz5kx069ZNY//g4GBMnTo1g2dJRERE2VVaz3lZKoj24sULeHl5KbV5eXkhMjISnz59gqOjo9o12h6uHj9+DFdXV5PNlYiIiLKXyMhIFCxYEDly5DD3VLKtLVu2YP369diwYQNKliypKN/h7e2NoKAgtf7jxo3DyJEjFccREREoVKgQn/OIiIhIL7o+52WpIJohVB+ukj4xrq6ufLgiIiIivXGZoOl88803GDt2LDp37gwAKF26NB49eoTg4GCNQTR7e3vY29urtfM5j4iIiAyR1nNelgqi5c2bFy9fvlRqe/nyJVxdXTVmoQHaH66IiIiIKHOJjo5Wq0NibW2NxMREM82IiIiIKFmWCqJVq1YNe/bsUWoLCQlBtWrVzDQjIiIiIjKWFi1aYObMmShUqBBKliyJS5cuYd68eejdu7e5p0ZERERk3iBaVFQU7t27pzgODQ3F5cuXkStXLhQqVAjjxo3D06dP8dtvvwEABgwYgMWLF+Pbb79F7969cfjwYWzZsgW7d+8211sgIiIiIiNZtGgRJk6ciEGDBiE8PBze3t746quvMGnSJHNPjYiIiAgySZIkc9386NGjqFevnlp7UFAQ1q5di549e+Lhw4c4evSo0jVff/01bty4gQIFCmDixIno2bOnzveMjIyEm5sbIiIiWCuDiIiIdMZniMyPXyMioqxNkiQkJCRALpebeyqUzVhbW8PGxkZrzTNdnyHMGkQzBz5cERERkSH4DJH58WtERJR1xcXF4fnz54iOjjb3VCibcnJyQr58+WBnZ6d2TtdniCxVE42IiIiIiIiIspfExESEhobC2toa3t7esLOz427YZDSSJCEuLg6vXr1CaGgo/P391TYy0hWDaERERERERERkNnFxcUhMTETBggXh5ORk7ulQNuTo6AhbW1s8evQIcXFxcHBwMGgcw0JvRERERERERERGZGh2EJEujPH9xe9QIiIiIiIiIiKiNDCIRkRERERERERElAYG0YiIiIiIiIiIMglfX18sWLBA5/5Hjx6FTCbD+/fvTTYnEhhEIyIiIiIiIiLSk0wmS/U1ZcoUg8Y9f/48+vfvr3P/6tWr4/nz53BzczPofrpisI67cxIRUXbz8CEwahQQHg506ADUqgWUL2/uWRFRFtf/7/44HHoYEiRIkoQxNcbgq0pfmXtaRETZUqKUiDfRb8w6Bw8nD1jJUs87ev78ueLjzZs3Y9KkSbh9+7aizcXFRfGxJEmQy+WwsUk7DOPp6anXXO3s7JA3b169riHDMBONiIiyh7t3gYMHgcKFge3bgRMngOHDgQoVgH79RJ/4eGDSJKBqVUAmA4oWBebOBSQp4+b56hVw8ybw+HHG3dOYJAm4cwe4fh2IiUn/eJ8+ARMnAi1bAps2ae938ybQtSvQowdw/35y+7NnQI0a4uvp6QkcO5b+ORFp8OzDM9x/dx8P3j1A6PtQvI95b+4pERFlW2+i3yDPj3nM+tIliJc3b17Fy83NDTKZTHF869Yt5MiRA3v37kXFihVhb2+PEydO4P79+2jVqhW8vLzg4uKCypUr4+DBg0rjqi7nlMlkWLlyJdq0aQMnJyf4+/vjr7/+UpxXzRBbu3Yt3N3dsX//fgQEBMDFxQWNGzdWCvolJCRg2LBhcHd3h4eHB8aMGYOgoCC0bt3a4K/bu3fv0KNHD+TMmRNOTk5o0qQJ7t69qzj/6NEjtGjRAjlz5oSzszNKliyJPXv2KK7t1q0bPD094ejoCH9/f6xZs8bguZgKg2hERGR6798DiYmp90lIAF6/Bj580C+oJUlA8+ZAsWJAw4aa+6xcKQIvP/wATJ8OnDsn2u/fB0aPBqysgEaNgJo1RTCmQQMgNFT3OWjy33/AV1+JoN2TJ6Jt/XogTx4gMBAoVAgYNgy4cUNkzk2eLAJsSWJjgXfvdLtXQgIwZw4waBCwcKEIGs6fD0RGpn6drveIiwPevgXkcqB6daB4caBUKcDRUbzPtEiSuE98vHL7gweAkxMwYwbw999Aly7AhQvKfZ4/F5+j+vWBjRuB338Xn7/Bg4G6dYH8+YFTp0Tf16+BevWUP49ERqKajSAhA4PvRESUZY0dOxbff/89bt68iTJlyiAqKgpNmzbFoUOHcOnSJTRu3BgtWrRAWFhYquNMnToVHTt2xNWrV9G0aVN069YNb9++1do/OjoaP/74I37//XccO3YMYWFhGD16tOL87NmzsX79eqxZswYnT55EZGQkdu7cma732rNnT/z777/466+/cPr0aUiShKZNmyL+/8+AgwcPRmxsLI4dO4Zr165h9uzZimy9iRMn4saNG9i7dy9u3ryJJUuWIHfu3OmajykwiEZElN2ZIsvq1i2gUyfAzw9YsyY5QPb6tQjmzJsnAmcA8PXXgIeHyBI6e1bzeIsWAba2oo+rK+DgAPzzjziXkKB9Hm/eiODK7t1pz7lo0dQznQ4cAE6eFB8fOgQUKSKCbmkFopIcOiQCSwEBIhuudGlg+XIRtCtYEPjyS6BnT+VrFi0CSpYUn69p00SArUIFoE0bwMsLyJVLBMYA7V/HqCgRUBozBliyRGTfrVwJjBwJuLmJ4FzKaxMSxPG+fUCBAuIeAwdqHnvfPqBJE8DeXnwNbWyAM2eU+8yYkfrn5cMHoFUrcZ/ixYF//xUBuX79xPePquXLxZ8xMUCdOoC3t/gcpfjNKeLigF9+Sf4eSSkxUcybyMhkMpnScaKUxi8GiIiIAEybNg0NGzaEn58fcuXKhbJly+Krr75CqVKl4O/vj+nTp8PPz08ps0yTnj17okuXLihatChmzZqFqKgonEv6xbAG8fHxWLp0KSpVqoQKFSpgyJAhOHTokOL8okWLMG7cOLRp0wYlSpTA4sWL4e7ubvD7vHv3Lv766y+sXLkStWrVQtmyZbF+/Xo8ffpUEZwLCwtDjRo1ULp0aRQpUgTNmzdH7dq1FefKly+PSpUqwdfXFw0aNECLFi0Mno+pMIhGRJSVffwILFsGrFsnsoSSSBKwebPIqrKyAqpVA54+1X/8ixeBBQtE0CzJjRsiULRli8gk6t1bBFo6dBBBsDFjRGZVzpxA587i+sREETjp0kV5noBYejlsmHJbXJzIMpLJADs78aeNjViG+eSJyFYaNgzInRs4ckT393Ptmn7v/9tvRSBqwwZRV83WFujfX8wvaZ4bN4rAV4MGYonjrVuiLpuq9etTDwgmuXQJ2LkTiIgQx0uWJH8dXV2BpUtF++3bQJkyQI4cyYEnTaZNE8G9Fy8Af3/xHqysxNfs9WvRZ+lSoGlT8X5WrwZWrBDvvUmTtANSmzert718Cfz8s/hecHUVWWaAyO6rXFkE5Fau1Dze8uXA99+LLDdDl2aePm3YdUSpUMtEy8hl4ERElGVVqlRJ6TgqKgqjR49GQEAA3N3d4eLigps3b6aZiVamTBnFx87OznB1dUV4eLjW/k5OTvBL8QvLfPnyKfpHRETg5cuXqFKliuK8tbU1KlasqNd7S+nmzZuwsbFB1apVFW0eHh4oXrw4bt68CQAYNmwYZsyYgRo1amDy5Mm4evWqou/AgQOxadMmlCtXDt9++y1OJa00yGS4sQARUVYlSWL5YlLAoHt3kelVubIIfuzfn9z3zBlR+2vePN3GfvECGD9eZJkBIih25YrIzipZUr3/gQOax1ENsISGAl98IbK2wsOBkBCRuZbW+wRE8O3cOZHVldG6dUv+eMUK8TKHDx9E1tj79yK4lsbDlsKNG0C+fKn32btXZJwZIiJCBBsBkRlXt65y4FVf48YZfi2gni1HZAQyMBONiCijeDh5IHy09gBRRs3BGJydnZWOR48ejZCQEPz4448oWrQoHB0d0b59e8Ql/ZJWC1tbW6VjmUyGxFTKpWjqb+5fAPXt2xeNGjXC7t27ceDAAQQHB2Pu3LkYOnQomjRpgkePHmHPnj0ICQlB/fr1MXjwYPz4449mnbMqBtGIiMzh+nVRt6lWLcDa2rAxlixRz7ipWlUsb0yRqq0wf754pTRliijq/uiRWBoXEyMyiFTrXCUmilpbqjWtDHH4sMjs+uorEXAxtmLFRJH616+BtWtT71ujhljSWKaMKHCf1tLEzCK9QSZjO31aZJy9ewfMnp2+AJoxXL0qsjRVHlqJ0oM10YiIMo6VzAqezvrtUJlVnDx5Ej179kSbNm0AiMy0h5pWMZiQm5sbvLy8cP78ecVySrlcjosXL6JcuXIGjRkQEICEhAScPXsW1atXBwC8efMGt2/fRmBgoKJfwYIFMWDAAAwYMADjxo3DihUrMHToUABiV9KgoCAEBQWhVq1a+OabbxhEIyIyuffvgQkTRNH4wYMBU6ylf/8emDVLBAu++gpo1ky9z7lzIijj7AzMnCl2F1y8WHl5XMOGImPs40ex42FAgFjGJkmiv7u7qAml6uNH8d400RRA02bKFPF5+v33tPsaM/sqZWaXMW3bBrRrl3w8fLhYhqmJszNw/LhYKpmkaVNROJ/006SJuWcgdO4sli5Xqybq6hEZEWuiERGRMfj7+2P79u1o0aIFZDIZJk6cmGpGmakMHToUwcHBKFq0KEqUKIFFixbh3bt3av/faXLt2jXkyJFDcSyTyVC2bFm0atUK/fr1w7Jly5AjRw6MHTsW+fPnR6tWrQAAI0aMQJMmTVCsWDG8e/cOR44cQUBAAABg0qRJqFixIkqWLInY2Fjs2rVLcS4zYU00IjIdSQKePTNNYfvUjBsnio7v3w+0bZv+XRY1mTZNFJ3/+2+gfXsgxdbNiIsTNbGqVhXnN20SBdSbN1evLxUSIupp5cgBVKwodiocNUrsMFiypChQv2WL+v21FYI3hC4BtIxkSNCzc2dRvy1lAA0AypXTvtR09WrlABoggi/79wNDh4qAmpOT/nM5e1YUwV+2TIyjSf36ou5Zx44icDpihP73UVW7tvjey6xF9WfN0rwUeNQokQGpbQnmuXPi35A3b0SWW0pVq4qNGz59En02bhS18ipXNjzDk0gL1eWc5l4SQ0REWdO8efOQM2dOVK9eHS1atECjRo1QoUKFDJ/HmDFj0KVLF/To0QPVqlWDi4sLGjVqBAcdfhFZu3ZtlC9fXvFKqqW2Zs0aVKxYEc2bN0e1atUgSRL27NmjWFoql8sxePBgBAQEoHHjxihWrBh++eUXAICdnR3GjRuHMmXKoHbt2rC2tsam1DYFMxOZZGFPAJGRkXBzc0NERARcXV3NPR2i7EOSxFI/Ozvg6FERmFm9WpwrV04sFUz6OyeXG/4DblJR+g8fRPFxW1vxQ7NninRv1cDIoEFiF0QrA35vEBOTnNGS9B5tbNTn36GDyHiaNy+5WLsxXb4MlC0rPo9ffimK62dGOXOKoF/16mITgTR2GVIzcKAIgIaEiCBWaoX469YVS0+LF0/9+yk2VgSqkoKpefOKDQZ03TL72TNRKN/ZWWQFXrwoCvG/fi3mmdLYsUBwsHLb5s0iyJdSTIx6/bFLl8RyW2dn8X7evRNBsW3bUp/fqFEiCFegQHLbn38CW7eKYG7SjqMNGog+Q4eKv6eFComvVb9+qY9fpIh4v198kXo/bUaPFkuGXV3F36FZs4DvvhPnChQATpwAfHzE8a5dIigdGyuCgn//nfzvBiCuX7xYvKd27cTfuwzEZ4jMz5Rfo87bOmPz9eQ6j9/V+g7TP59u1HsQEVmqmJgYhIaGonDhwjoFccj4EhMTERAQgI4dO2L69Oz5/1tq32e6PkMwiEZE+nv5UtSaio4WP8hu2yayQaytgZo1gVOn1GtnjR8vAiQtW4pggY+PyOa6f18EqXr1EsGN1PzzjwhGvHih3F6woMj+yZdPBF1Uimgq3LsnMsKA5Ow4benKsbHih/ndu4EqVUTG0KhRqc/P1IoUEbthZibLlwN9+4rg5vXrQNGiyXWoPn4UwZKrV4GuXcVujGkVfL9zR+wgCYgg0vnzIhj0/LnI1Dt8WGQdNWoETJ4sgkG6uHxZfI/a24slrMWKGfqONXv4UHz/Fyig/j0VEyOyDW/eFH22bxd/D3QhSeLztnmzGOPOHREgS+nlSyBPHsPmHRkpgtxJAcaFC8Xnf/Bg8b1WpYrYVbRoUbGE+f590a9AAbFketUq7WN37So2s9D09zoqSmRv+vsDLi7K554/F++pTBnDAt8mxGeIzM+UX6Muf3TBpv+SfyM+odYEzPg8i9RRJCLK5BhEy3iPHj3CgQMHUKdOHcTGxmLx4sVYs2YNrly5kimXURoDg2gG4AMwUTolJACBgcrLF3Xl4yMK2GuSP78IhOXPr34uNFTsPJmUUaONr68I2vTtq/m8TCaCBNu3A0eOiNpjXbqIZZm7d4vg39KlgJeX+CE+KylcWHnZamCg2JExPU6cEIGMgQNFIEWTsDDdd8tcvFj78kZABJZUA0TZRXS0qL/m5ycCUunx6pX4frW3F0tfVYNQ+oqMFBsDFC8u/g7p6tEjzf3z5xfBTmMHKjMBPkNkfqb8GnXb3g0brm1QHI+rOQ6z6s8y6j2IiCwVg2gZ7/Hjx+jcuTP+++8/SJKEUqVK4fvvv1dsNJAdMYhmAD4Ak8W6elUEhtzcxA/0tWvrnuVx8SJw8KDI9Dp8OO0dDw1Vvz4wcqQIcq1aJbJgPn0SS+9Iu9hYkZH1778icNasGeDhIXbUdHQUSwJTmjwZ6NNHLO+7cye53cdH1JCrXl0Uilfd2XD4cBGE1HRvXbx7JwJIb9+K4zVrRDBz715RA27ZMrGRAmUdQUHAb78lHz94IAK62RSfITI/U36Nvtz+JdZfS/6FwtgaYxHcIDiVK4iISFcMolFGMEYQjbtzEmU1iYliOWSxYqIYfWqePxf1iDZsUD9XpIioiXT0qDieP18ESV6+FAW8ixUTyyInTRLL4DLCoUPKO0ueO5cx9zWVmTNFraozZ0QgskULkT20ebOonQWIAFT//sC334r6VDt2iGy/s2d1u8eWLclBrEqVxCuJlZVYhrpuXXKbjY3I1CtQALh9W7/3U7q0epuuATRA1Eu7ckUs/y1bVgTOevbUbw6UuSxdCjRuLJastmunXL+MKJuxkin/4kmCRf0emoiIiMBMNHNPh0g/8fEi+BEeLoIxx4+LXeg0OXRIZBrpw8lJLHn8+FHsovf33yLYRvqZPFnU3UqPa9fE8saHD5PbKlQQWT4HDohMwq++Snsny/BwsSvo+fOi9lxwsOE7QUZFie+/iAhx3LcvsGKFYWMRZUF8hsj8TPk1CtoZhN+uJGdeflP9G8xpOMeo9yAislTMRKOMwEw0ouxIkkThfHd3sRTv40dgyRLg2DER1EoSGyuWO4aGqtclev5cFMXXV3R08sfXr6c/gLZ2rekyjYoWBbp1E8s+M3KnSnt78blPTf366b9P6dJiqWV0tAieurgk7xKqjzx5RFbbo0diiWda2YupcXERddIWLhS7VH77reFjERFlMWqZaJb1e2giIiICg2hEpvPhA7BpkwiCdO8O5Mql3ichQfxpYyOWaK5ZAyxapN99ChcWu+Q1aADUrSvafv1V7KSXEapUAVq1ErW0Uu7i0qmTeN+lSgF16ohgoDa6BKZS3m/qVLGEDBDvvWpV8fnT5NQpsWx1yhSxlDA2NnknSU02bBA1uu7dE4G6nTvF1xIAPvtM1H96+VJ8ruVyzWMYK3vP1lbUsEsvmUy/gvGpKVVK7MhJRGRhZFDeeTdRSjTTTIiIiMhcGEQjMpV+/UTtK0Asn4uLE0GRJJMmAQsWiEBakyZiV0JtQZm0zJwpXnnzivpa06ald/Zpa9UK+P57oESJ5DZJErt2RkYC5cqJmlwVKwL374uC9xUrqgeFypYVSw0nTxYbCmir07V5s6jvpcrWFqhZU3MQrWFDoFo18bHqssPISOCLL5Rrj92/LwJgXbokt0VHi9psZcuKml4A4O8vAmnVqysX5gcAa2vxdSAiomyFNdGIiIhIx635iEgvoaHJAbQkpUolf7x3ryjW/+GD2H1y+3bDA2gpvXihOYD2++8iwCVJYnfNsmWBwECxPDRl0fm0rF2bPM7OncoBtCT+/iJYZm2d3OblJYrIu7oCbdoo91+5UgTCZs0Cbt0SY4eFiSWDX3wBFC8OzJihOYCWRNuOjmXKaL/G1RU4eRLYtQs4fVps2KApg8zJSWSdJQXQknh4iPmp8vZWfu9ERJQtMBONiIiIGEQjMoV9+9Tb7twBXr8WH//8c8bNpWxZUTssSb16wOXLYjlj8+ZA167KOzpqM2YMEBSU/vnMnCmCW87OwHffab53wYLA0KHA/v0isDZhQupjaguiffZZ6tdZWwPNmol+MlnqfTVxdlZvK1BA/3GIiCjTY000IiIylbp162JEis2/fH19sWDBglSvkclk2LlzZ7rvbaxxLAWXcxKZguoSvyStWokA2+7d+o3n7Jx6TbHUDBqUeoBIJhPZaT4+wLt3oq1OHbH7Y3y8qFdWtapYcmoMAQGiNpkxqWaJJWnVyrj3UeXiot5WvLhp70lERGYhkzETjYiIlLVo0QLx8fHYpyGJ4vjx46hduzauXLmCMqmtkNHg/PnzcNb0C/t0mDJlCnbu3InLly8rtT9//hw5tf08ZSRr167FiBEj8D6j6nabEINoRKbw8qXm9lOnxDJCXXl6ikysXLnEcsPoaBG40TVrqkQJoEePtPvlyCGWNv78s1iOOGKEWMaYVWjKRPv2W+UadKag6T+20qVNe08iIjIL1eWcrIlGRGRCUiIQ+8a8c7D3AGSpL97r06cP2rVrhydPnqCAyoqUNWvWoFKlSnoH0ADA09NT72sMlZf1nPXC5ZxEpqAtiKaP4sVFjbOkXT2trJIznxYu1H6dra1YstmvH3D0KODgoNv9AgKAxYuB8eOzVgAN0DzfKlVMf19NmWgVKpj+vkRElOFUl3MyE42IyIRi3wDb85j3pUMQr3nz5vD09MTatWuV2qOiorB161b06dMHb968QZcuXZA/f344OTmhdOnS2LhxY6rjqi7nvHv3LmrXrg0HBwcEBgYiJCRE7ZoxY8agWLFicHJyQpEiRTBx4kTEx8cDEJlgU6dOxZUrVyCTySCTyRRzVl3Oee3aNXz++edwdHSEh4cH+vfvj6ioKMX5nj17onXr1vjxxx+RL18+eHh4YPDgwYp7GSIsLAytWrWCi4sLXF1d0bFjR7xM8TP1lStXUK9ePeTIkQOurq6oWLEi/v33XwDAo0eP0KJFC+TMmRPOzs4oWbIk9uzZY/Bc0sJMNCJjk8vF8sj0mjlTBM406dhR7Iz57Jk4/uknoHFjwMZGc3H87K5QIfW2hg1Nf9+qVZWPy5UTy2CJiCjbUV3OyZpoRERkY2ODHj16YO3atZgwYYLi/4qtW7dCLpejS5cuiIqKQsWKFTFmzBi4urpi9+7d6N69O/z8/FBFh1/8JyYmom3btvDy8sLZs2cRERGhVD8tSY4cObB27Vp4e3vj2rVr6NevH3LkyIFvv/0WnTp1wn///Yd9+/bh4MGDAAA3Nze1MT5+/IhGjRqhWrVqOH/+PMLDw9G3b18MGTJEKVB45MgR5MuXD0eOHMG9e/fQqVMnlCtXDv369dP7c5iYmKgIoP3zzz9ISEjA4MGD0alTJxw9ehQA0K1bN5QvXx5LliyBtbU1Ll++DNv/rzoaPHgw4uLicOzYMTg7O+PGjRtw0ZTsYCQMohEZ26JF+vUvUUIs2UypSRP1XSxT8vICrl4Vu0qWKgX4+uo9zWylRAmgenWxXBYAvv5av2WzhipTRgQwly0TmYOLFmkPfBIRUZbGTDQiItKkd+/e+OGHH/DPP/+gbt26AMRSznbt2sHNzQ1ubm4YPXq0ov/QoUOxf/9+bNmyRacg2sGDB3Hr1i3s378f3t7eAIBZs2ahiUrN6u+++07xsa+vL0aPHo1Nmzbh22+/haOjI1xcXGBjY5Pq8s0NGzYgJiYGv/32m6Im2+LFi9GiRQvMnj0bXl5eAICcOXNi8eLFsLa2RokSJdCsWTMcOnTIoCDaoUOHcO3aNYSGhqJgwYIAgN9++w0lS5bE+fPnUblyZYSFheGbb75BiRIlAAD+/v6K68PCwtCuXTuU/n9ZnSImTirhT3tExpSQAKSxi4oSa2tgyhTlNg8PYNu2tIMxHh5id01LD6ABokZcSAiwbh3w11/Ajz9m3L2HDRM7nW7fDuTPn3H3JSKiDMWaaEREpEmJEiVQvXp1rF69GgBw7949HD9+HH369AEAyOVyTJ8+HaVLl0auXLng4uKC/fv3IywsTKfxb968iYIFCyoCaABQrVo1tX6bN29GjRo1kDdvXri4uOC7777T+R4p71W2bFmlTQ1q1KiBxMRE3L59W9FWsmRJWFtbK47z5cuH8PBwve6V8p4FCxZUBNAAIDAwEO7u7rh58yYAYOTIkejbty8aNGiA77//Hvfv31f0HTZsGGbMmIEaNWpg8uTJuHr1qkHz0BUz0YiMaccO4NEj3ft7e4uMs/btReCsbFngzz+zXk2yzMDJCejWzdyzICKibIqZaEREGcjeA2hrWFDGqHPQUZ8+fTB06FD8/PPPWLNmDfz8/FCnTh0AwA8//ICffvoJCxYsQOnSpeHs7IwRI0YgLi7OaFM9ffo0unXrhqlTp6JRo0Zwc3PDpk2bMHfuXKPdIyVblQ3cZDIZEhNN9//ilClT0LVrV+zevRt79+7F5MmTsWnTJrRp0wZ9+/ZFo0aNsHv3bhw4cADBwcGYO3cuhg4dapK5MBONyJiWLFFve/FCLM/UJHduwM4O2LoViI8HLl4EfHxMO0ciomzk4UMgOBjYvFmUpCQyFdZEIyLKQDIrwMHTvK80duZMqWPHjrCyssKGDRvw22+/oXfv3or/N06ePIlWrVrhyy+/RNmyZVGkSBHcuXNH57EDAgLw+PFjPH/+XNF25swZpT6nTp2Cj48PJkyYgEqVKsHf3x+PVJI77OzsIE/jYSkgIABXrlzBx48fFW0nT56ElZUVihcvrvOc9ZH0/h4/fqxou3HjBt6/f4/AwEBFW7FixfD111/jwIEDaNu2LdasWaM4V7BgQQwYMADbt2/HqFGjsGLFCpPMFWAQjSj97twBRo0C5s1LrsmVZN06Ub9MWxAtaedNQGwKwHpaRGRBrl0DVq0CHjww7Pq3b4HChcWmwp07A3PmGHd+lPF8fX0Vu4alfA0ePNjcU1PPRAMz0YiISHBxcUGnTp0wbtw4PH/+HD179lSc8/f3R0hICE6dOoWbN2/iq6++Utp5Mi0NGjRAsWLFEBQUhCtXruD48eOYMGGCUh9/f3+EhYVh06ZNuH//PhYuXIgdO3Yo9fH19UVoaCguX76M169fIzY2Vu1e3bp1g4ODA4KCgvDff//hyJEjGDp0KLp3766oh2YouVyOy5cvK71u3ryJBg0aoHTp0ujWrRsuXryIc+fOoUePHqhTpw4qVaqET58+YciQITh69CgePXqEkydP4vz58wgICAAAjBgxAvv370doaCguXryII0eOKM6ZAn9iJ0qPK1eAChVEAG3UKED1H6L/FzdEr16ar/fQPUWYiCg7OXZM/PPZty/g5yd+53D9OjB6NLBwoUjOTc2LF+r/hI4fz2y0rO78+fN4/vy54hUSEgIA6NChg5lnpqEmGjPRiIgohT59+uDdu3do1KiRUv2y7777DhUqVECjRo1Qt25d5M2bF61bt9Z5XCsrK+zYsQOfPn1ClSpV0LdvX8ycOVOpT8uWLfH1119jyJAhKFeuHE6dOoWJEycq9WnXrh0aN26MevXqwdPTExs3blS7l5OTE/bv34+3b9+icuXKaN++PerXr4/Fixfr98nQICoqCuXLl1d6tWjRAjKZDH/++Sdy5syJ2rVro0GDBihSpAg2b94MALC2tsabN2/Qo0cPFCtWDB07dkSTJk0wdepUACI4N3jwYAQEBKBx48YoVqwYfvnll3TPVxuZZGFPAJGRkXBzc0NERARcM2L3Psre6tUD/r/trkYPHyYvz6xbF/jnH+XzAwcCJvwLTkRkLG/fAvb2QIo6s+lSuTLw77/az48bB8yalXz8/7qyCAgQAbR8+TRf17YtMHQoULOmSPA1Jj5DZLwRI0Zg165duHv3rtpySk1M+TUaEzIGc04lpzt2L9Mdv7X5zaj3ICKyVDExMQgNDUXhwoXh4OBg7ulQNpXa95muzxDMRCMy1P37qQfQAMDNLfljPz/188xEI6IsYMAA8c+Vjw9w+LBu19y6JTLN3NyApF+EJiYCSb+6Sy2ABog6Z0eOiP5TpgCBgeL1zTfA999rv277dqBRI2akZQdxcXFYt26dUl0ZVbGxsYiMjFR6mYpaTTTuzklERGRxGEQjMtTJk2n3yZEj+WNNaRMMohFRJnftGrBsmfj4zRtApQSHmpMngebNRcbYpUtAZCQwYwZQvDhgbQ1UqgSkqBubqs8/B+rXB/6frQ8A+PFH4KefUr+udGmRNUdZ286dO/H+/XulujKqgoOD4ebmpngVLFjQZPNRrYlmYYs5iIiICAyiERnm6lUgKCj1Pq6u4ifGJJqCaEWLGndeRGTxwsOBhATxcVwc8N13QPXqIhCV1J6axERg+XKga1fgt9+Ab79VPn/mDDB7tuZro6KApk2B3bvVzyVtQnXxIlCokO7v58gR3fsmqVRJ/2so81m1ahWaNGmiVFdG1bhx4xAREaF4PdY1QmsA1ZpoiRI3FiAiIrI0Rq4WQmQhdNklLOVSTkD8ZKoqaeMBIqIUxo0DFi0ScfbNm0UWl6qPH4GNG8Umv23aADExQM6cYn+TQoWAvXuB06eBpLqzp08D3t6iTli+fECDBuJjuRzo10+MlSMH4OgIhIWJazTUmwUAjB0rsst+/x1IWRd32TKReWZuDKJlfY8ePcLBgwexffv2VPvZ29vDPoPSDrmck4iIiBhEI8v29q1ItbC2FplluhQhvn0bOHEi7X6qQbRatdT76JOOQUQWYerU5JpfV64ALVoAuXMDnz4B06aJY0kS/6RcuiT6DR0qgm5JwsKAkiXVx+7fP/njsmUBT08xxps3oi0mRvd5RkUBHTsCu3aJudy5I3bWzAwYRMv61qxZgzx58qBZs2bmnoqC6nJOZqIRERkfl8qTKRnj+4tBNLJccrn4afTUKXEcEgL89Vfa1+3apdv47u7Kx2XLAnXqJO/QGRwM6LDTGBFZhqdPxT8PU6Yot9+9K14A0LKl+Gfkw4fkABqgHEDT1ZUrBk9VIT5eFPHPbDQFECnrSExMxJo1axAUFAQbY2+xmg6qyzn5gx4RkfHY2toCAKKjo+Ho6Gjm2VB2FR0dDSD5+80QmefJhCij7dqVHEADgL//Fj+dTpkC1K2rPcB1/rxu43t5KR/LZMCBA8D+/WJDgerVDZk1ERmRJIm6YRmxGkySgG3bgFevgC+/VE58PXECaNxYLNFMS1IcnjQrVQpIx3MRZQIHDx5EWFgYevfube6pKGEmGhGR6VhbW8Pd3R3h4eEAACcnJ607MxPpS5IkREdHIzw8HO7u7rBOWbtcTwyikeUKCVFvO3ZMbAc3dSowaZLm665f1218TYWQ7exE9hsR6eT0abGTY/PmgJOTcce+fFnU83r0CBg4EPj55/Qlh378CKxcKVaH9+0raoOtWQPkzQt07y7qnM2ZI/r+/LPYn8TaWvTTtNrbEuXODbx+rf91pUuLXUTt7LRvekBZxxdffJEps7xYE42IyLTy5s0LAIpAGpGxubu7K77PDMUgGlmuV6+0n5s9G5gwQXl3TUDUQ/vvP+W2OXPUt68DNO/GSUQ6W7pUBLcAsTzv8mVRCN9YJk8WATQAWLIE6NYNqFHDsLH27hW7UiYZOlT5/KxZybtTAsCNG+K9NGsGvHhh2D2zoqpVgQEDxD+bN28qn+vRQ/Ounmnp1EkEK8+eBXx9xYvIFJiJRkRkWjKZDPny5UOePHkQHx9v7ulQNmNra5uuDLQkDKKR5Xr/Xvu56GjxE16pUuL477+B7duBtWvV+2rbHIBBNKJUxcYCVlbal96NGZP88fXrol+9ekCxYmLldefOqWeOxcWJwFXBgur7fADqJRCHDRMJqCVLil0xVT15AvTuLWqXDRwIDBki2uVy5QCaJikDaCkZEjTKambOFFl4Kb9W7dsDq1eL2m4ymchA69ULWLhQfXOCP/4QCbx2dupjjx8vxnZ0FKvwiUyJNdGIiDKGtbW1UYIdRKZglXYXomwqtSAakFz77OhRUc1bUwAN0B5EK1zYwIkRZX87d4pljo6OwPz5mvtERqq3HTkCLFsGdO0KbN0q2q5eBfr0EcGUDx+Sr61cWSzzc3cHvvkGuHcveZzHj9XHvnhRLO/09xeZaSlt2CCCcSEhIots6FAR/GnXDvj3Xz3fvJlpSpzVxdChmleppyZ3bpF5phrsdHERQcsJE0QgrH9/ESTt21c5gPn770DbtpoDrSVLigCdi4v+74XIEMxEIyIiIgbRyDLt3AmcO5d6n969xatevdT7aQuiGboujCibevcOGDUK6NIFaNNGxLHlcmDsWPWYdkJC2uN16iSCM2XLiqym778XxfobNRIBr6tXk/v++KMIuly4II6/+Sb1sQcNEiUSAWDECLHUU5Pt24HPPkt7rhkpb16gQAHxcf78IjCVO7c49vMTQStVFSumPuamTSJL7MkT4Nkz9c2HkxQvDsydKz53a9aIDMJcuXSfu5ub2O/lt9/E7zFSft5XrlTu+/33uo9LZAysiUZERERczkmWJyFB/ISsizVrUj/v7a152WahQsYt3kSUhcXGipphkycrB7aSxMWJgImLi8gscnVNXippiAMHNLfHxQGVKulevL5OHZGVdveu4XPJaH37iuCSh4dy+88/i4BWmTKi1OPEicD06eKcs7PIsDt5Un3fE09PEfRs104cy2Tin7xly0QQM6XgYJHlZvX/X88ZulmCp6fYiEFVjx5iKe3x42KjibSW0BIZGzPRiIiIiD/lk+V5+BB4/tw4Y/32W/JPjCmp/gRLlMWcOwfs2iUSKhs1MnwcuRyoVg24dCn1fitWJC/PBICNGw2/Z1r02f0xKwXQBg0SwTJN7OyA8uWTjydNEsGwBw/EUticOUVg6u+/xdJKuRxYtAjo2FHzeG3bAkFBwJYtQJUqIlMtnRsdpcnWVvumyUQZgTXRiIiIiMs5yfIY46fiYcMASQLq19d83tEx/fcgMpMrV8QSxenTgcaNRWBFm8OHRfk/V1ex3E/V9u1pB9AA5QCapatYEVi3DnjzBtizR/OmCO3bi2WwSZycgO++0/0eNjZic4QffgBKlEhub95cLNd8+VJ7AC3p+rVrxR4sR4+aPoBGlBkwE42IiIiYiUbZW3Q08PatKAwkkwH79hlnDdDIkamfZxCNMrmQEFEQv00b5SAKIJZdpkywmDIleZlfZKQo4H/rlijCP3as+GsGAMOHizFXrADs7UVbaoEYSxIQIDb8Tc3EiWL5aNeuYsklADRpArx6JQJbrVqJAKe/v6jx5uMDfP65aGvXjhsCE5kaa6IRERERg2iUfV28CDRrBrx4ATRoIKpdN2+e/nGPHBE/vaaGQTTKxLZtAzp0EB9PmSICYoULA+HhIuvszz+V+1+8mPzxlCnAL7+Ijw8fVh/799/FK7uqX18kop49C8yapds1crnYNbRECfHPEQDUrStWld++LY4nTQKmTtV8va2t+Cfn/HlREyxvXsDBQZxr2FC8iMj0VJdzMhONiIjI8jCIRtnXpEnJP7EePCi28EuvHDmAypXT7ufllf57Eenp3Ttgwwax30Xr1iL5UpOZM5M/josDpk0D5s0Tu1emVi/s3Ttg/nyjTjnLWLBAZNoladlS1BhLCkZqU7myKJvo5gbcuCE2WAgISK5Pdv++CLIVK5b2HGxtAV9fQ98BEaWX6nJO1kQjIiKyPKyJRtnTo0fA7t1p97O2Fuk3e/eKIlCp+ewzkcLj7Kx+rnNn5eOUxYqITGzTJrEhbK5cYlfLtm1FYOzIEaB3bxFPjokRfRMSgMuXla9fu1Zcm1oALTAQKFrUVO8gdeXKic0JkhQrBty7Z7zxFy0C/vsPqF1b8/lWrZQDaEk+/zztsadMSf44Z06xVDNlgX8/P90CaERkfqrLOZmJRkREZHkYRKPsJTFRZJ3pki0GiPQbT09RPf30abHdnCZ9+4rzX3yh+fysWUCdOmLN1U8/mS/aQJleQgKwZAkwYYLYKDYmBujUSSQ5tmgBvH+v33gREUCvXsDjx8rtU6aIIM+aNWKDAEdH4NgxUbTeEDdvivKC5lC3rlg6Om+eeF8nTojgk2rs+vvvlY+3bhW13YoUSX381q1FFt4//2iOvfv7a77O3T15WWVK3t7in6CZM9O3sykRZS5qmWisiUZERGRxGESj7KVbN1Eg6NWrtPt27iyKG6VkZ6e5b65cqY9VuLDYou7hQ/UxiVIYNw4YNEjEXStVEvXFtmwBoqKAXbtEgC2lxESxDFDTt/SFC0Dp0slZZmmpUwe4ejX978GUunRRDnrJZMDgwSJY9fXXYtMDT09xbtKk5JXT5cuL3Sbfvwf++EME/dq3F+eCg7Xf78oVoECB5GNvb/U+gYGar7WyAsaPV277/XfgyRPg3DlxLmmDACLK+lRronE5JxERkeVhEI2yj1u3xLo2XVhZAatXq7cnbSmoKmdOw+dFmcanTyJRcO5cEbQyNrlclOGLi9N8/tUrsatikjdvgFGjlPuMHw/cvSuCZxs3iiBMyZIisHTggOjz8aN4D5UqqWegZXUbNojA1rffirpjf/6pPbEzIEDUFLt5EzhzBnB1FbXH2rZV3nG0fXvxdU/a7+Ozz0RiqSQBZcooj6kpiJbacsuJE8UmA4cOia//l19qr0VHRFmbaiYal3MSERFZHm4sQNnHnj269/X317yDpqGZaJQldOwosr0AsQvl0aPa+8rlYrfEP/8EatQAfvhBvRzeoUPAihUiwDV4sEhuPHFCBH0OHBAJikmGDRO1t3RRrJjIsHr5MrktKkosDezYUWSuZTbNmokllgsXpt33wAGRTZayNhiQXD/MxQWYPVu3+zo7KwfMNLGyEp9/XZJEPT1FYC0pY69wYaBKldSvSes8EWUPqjXRuJyTiIjI8jATjbKPO3d079uwoeZ2ZqJlW5GRyQE0QNS/Sq04/a5dopbY1atiieWyZcrnr14VgaPNm8VywcBAEUADxLgpg0CXL+seQEuSMoCWUkYF0Nzc9NvQtlo1ke21d2/q/Zo0AerXF5sFvHyZ/FerZk2xKYK5yWRi/5B27cSGAjt2iF0xiYiYiUZERETMRKPs48yZtPv4+AD16onoiCbaMtF8fAyfF2UKHz6ot5UsCVy8KP5M6dUrUWw+pVGjRMBsxgwRgx0zBoiNTT4fGancf9kykQE1dqyoe5ZVeHqK2mmjRolljzdvioyxlO9Vkz59tJ/75x/xOY6MBHx9k5c75skjlrQmJmau2mH+/iKQRkSUEmuiEREREYNolD28fAlcu6b5XKlSwLRpQIMGYgvE1GjLRCtXLl3TI9NJqglWsGDq/aKj1dvi4sReFJcvK7drCwidOyc2aJ05E9i3L+25LVmivlFAZtahg3qmW0CA2Ljg1i0Rp/7tN+DIEeU+q1YBefOKjzXVD6tSRWwM4OGhfk4my1wBNCIibZiJRkRERFzOSVnbhw9ivVX58iKdRZNGjYA2bdIOoAGAjYa4cr582jPUyKxmzxZJgj4+YrfL1Hz8qLn9yhUgIiL5+NUrUS8tNRMm6DfPrGDq1NSXipYoAfTsCRw8KFZOjx0rll9evgz07p3cr0gRsWQzSd++IoBGRJTVsSYaERERMRONsq63b4H8+UWaTGpKl9Z9TE3bKmalVKJs6ONH8aUuUEB518OoKBH4SVpNM22aKO7v5qZ9HG0ePUrepfHwYePM2xAZtWlAnTpid08PDxEQq1VL8z4bmlhZieWOwcHa++zcCWzdKhI727Y1ypSJiMyOmWhERETEIBplXVu2pB1AK1JERCZ0pWm8unX1mhYZz7//As2bi9W6np6i2HtgoAjOjB0LfPqU3Dc2VvSvX1/zWKkF0cqWBcLDxT1S22zA1DZvFsGsX3813T3GjlUOgPn6Gv8ednZimSwRUXbCmmhERETE5ZyUdaWWIdatGzBoEHDypO4pNoDmIJqLi/5zI6OYNSt5l8pXr4ClS4Fhw4CvvgLevVPvv3598sdnzwKbNiVvKJBaEA1IzgC7cSP9806PevXS7pMvn3rb1KlA06bq7SmDWTVrAiNGGDw1IiKLprqck5loREREloeZaJT1PHoE/PUXcPWq9j7r1hk2tqYgGqueZ4i4OFGg/sABsQfEwIGi3J0+1qwRmWq5cwO9eiW358ihueB9Sj//DLRoAWzYoP/cdbV1q6gh5usrCvQfP67ep0kTkWmnbTfMZs1EMPHyZWDoUNG2eLFoHzJEvf+6deKVmCiWYhIRkWFUl3OyJhoREZHlYRCNspbwcFHAKWlLRmNT+S0zpU9iInDoEGBrK+pwqX56JQmIjBTF57dtS27fuVNzQEgX33yj3vbhA3DhQurX3bwpNigwpc8+A9q3Fx+XLi2Ok8ybJ/7Mk0cEE6dMAXLlAlq2BL77TpwbPRr44QfxcYECYqlrSoMHi2BgkpTnGUAjIkof1eWczEQjIiKyPAyiUdYya5bpAmiAWAK6aFHycePGpruXBejZE/j99+Tj/PlFtlf16kDBgsBPP4mAWXbTuzdw6xZw6pRye548yR9XrSqWn27eDFSurBw07NZNeRnm+PGAXK5589iUAgJE8O2HH3TbsZSIiHSnlonGmmhEREQWh7kJlLX89FPafcaPN3z8EiXE9TY2QOHCwIwZho9l4Z4/Vw6gAcDTp2IpYo8eovZXVgygbdoElCuXep+VK0XmXUr164uC+yl17Qr8+afINLO11T6eTJZ2AC3J5Mli59Lr1/XbmJaIiFLHmmhERERk9iDazz//DF9fXzg4OKBq1ao4d+5cqv0XLFiA4sWLw9HREQULFsTXX3+NmLR2aKTsI63llqVLi2Ja6TFzJhAfDzx4AFSsmL6xLMzjx8B//4llmrdumXs2xjdsGNCpE7B7t6hBpo1MJvomLdds1MjwMn1ERJQ5sCYaERERmTWItnnzZowcORKTJ0/GxYsXUbZsWTRq1Ajh4eEa+2/YsAFjx47F5MmTcfPmTaxatQqbN2/G+PRkHlHWkZioPYhWvbqol3bhgigWRSb39Clw7FjyXgy//w74+Yk4ppUV8O235p1fWnTJ0ho1Siw7BQAvr+Qll97ewK5dmuuvde8u/sybFzh9WmwQsG+fOCYioqyLNdGIiIjIrEG0efPmoV+/fujVqxcCAwOxdOlSODk5YfXq1Rr7nzp1CjVq1EDXrl3h6+uLL774Al26dEkze42yiffvRSBNk969AU/P1NfEkdEcOwYULy6WLJYvL7LPevQQCXxJ/v3XfPNLS44cYsOD4GDtfdq1A378Uby306fFxgP+/sp9vvpK/TrVmL7qEk4iIsqaWBONiIiIzBZEi4uLw4ULF9CgQYPkyVhZoUGDBjh9+rTGa6pXr44LFy4ogmYPHjzAnj170LRpU633iY2NRWRkpNKLsqhXrzS3164NfPllxs7FAiUmAq9fiwL38+YBHz+K9lu3jFN7q1494I8/gDFj0j9WasqVA7ZsETHXsWOBAweA2bPFt1ESW1tg6lTxsaurWJaZM6f6WH5+wI4dQNOmwIABwLt3oqweERFlP6yJRkRERGbbnfP169eQy+Xw8vJSavfy8sItLcWUunbtitevX6NmzZqQJAkJCQkYMGBAqss5g4ODMTXpp2HK/CQJOHECiI4GGjQArK2Tz2lKG9qzB6hVC7C3z7g5ZnMREWI/hSdPgKFDxUrZN2+Ahg2BS5dMc8927YBt28THrVqJXSwnTEheKmoMq1cDHTsCzs7K7Q0bilf37sC4ccC9e2LZZsmSuo3burV4ERFR9saaaERERGT2jQX0cfToUcyaNQu//PILLl68iO3bt2P37t2YPn261mvGjRuHiIgIxevx48cZOGPS24QJIiWocWOgQwflc8ePKx/7+ABNmgAuLhk3PwswapRYxrhpE1Czpohl5s5tugCajQ2wdWvysbU1MHIk8OmTiKkePiyywQxx7hxw/rzInuvVSz2AllK+fMDatSKG27mzYfcjIqLsS7UmGpdzEhERWR6zZaLlzp0b1tbWePnypVL7y5cvkVdLBe6JEyeie/fu6Nu3LwCgdOnS+PjxI/r3748JEybAyko9Jmhvbw97ZillDZ8+KWeb7dghtntMquweEaHc38kp4+ZmASIiRABt1arkNkkStcNMaeXK1DddrVcPCA0V+0bExwNlyqj3GTgQWLJEvb1yZePNk4iILJtqJhqXcxIREVkes2Wi2dnZoWLFijiU4if0xMREHDp0CNWqVdN4TXR0tFqgzPr/y/3428Bs4MIF9bZ798SfHz6INYUpbd5s+jllQ5IkMrNUTZigHEDLCOfOAUFBaffLlUvUGitdWuyK2aWLqGN24YLYwODnn00/VyIismyqNdG4nJOIiMjymC0TDQBGjhyJoKAgVKpUCVWqVMGCBQvw8eNH9OrVCwDQo0cP5M+fH8H/z05q0aIF5s2bh/Lly6Nq1aq4d+8eJk6ciBYtWiiCaZSFnT+v3hYVJf7csUP9nOpWiZSm3bvFLpoxMcDcuaIYfhJTB9B69xZ1yQDA3V3ERz089B+nWTPxSouGxFQiIiKDqS7nZCYaERGR5TFrEK1Tp0549eoVJk2ahBcvXqBcuXLYt2+fYrOBsLAwpcyz7777DjKZDN999x2ePn0KT09PtGjRAjNnzjTXWyBj0lSv7s0bUaDrm2+U2wsWBBwcMmZe2YQkAYMHA2/fiuPBg0Um1/XrYm8GYxbx12TIEJF19t9/ohC/IQE0ffDbg4iIjEltYwGugiAiIrI4MsnCngAiIyPh5uaGiIgIuBparZyM58IF4P59ERSrXl39/MiRwE8/qa8/nDYNmDgxY+aYyezaJeqIlSwpPgW6BIskScQh5841/fy0eflS7LppKqp11erXBw4eNN39iMjy8Bki8zPl12jfvX1osr6J4jh/jvx4MvKJUe9BRERE5qHrMwQXPJH5rFsHVKoEdOqkOYAGANu2qQfQGjcGxo41/fwyobt3gRYtgD//BGbNAnRNwjx61HQBtDFjxJckNe3bmzaABqi/vx9+MO39iIjINJ4+fYovv/wSHh4ecHR0ROnSpfHvv/+ae1rqmWisiUZERGRxzLqckyzcqFFp9wkLU2/bsgWwtTX+fLKA6dOVj2fMUG8DRNzx++/FUk0/P9HPFGQyoFs3salqaCiQOzdQtizw8GFynwULxNJRUxs2DIiNBS5eFBsPlC9v+nsSEZFxvXv3DjVq1EC9evWwd+9eeHp64u7du8iZM6e5p8aaaERERMQgGmUwuRxYvBg4dQoID9f/+jlzgBw5jD+vTO7FC2DQIM37K1y+DAQGAnZ2yW1jx4pScqYwdCiQM6cIlHXpInbMBIAiRcSf8+cD3bsD8fEikDd8uGnmocrGBhg3LmPuRUREpjF79mwULFgQa9asUbQVLlzYjDNKxppoRERExCAaZawlS4ARIwy71sEB6NvXqNPJKiZP1hxAA0TGVaFCYslm4cJi4wBTBdD27AGaNEm9T+vWwPv3IojG4v5ERKSPv/76C40aNUKHDh3wzz//IH/+/Bg0aBD69eunsX9sbCxiY2MVx5GRkSabm0zGTDQiIiJLx5polLHmzzf82l69RAqUBYmMBPr0AZYvT71fWJjYf+HFC9PuehkYqFs/a2sG0IiISH8PHjzAkiVL4O/vj/3792PgwIEYNmwYfv31V439g4OD4ebmpngVLFjQZHNjTTQiIiJiEI0y1oMHhl87dKjx5pFFzJkDrF6tW9+ffgKaNTPevT99Ui5b16YN4ONjvPGJiIhUJSYmokKFCpg1axbKly+P/v37o1+/fli6dKnG/uPGjUNERITi9fjxY5PNjTXRiIiIiMs5KeN8/Ji+6wMCjDOPLETX3TeTXLyoe99ixYA7dzSf8/AQmWQ//gh07Ah8+ADUravfXIiIiPSVL18+BKqkPQcEBOCPP/7Q2N/e3h729vYZMTXWRCMiIiIG0SgDbdli+LVVqhhvHhasbl2gXj2gf38gb17R9uKF2FEz5T4PixYlf8xPPRERZZQaNWrg9u3bSm137tyBTyZIhWZNNCIiImIQjTLGnTtA796GXz91qvHmYsGOHFFvy5sX+PtvsRT09Wugdm2gffuMnxsREdHXX3+N6tWrY9asWejYsSPOnTuH5cuXY3laxUEzAGuiEREREWuiUcbQVMtk9Wpg8eK0r23fHmjUyPhzygSuXQMqVABkMvGaPx+Qy0Uwy9irV/v00X6uShXg/n0R6zx6FLC1Ne69iYiIdFG5cmXs2LEDGzduRKlSpTB9+nQsWLAA3bp1M/fUWBONiIiImIlGGURT8a3mzQFJAoYMSf3aIUNEhCmbeP0aGDAAuHEDuHlT+dzIkWJny2vXgFu3Uh+nQAHgyRPt521sgC++ACIigCJFgODg1MdzdRUvIiIic2revDmaN29u7mmoUc1EYxCNiIjI8jCIRhnj6VPlY0dHwNMTSEhI/TpPT+Czz0w3rwxw9Srw3XciqBUcDCxYAGipjwwAGD487TG/+w6YPl28Jk1SP1+jBrBpkwi0ERERUfpZW1krHcsT5WaaCREREZkLg2hkWmfPikyyy5eV27duFX/aaPgWrFMHeP8eiIsD5s0DMmjXLVNITARatwZCQ8Xx/fupZ4/pasoU8efXXwO7dgHnzimf79OHATQiIiJjspapBNEkBtGIiIgsDYNoZDqSBPTqpb5mEQC8vZM/rlEDOHky+Xj5cqBYMdPPLwNcuZIcQANEVlp6ODoCGzeKJZ8A4OICnDkD/PcfMG0acOyYWCXbpUv67kNERETKmIlGREREDKKR6bx5ozmABgD58iV/PGsW0KEDEB4OjB6dbQJoAPD2rXHG6dgRmDwZyJ0byJNH+ZxMBpQunZzcR0RERManmokmQYIkSZBlo7qtRERElDoG0ch0XrzQ3O7qqhwJql0bePxYbEvp6Jgxc8sgHz4YZ5zNm40zDhERERlGNRMNEEs6bWR8nCYiIrIU/F+fjCshAVi9WgTFChXS3KdCBcBKeYcr2NmZfm4ZSJLEqtQBA8w9EyIiIjIG1Uw0QCzptLHi4zQREZGl4P/6ZFydOgHbt6fep2LFjJlLBpAk8Xb/+w/o2hXw9xfthw4xgEZERJSdaMtEIyIiIsvBIBoZz+LFaQfQAJGJlk0sXQoMGiQ+nj0bePhQrFQdPdp495g923hjERERkWG0ZaIRERGR5bBKuwuRDn74ARg6VLe+2SiI9vXXyR9/+gQEB4uPr1wxzvglSwJBQcYZi4iIiAzHTDQiIiJiEI3S7/594Ntvde+fjXbfjI1VPv7zT+OM26sXcO8ecOEC4OVlnDGJiIjIcJpqnyUkJphhJkRERGQuXM5J6SNJQNGiuvdfvVp9U4FsJDQUaNgw/eMMGAD4+aV/HCIiIjIOLuckIiIiBtEoffbs0b3vihUixSqbO3gwfde3bw9UqWKcuRAREZFxOD7eglkegAxiKceeaC7nJCIisjQMolH6zJunW7/ffwe+/NK0c8nkvv4aOHcOcHcHdu9WPrduHVCqFPDhA1CjhlmmR0RERKmwf/Y3xuVKPn6dyEw0IiIiS8MgGunnwQPg+HGgZk0gKgo4fFi361jYC127JsccN28GunUD5HIRPOvQAbCzM+/8iIiISDuZTKZ0bAVmohEREVkaBtFIdzdvAtWrA+/fA9bWQKVK6n08PIA3b9TbCxc2+fQy2vr1uvctUgSoWDH5uFMnETwLCwPq1WMAjYiIKLOTqdREswIz0YiIiCxN9q3wTsY3apQIoAEihersWeXzEycCr18D7dopt/v5Zckq+WFhQKtWoj7Zjh3q5wcO1G2c6tWBkBBA5RfYKFkSaNIEcHBI/1yJiIjItFSDaDIwE42IiMjSMIhGuomNBfbuTb1P7driz3HjlFOrBg5UjyBlAcOHA3/9BZw/LzLHUibY/fSTqF+WllKlgJMnRSYaERERZV0ymfJjs5WMmWhERESWhss5STe3bqXdp0wZ8WfFiqJy/saNQPnyuqdsZTI7dyZ/HB8vVqRu3Ag0b677GLNmGX1aREREZA7MRCMiIrJ4DKKRbq5eTf18wYJAnjzJxw0aiFcWJUnqbR8+6BdAW7ECaNHCeHMiIiIi85FBw8YCzEQjIiKyKFzOSbp58CD18/pEl7KA2Nj0j/HFF+kfg4iIiDIJ1eWcABISE8wzFyIiIjILBtFIN6kVAHNyAkaOzLi5ZIDIyPSPkTt3+scgIiKiTEIliMblnERERJaHyzlJN1FRyseOjsCiRWK3zlatgKJFzTItY/j0CVi3TsQCO3cGrK2NE0Rzckr/GERERJRZqCzn5MYCREREFodBNNLNx4/Kx0OHAn36mGcuRhIdDcjlYiXqsWOibcUK4OhR/YJomzcDQ4YAr16ZZJpERESUGTATjYiIyOJxOSfpRjUTzcXFPPMwkt9/Bzw8AFfX5AAaAPzzDzB8uO5BtHbtgI4dgUmTTDNPIiIiyiy4sQAREZGlYxCNdJMNgmgJCcDNm8Dr18Do0UBMjOZ+CxcC9erpNubPP4s/g4IAT8/k9qVL0zdXIiIiymQ0bCzATDQiIiLLwuWcpJsrV5SPs1gQLTYWaNAAOHHCeGP++y/g5SU+zpEDuHoV+OMPUR6uUSPj3YeIiIgyA+VMNBlrohEREVkcBtEobWFh6gW/slgQbe9e4wbQihQBypVTbsubFxg82Hj3ICIiokyEmWhEREQWj0E0Stuvv6q3ZbEg2syZ6R+jSxeR0ZaQAEybJnbxJCIiIguhaWMBZqIRERFZFAbRKG2aqubb22f8PNLB0TF9148bB0ycmP5xiIiIKKvSsLEAM9GIiIgsCoNoBLx7B9jZAc7O6ufevNF8TRaLJqVnujNnAuPHG28uRERElAVpyERLSEwwz1yIiIjILLg7pyVLSBDbSHp7A25uwOLF6n1atNB8bZUqpp2bkTk56dYvaaOAlAoUMO5ciIiIKCtSyUTjxgJEREQWh0E0S7V7t9hScuBAICYGkMuB4cOBBw/E+cREYOdO4PRp9WvPns1SyzkjIsRb0UWbNuptgYFGnQ4RERFlRdxYgIiIyOIxiGaJJElsIxkTo9yemAj89pv4ePFizRGltWuzVBbalSuAu7tufUeNErtuqipTxqhTIiIioiyJGwsQERFZOgbRLFFYGPDokeZzd+6IINv332s+HxRkunkZ2d9/A+XKpd1v0ybgzBlgzhygZUvlc198IcrFERERkYWTaVjOyUw0IiIii8IgmiW6dk37uSdPgMuXgefP1c9pq4+WSc2fr1u/Tp2AqlUBKyugeHEgOBjw8ADKlwfmzTPtHImIiCirYCYaERGRpWMQzRJdvqz93OPHwPHjms+VLm2S6ZjCkyfAkSOGXTt2LPD6NXDxIlCypHHnRURERFmUaiYamIlGRERkaRhEs0Rnzmg/9/QpcOqU5nO1aplmPkZ26hRQsKC5Z0FERET6mjJlCmQymdKrRIkS5p7W/2nYWICZaERERBbFxtwToAwml2sPkgFAfLzmTLS6dUWBsEzu1SugRg1zz4KIiIgMVbJkSRw8eFBxbGOTSR5XVTLRZGAmGhERkaVhJpqlOXMGePcu9T7Pnikfz54NHDokioZlEnK52ONAJhO7Z96/L9r13fdgyBDjz42IiIgMZ2Njg7x58ypeuXPnNveUBJlKJpoMSEhMMNNkiIiIyBwyT1SETGfVKsDfH6hdW3ysr6CgTBVAA4D9+4HffhMfX7smNgO4fx/Yu1f3MYoWBYYPN838iIiIyDB3796Ft7c3ihQpgm7duiEsLExr39jYWERGRiq9TEd9YwEG0YiIiCxLJsmPJ5N5/Bjo3x9ITATu3dO+aYA2rq5AnjymmZsBjh4FFi0Ctm9Xbl+1CqhSRfdxXrwA3N0Be3tjzo6IiIjSo2rVqli7di2KFy+O58+fY+rUqahVqxb+++8/5MiRQ61/cHAwpk6dmjGT07CxQLw8PmPuTURERJkCg2jZ3dmzIoBmqE6d1B4azeXVK6BhQyBByy99v/pKt3EWLAC8vIw2LSIiIjKSJk2aKD4uU6YMqlatCh8fH2zZsgV9+vRR6z9u3DiMHDlScRwZGYmCJttdSH1jgTh5nInuRURERJlR5lqjR8YXHp6+67//3jjzMIJt27QH0FKzaxdQrpzIPJs8GRg61NgzIyIiIlNwd3dHsWLFcO/ePY3n7e3t4erqqvQyGdWNBWQMohEREVkaBtGys8RE4OXL1Pts2yaiS5q8fg3kymX0aRlKdb8DXdWsCVy6JPZTmDIl05V3IyIiIi2ioqJw//595MuXz9xTgaZMtPhELuckIiKyJAwnZFerVokA2LRp2vtYWQFt2wKOjurnuncHPDxMNz8N5HJg9GjA1xfo2BF4+zb5XHw8YOgO96b8pTQREREZz+jRo/HPP//g4cOHOHXqFNq0aQNra2t06dLF3FNT251TBmaiERERWRrWRMuOIiPFtpMfP6be78ABsRbBwUH9XOnSpplbKubOFS8AePRITGHiROD2baBJEyA0VP8xx47NNCXdiIiIKA1PnjxBly5d8ObNG3h6eqJmzZo4c+YMPD09zT01iLBZMtZEIyIisjwMomVHd+6kHUADgDJlxJ+atqj09jbunNLw6RMwZoxy25kz4s/58w0LoB06BNSrl/65ERERUcbYtGmTuaegnUommpWMu3MSERFZGi7nzI7ev9etX1K9M02ZaBlce2TQIPW2PXuAEyeAZcv0G6thQ7EU9PPPmYVGRERExiJTO4pLZCYaERGRJWEQLTvSNYhmbS3+lCT1cxkcRFu7Vr3N1laUbNPX+vVAzpzpnhIRERFRMtVMNHA5JxERkaVhEC07GjtWv/7v3qm3ZWAQLTZWc3t8PPDqlf7jZYqyKURERJS9yNQz0bick4iIyLKwJlp28/YtcP9+2v1y5Ej++MUL9fNubsabkxYXLgA//SQ2CTWUgwMQE5N8PHhw+udFREREpI6ZaERERJaOQbTsZupU3frlz5/8cZyGB0ATFxOLiABq1RIbCqTH7dtA375ASAhQtiwwfrxx5kdERESkRMPGAgyiERERWRYG0bKT2Fhg4ULd+hYsaNq5pGHDhvQH0Jo2BQoVAg4cEJuROjqmL6uNiIiISDsNGwswiEZERGRRGHLITm7e1L1vyoy1kiWVz/n7G2c+qdBlxWlaUibQOTszgEZEREQmpGFjgfhE1kQjIiKyJAw7ZCc3bqR+3stL/Nm3L/DZZ8ntkycr91u1yrjz0iBlSTZD6bt/AhEREZHhmIlGRERk6bicMzvRlolmZwesXg107AhER6tvGtChA7BuHXD0KNCypShWZmJ2dum7vmVLoG5do0yFiIiIKG2siUZERGTxGETLTlSDaCNGiJejI5Anj2jTtutmt27iZWLPnwPx8cDVq4aPcfMmULy4yfc+ICIiIkqmaTmnnMs5iYiILAmDaNnFwYPAH38ot5UsCfj4mGc+GkyZovvmoanx82MAjYiIiDIal3MSERFZOgbRsoOPH4HGjdXbAwMzfi4aJCQAd+8aJ4AGALa2xhmHiIiISGcaMtEYRCMiIrIs3FggO9i6FZDL1dtVd900gzdvgGrV9IvnbdwI9Owp9kHo0AHImTP5XIcORp8iERERkQ7UM9G4OycREZFlYSZadnDhgnpbhw7a659lkPh44PPPda9/5uwM7N8P1KgBdO6c3B4WBsyfL97ON9+YZq5EREREqeLGAkRERBbP7JloP//8M3x9feHg4ICqVavi3LlzqfZ///49Bg8ejHz58sHe3h7FihXDnj17Mmi2mdSdO+pt8+Zl/DxU9O+vewAtOBh4+lQE0FQVKiSCaFOmiEAbERERUcZTzkTjxgJERESWR+8gmq+vL6ZNm4awsLB033zz5s0YOXIkJk+ejIsXL6Js2bJo1KgRwsPDNfaPi4tDw4YN8fDhQ2zbtg23b9/GihUrkD9//nTPJcu6cAE4cEC5bf16oEAB88zn/xITxbJMXQ0aZPbEOSIiIjKAMZ8NMzWVTDQZgITEBPPMhYiIiMxC7yDaiBEjsH37dhQpUgQNGzbEpk2bEBsba9DN582bh379+qFXr14IDAzE0qVL4eTkhNWrV2vsv3r1arx9+xY7d+5EjRo14Ovrizp16qBs2bIG3T/Le/QIqFRJvT0gIOPnomLxYkDXb4vt2wFXV9POh4iIiEzDmM+GmZqGjQVYE42IiMiyGBREu3z5Ms6dO4eAgAAMHToU+fLlw5AhQ3Dx4kWdx4mLi8OFCxfQoEGD5MlYWaFBgwY4ffq0xmv++usvVKtWDYMHD4aXlxdKlSqFWbNmQa6pqP7/xcbGIjIyUumVbfz9t3pboUJAmTIZP5cUrl0Dhg/Xvb+mOCARERFlDcZ6Nsz8VDYWkDETjYiIyNIYXBOtQoUKWLhwIZ49e4bJkydj5cqVqFy5MsqVK4fVq1dDkqRUr3/9+jXkcjm8vLyU2r28vPDixQuN1zx48ADbtm2DXC7Hnj17MHHiRMydOxczZszQep/g4GC4ubkpXgULFtT/zWZWu3apt3XpAlhbm/S2W7cCuXKJ19at6udDQvQbz5JX4xIREWUX6X02zPQ0ZKIlJCZk/fdFREREOjM4iBYfH48tW7agZcuWGDVqFCpVqoSVK1eiXbt2GD9+PLp162bMeQIAEhMTkSdPHixfvhwVK1ZEp06dMGHCBCxdulTrNePGjUNERITi9fjxY6PPy2w8PdXbunQx6S0TEkT9snfvxGvwYCDu/xtTffoEvHoldtjUVd++gJXZt7cgIiKi9DLHs2HGkmk8kkvaV0QQERFR9mKj7wUXL17EmjVrsHHjRlhZWaFHjx6YP38+SpQooejTpk0bVK5cOdVxcufODWtra7x8+VKp/eXLl8ibN6/Ga/LlywdbW1tYp8i0CggIwIsXLxAXFwc7Ozu1a+zt7WFvb6/PW8w6VDP2rK0BE9eHCwsDXr9OPn71SmwIkDs38ORJ2tcfOQIEBgJLl4pMtv79TTdXIiIiMj1jPRtmehoy0QCxQ6eNld6P1ERERJQF6f0/fuXKldGwYUMsWbIErVu3hq2trVqfwoULo3PnzqmOY2dnh4oVK+LQoUNo3bo1AJFpdujQIQwZMkTjNTVq1MCGDRuQmJgIq/+nL925cwf58uXTGEDL9p4/Vz5eu9bkt0xMVG+LidEtgAaIOF+ePMCkScadFxEREZmHsZ4NMz/lTDSr/x+yLhoREZHl0DuI9uDBA/j4+KTax9nZGWvWrElzrJEjRyIoKAiVKlVClSpVsGDBAnz8+BG9evUCAPTo0QP58+dHcHAwAGDgwIFYvHgxhg8fjqFDh+Lu3buYNWsWhg0bpu/byPri4oD795XbvL1NftvoaMOvdXcHsvovoYmIiEiZMZ8NMzWVTLSkkBp36CQiIrIcegfRwsPD8eLFC1StWlWp/ezZs7C2tkYlPbZa7NSpE169eoVJkybhxYsXKFeuHPbt26fYbCAsLEyRcQYABQsWxP79+/H111+jTJkyyJ8/P4YPH44xY8bo+zaytidPAF9fQHVX0vLlTXZLuRyYPh2YOtWw6318gPnzAQcH486LiIiIzMuYz4aZm+blnMxEIyIishx6l3QfPHiwxuL8T58+xeDBg/WewJAhQ/Do0SPExsbi7NmzSg9gR48exVqVJYrVqlXDmTNnEBMTg/v372P8+PFKNdIsQteu6gG0EiWAnDlNdsv9+w0PoM2bBzx8CLRpY9QpERERUSZg7GfDTEumeWOBeDkz0YiIiCyF3kG0GzduoEKFCmrt5cuXx40bN4wyKUrF9evA8ePq7fXqmfS2s2YZfm1MjPHmQURERJmLxTwbattYgMs5iYiILIbeQTR7e3u1HTUB4Pnz57Cx4c5EJnfzpub2pk1NetsrVwy/NrtujkpERESW9GzIjQWIiIgsnd5BtC+++ALjxo1DRESEou39+/cYP348GjZsaNTJkQbv3mlur1jRpLd1djbsOisrIMtvxkVERERaWcyzobaNBbick4iIyGLo/evBH3/8EbVr14aPjw/K/7+Q/eXLl+Hl5YXff//d6BMkFe/fa27Pm9ekt00riPbTT0CrVoC1tdg0dMgQ4OVLYNKkDNk0lIiIiMzEcp4NubEAERGRpdM7iJY/f35cvXoV69evx5UrV+Do6IhevXqhS5cusLW1NcUcKSVNQbQuXdSK3RpbVJT2c7a2QL9+gKOjOC5QALh2zaTTISIiokzCYp4NtW0swJpoREREFsOgQhXOzs7o37+/sedCutAURPv+e5Pe8v59IDxc+/nx45MDaERERGR5LOPZUCUTjTXRiIiILI7B1V5v3LiBsLAwxMXFKbW3bNky3ZOiVKgG0caOBQoVMtnt4uOBokVT7zNlisluT0RERFlEtn82VMlEU+zOyZpoREREFkPvINqDBw/Qpk0bXLt2DTKZDJIkAQBk/3+wkMvlxp0hAXFxItvs9Glg3z7lc+7uJr31oEEmHZ6IiIiyOMt5NtS8sQAz0YiIiCyH3rtzDh8+HIULF0Z4eDicnJxw/fp1HDt2DJUqVcLRo0dNMEXC8uXA5MnqATTA5EG0lStTPz9xoklvT0RERJmcxTwbastEY000IiIii6F3Jtrp06dx+PBh5M6dG1ZWVrCyskLNmjURHByMYcOG4dKlS6aYp2UbOlT7uf/vgmUOvr5Ar15muz0RERFlApbzbMhMNCIiIkundyaaXC5Hjhw5AAC5c+fGs2fPAAA+Pj64ffu2cWdHqfPyAipXNtnwnz5pbq9bV+y+ee0aULiwyW5PREREWYDFPBvKNG8swJpoRERElkPvTLRSpUrhypUrKFy4MKpWrYo5c+bAzs4Oy5cvR5EiRUwxR8v28aP2cwULqi0tMIbYWCA4GFiwQPP5MWOAUqWMflsiIiLKgizm2VDLck5mohEREVkOvTPRvvvuOyQmJgIApk2bhtDQUNSqVQt79uzBwoULjT5Bi5faUs6cOdM19OnTQEgI8P8vp0JwMDB1KhARoX7NpUtA48bpui0RERFlI6Z8Nvz+++8hk8kwYsQII8w0vTQv52RNNCIiIsuhdyZao0aNFB8XLVoUt27dwtu3b5EzZ07FLkxkJO/fA1u2aD+fK5fBQ0+dCkyZIj5u2xb444/kc7t2ab7G1RUoV87gWxIREVE2ZKpnw/Pnz2PZsmUoU6aMMaaZfsxEIyIisnh6ZaLFx8fDxsYG//33n1J7rly5GEAzhd9+S305p4GZaJIEzJiRfLx9O2BnB3zzDRAXB7x6ZdTbERERUTZlqmfDqKgodOvWDStWrEDOTPMAopKJxppoREREFkevIJqtrS0KFSoEuVxuqvlQSqdPp37ewEy0jx+BBJVfmsbHAz/+CKxfD7x+rfm6TPMMS0RERJmCqZ4NBw8ejGbNmqFBgwap9ouNjUVkZKTSy2RUNxb4/59czklERGQ59K6JNmHCBIwfPx5v3741xXwopTt3Uj9vYFRLU62zJH37AtHRms95eRl0OyIiIsrGjP1suGnTJly8eBHBwcFp9g0ODoabm5viVbBgQaPMQTPNyzk/xqWyaoCIiIiyFb1roi1evBj37t2Dt7c3fHx84OzsrHT+4sWLRpucRZOktINoPj4GDZ1aEE11k4GUunUz6HZERESUjRnz2fDx48cYPnw4QkJC4ODgkGb/cePGYeTIkYrjyMhI0wXSZJo3FvgQ98E09yMiIqJMR+8gWuvWrU0wDVLz5g0QFZV6n88+M2jo1IJo2hQvDrRvb9DtiIiIKBsz5rPhhQsXEB4ejgoVKija5HI5jh07hsWLFyM2NhbW1taKc/b29rC3tzfa/VOnkon2/8PIWBMuISUiIqJMRe8g2uTJk00xD1Klrbp/En9/wMDftOobRFuxAmjdGnB0NOh2RERElI0Z89mwfv36uHbtmlJbr169UKJECYwZM0YpgJbhtNREYxCNiIjIcugdRKMMohpEc3UFhg8Hpk8HPDyAhQsNHlqfIFrbtqJOGhEREZGp5ciRA6VKlVJqc3Z2hoeHh1p7hpMpB/CSjhhEIyIishx6B9GsrKxS3bKcO3caiWoQzdMTmDYNGD9eHOtQJ0QTSQKmTtW9/5dfGnQbIiIishAW82yoGkTjck4iIiKLo3cQbceOHUrH8fHxuHTpEn799VdM1Sc6Q6lbsED52NNT/Glg8AwAEhLEKtCHD3W/hiXwiIiIKDWmfjY8evRouscwCmaiERERWTy9g2itWrVSa2vfvj1KliyJzZs3o0+fPkaZmEVLSABOnFBu8/BI97CHD+sXQKtXD0jlF8tERERElvNsqBJE48YCRERElscq7S66+eyzz3Do0CFjDWfZNEW6cuY0aKiEBGDsWLG7ZqNG+l2r4ZmYiIiISCfZ7tlQpr6pgTUYRCMiIrIkRtlY4NOnT1i4cCHy589vjOHozh31tt69DRpq5kxg9mzDphEUZNh1REREZNmy5bOhhiCajQyIlceaYTJERERkDnoH0XLmzKlUPFaSJHz48AFOTk5Yt26dUSdnsW7dUm+rV8+goRYtMmwK/v6Au7th1xIREZHlsJhnQyvNmWixCQyiERERWQq9g2jz589XelCysrKCp6cnqlatipwGLjkkFUeOKB/36mXwUG/eGHads7PBtyQiIiILYjHPhjL1x2ZrGRAnjzPDZIiIiMgc9A6i9ezZ0wTTIAVJUg+iNWhg0FC//mr4ND5+NPxaIiIishwW82yopSbaJwbRiIiILIbeGwusWbMGW7duVWvfunUrfk1P1IaE9+/VI1jVqxs01JAhhk8jKsrwa4mIiMhyWMyzoZYgWpw8DpIkZfx8iIiIKMPpHUQLDg5G7ty51drz5MmDWbNmGWVSFu3lS/W2vHkNGio9gTAG0YiIiEgXFvNsqCmIJgMkSJBLcjNMiIiIiDKa3kG0sLAwFC5cWK3dx8cHYWFhRpmURQsPVz52dQUcHPQe5ty5tPtMnQosXqz5nI1R9m0lIiKi7M5ing21ZKIB3FyAiIjIUugdRMuTJw+uXr2q1n7lyhV4eHgYZVIWTTUTzcvLoGHmz0+7j7s7MHgwMHKk+rm5cw26LREREVkYi3k21JKJBnBzASIiIkuhdxCtS5cuGDZsGI4cOQK5XA65XI7Dhw9j+PDh6Ny5synmaFmWL1c+NjCItmlT2n0SEsSf/fsrtwcEAO3bG3RbIiIisjAW82yYSiYag2hERESWQe9Fe9OnT8fDhw9Rv3592Px/zV9iYiJ69OiRvepemMPVq8DBg8ptBtZD08X79+LP4sWBd++AW7eAggWBfPkAK73Dq0RERGSJLObZkJloREREFk/vIJqdnR02b96MGTNm4PLly3B0dETp0qXh4+NjivlZlt9/V28rWtSgoQoVAtIqQ+LomPyxuzvw2WcG3YqIiIgsmMU8G6ZWE03OmmhERESWwODy8f7+/vD39zfmXOj4cfW2fPkMGioyUr3N0RH49El8LJMBPXoYNDQRERGRmmz/bMjlnERERBZP70V77dq1w+zZs9Xa58yZgw4dOhhlUhYpKkrzlprly+s9VGIiEBGh3Hb+PHDlClC3rkhuW74cyJ/fsKkSERERJbGYZ0OZ+mMzl3MSERFZFr2DaMeOHUPTpk3V2ps0aYJjx44ZZVIWJyZGBMskSf1c9ep6D/f2rfpQefIA/v7AkSPA3btA374GzpWIiIgoBYt5NpTJ1AJpzEQjIiKyLHoH0aKiomBnZ6fWbmtri0hNawgpbZs2Affuqbf/+CNgrb50IC0NGqi35cxpwLyIiIiI0mBRz4YqSzqZiUZERGRZ9A6ilS5dGps3b1Zr37RpEwIDA40yKYuzZInm9lKl9B7q+XOxbFOVi4veQxERERGlyaKeDVWDaP//MzaBGwsQERFZAr03Fpg4cSLatm2L+/fv4/PPPwcAHDp0CBs2bMC2bduMPkGLkFTtPyUbG6BaNb2HevRIc7tMpvdQRERERGmyqGdDZqIRERFZNL2DaC1atMDOnTsxa9YsbNu2DY6OjihbtiwOHz6MXLlymWKO2Z+mIFqZMoCrq95DffxohPkQERER6ciing21ZKIxiEZERGQZ9A6iAUCzZs3QrFkzAEBkZCQ2btyI0aNH48KFC5DL5UadoEWIilJvM3CL+Bs31Nv69zdoKCIiIiKdWMyzIYNoREREFk3vmmhJjh07hqCgIHh7e2Pu3Ln4/PPPcebMGWPOzTLExAAvXqi316mj91CSBAwbpt4+ZIgB8yIiIiLSg0U8G2pZzvkh7oMZJkNEREQZTa9MtBcvXmDt2rVYtWoVIiMj0bFjR8TGxmLnzp3Zr3BsRnn4UL3Nzg7o0UPvocLCNLeXLq33UERERERpsrhnQy2ZaM8/PM/4uRAREVGG0zkTrUWLFihevDiuXr2KBQsW4NmzZ1i0aJEp52YZHjxQb7t+HXB21nuop0+NMB8iIiIiHVjks6GWTLRnH56ZYTJERESU0XTORNu7dy+GDRuGgQMHwt/Ael2kwf79ysdVqwJFixo01M8/q7c1aWLQUERERESpsshnQ5UgWtKD9PMoZqIRERFZAp0z0U6cOIEPHz6gYsWKqFq1KhYvXozXr1+bcm7Z38ePwMKFym1Fihg01L17wIYN6u0DBhg0HBEREVGqLPLZUEsm2tMPXA5ARERkCXQOon322WdYsWIFnj9/jq+++gqbNm2Ct7c3EhMTERISgg8fWFBVb3v3qrd5eRk01Pr1mttbtDBoOCIiIqJUWeSzoZaaaK+js3nwkIiIiAAYsDuns7MzevfujRMnTuDatWsYNWoUvv/+e+TJkwctW7Y0xRyzr0uX1NvKlDFoqOcaVhEsWwbIZAYNR0RERKQTi3o2tFKuhJKUiRYRE2GGyRAREVFG0zuIllLx4sUxZ84cPHnyBBs3bjTWnCzHjRvqbW3aGDTU+/fqbd27GzQUERERkUGy/bOhlky0iNgISJKU8fMhIiKiDJWuIFoSa2trtG7dGn/99ZcxhrMcd+8qH48fD7i7GzRUhMovQGfPBhwdDZsWERERUXpk22dDLTXREhITEB0fbYYJERERUUYyShCNDCBJQGioctsXXxg81L59ym1ubgbOi4iIiIg005KJBohsNCIiIsreGEQzl9evgWiV31j6+uo9TGys5r0IDExoIyIiIiJtUguisS4aERFRtscgmrk8eKB8bGMDFCig9zBbtgCvXqm3M4hGREREZGRalnMCwPuY9xk7FyIiIspwDKKZy/nzysdFigDW1pr7puLvvzW3OzsbMCciIiIi0o7LOYmIiCwag2jmcuaM8vFnnxk0jFyuud3b26DhiIiIiEibVDLRnkY+zeDJEBERUUZjEM1cVDcVqFTJoGFUd+UERDyucGGDhiMiIiIibVLJRLv7VmXXdSIiIsp2GEQzl5cvlY8NTB17/lz5uGpVICQEkMk09yciIiLKrJYsWYIyZcrA1dUVrq6uqFatGvbu3WvuaSWT2Sgd2qR43mIQjYiIKPtjEM1cVINomrbY1MGzZ8rHs2YBLi4GzomIiIjIjAoUKIDvv/8eFy5cwL///ovPP/8crVq1wvXr1809NcHKTunQLkUQ7eH7hxk7FyIiIspwNml3IaOLjgaiopTbDAiiffoEvH+v3JYvn+HTIiIiIjKnFi1aKB3PnDkTS5YswZkzZ1CyZEkzzSoFa5UgWoqPuTsnERFR9scgmjmEh6u35cmj9zAvXqi3cUMBIiIiyg7kcjm2bt2Kjx8/olq1ahr7xMbGIjY2VnEcGRlp2klZ2Ssd2qfIRIuI4e6cRERE2R2Xc5qDaiEze3vA1VXvYVSXcjo6GjQMERERUaZx7do1uLi4wN7eHgMGDMCOHTsQGBiosW9wcDDc3NwUr4IFC5p2cqks54yIjYAkSaa9PxEREZkVg2jm8PCh8nGhQgbtBKAai/P25oYCRERElLUVL14cly9fxtmzZzFw4EAEBQXhxo0bGvuOGzcOERERitfjx49NOzlr7ZloCYkJ+JTwybT3JyIiIrPick5zCA1VPvb1NWgY1Uw01kMjIiKirM7Ozg5FixYFAFSsWBHnz5/HTz/9hGXLlqn1tbe3h729vVq7yaSSiQaIJZ1Otk4ZNx8iIiLKUMxEM4c//1Q+NjCIdvOm8jHroREREVF2k5iYqFT3zKxSqYkGiCWdRERElH0xEy2jPXoEnD+v3FasmN7DhIQAS5cqtzETjYiIiLKycePGoUmTJihUqBA+fPiADRs24OjRo9i/f7+5pyaoZKI5WlsDkCuOubkAERFR9sYgWkY7fhxQLTrbvbvew0ybpt7GTDQiIiLKysLDw9GjRw88f/4cbm5uKFOmDPbv34+GDRuae2qCSk00F2tbpAyivfn0JoMnRERERBmJQbSMdvas8nHTpoCXl97DnDun3sZMNCIiIsrKVq1aZe4ppE5lOaebrQOAGMXxnTd30NS/aQZPioiIiDIKa6JltDt3lI8/+0zvIT59AuLi1NsLFzZwTkRERESUNpXlnDntnJWOb72+lZGzISIiogzGIFpGU92Z089P7yFevFBvK1IEqF7dwDkRERERUdpUlnO62jooHd98rbLrExEREWUrmSKI9vPPP8PX1xcODg6oWrUqzmlaq6jBpk2bIJPJ0Lp1a9NO0FgSE8XGAikZkD6mui8BAFy/Dlhliq8mERERUTalkomWw0b5mJloRERE2ZvZwy6bN2/GyJEjMXnyZFy8eBFly5ZFo0aNEB4enup1Dx8+xOjRo1GrVq0MmqkRPH+uvg7T11evISQJGD1aua1IEcDBQXN/IiIiIjISlZpoTtbK5YXDP4bj7ae3GTkjIiIiykBmD6LNmzcP/fr1Q69evRAYGIilS5fCyckJq1ev1nqNXC5Ht27dMHXqVBQpUiQDZ5tODx8qH9vb672pwIIFwOPHym1cxklERESUAVQy0RysAFsrW6W2269vZ+SMiIiIKAOZNYgWFxeHCxcuoEGDBoo2KysrNGjQAKdPn9Z63bRp05AnTx706dMnzXvExsYiMjJS6WU2qvXQfH31XoO5fbt625w5hk+JiIiIiHSkUhNNlhiPQm6FlNqefniakTMiIiKiDGTWINrr168hl8vhpZKN5eXlhReaqucDOHHiBFatWoUVK1bodI/g4GC4ubkpXgULFkz3vA2mmomm51JOAHirskKgc2cgXz6DZ0REREREulLJRIM8Ft45vJWann14loETIiIiooxk9uWc+vjw4QO6d++OFStWIHfu3DpdM27cOERERChej1XXQmYk1Uw0AzYV+PhR+bhr13TMh4iIiIh0p1ITDYlxakG0p5HMRCMiIsqubNLuYjq5c+eGtbU1Xr58qdT+8uVL5M2bV63//fv38fDhQ7Ro0ULRlpiYCACwsbHB7du34efnp3SNvb097O1VHnjMxQiZaKpBNGdng2dDRERERPqwcVQ+TviI/K75lZqeRTETjYiIKLsyayaanZ0dKlasiEOHDinaEhMTcejQIVSrVk2tf4kSJXDt2jVcvnxZ8WrZsiXq1auHy5cvm3eppi401UTTk2oQzcXF8OkQERERkR7sPJSP49+jYA7lX/xeen4pAydEREREGcmsmWgAMHLkSAQFBaFSpUqoUqUKFixYgI8fP6JXr14AgB49eiB//vwIDg6Gg4MDSpUqpXS9u7s7AKi1Zzrx8cCjR8ptei7nlMuBT5+U25iJRkRERJRBHDzVmmp6lVA6vv7qOp59eKa2zJOIiIiyPrMH0Tp16oRXr15h0qRJePHiBcqVK4d9+/YpNhsICwuDlZ47WGZK+/YB/196qqBnEC06Wr2NQTQiIiKiDGLnAUAGQFI0lc9ZAE62ToiOT35Qe/DuAYNoRERE2ZDZg2gAMGTIEAwZMkTjuaNHj6Z67dq1a40/IVM4fFj5uGxZwFP9t5mpUV3KCTCIRkRERJRhrKwB+1xA7BtFk3XcG+RxzoOH7x8q2t5Ev9FwMREREWV12SDFK4t4+1b5uG5dvYdgEI2IiIjIzOxVfgka8woejsq10t5+UnnuIyIiomyBQbSM8uGD8nGuXHoPoRpEk8kAx/+1d+dxNpb/H8dfZ2bMvjLMDIaxZd+3r10oW4WUiCyRn6JvKiUt0iKKpFWbaKX0RYqoRJbsOzH23czYZjf7/fvjzuHMYgbnzDG8n4/HeTT3dV/3dX/OfUYun3MtXrnXFREREREH8Ai2PU47R3Ev237d2QsaiSYiInIzUhKtsMTH2x77+V11E9mTaD4+ZiJNRERERApJMX/b4/QESnjbjkTTdE4REZGbk5JohSX7SLRrSKJFR9se+/peRzwiIiIicvWKBdgep8dT3NN2JNrE1ROJSYopxKBERESkMCiJVliyJ9H8/XOvdwUbN9oeV69+HfGIiIiIyNXLMRItPsdINIB31rxTSAGJiIhIYVESrbDYYTrnpk22x02aXEc8IiIiInL1ckmiNSvbLEe1lUdXFlJAIiIiUliURCss1zmd8+xZWLzYtqx27euMSURERESuTvYkWkY8nSp3ommZpjbF26O3YxhGIQYmIiIijqYkWmEwjJwj0a5iOuePP0JwcM7yiIjrC0tERERErlIuI9EsFgtz7p9jU5yQlsCu07sKMTARERFxNCXRCsOUKTnLCjgSLTkZhgzJ/Vz58tcRk4iIiIhcvexJtLQ4AMr6lyXcP9zm1Pw98wspKBERESkMSqI5WloajBqVs7yASbS9eyEuLvdzYWHXEZeIiIiIXL0cu3OaHTWLxUL3at1tTs3dPbeQghIREZHCoCSao23Zknt5AZNop0/nXn7nneDqeo0xiYiIiMi18ci2E2dKtPXHHtV62JzaErUFnzd8WHZoWWFEJiIiIg6mJJqjrVuXe7mHR4EuP3MmZ9n998Pnn19HTCIiIiJybbzK2B5nJEK6ufZtq/Kt8HO3/aI0OT2Zob8M1SYDIiIiNwEl0Rxt797rujx7Eq11a/jhBwgPz72+iIiIiDiQV+mcZcknAHBzcaNJmSY5Tu8/t5+41DzW5xAREZEiQ0k0Rzt8+Louz55Ey22XThEREREpJG5e4B5kW3bhhPXH3JJoANGJ0bmWi4iISNGhJJqjHTp0XZcriSYiIiJyg/Eua3t8fqv1x5ola+Z6ycaTGx0YkIiIiBQGJdEc7ciRa740IwM++si2TEk0EREREScLbmZ7fHKR9ceapXJPovWb18+REYmIiEghUBLNkVJTISnpmi//+uucZSVLXkc8IiIiInL9SnexPT67HrIyAahVqhbVg6vnetnc3XMdHZmIiIg4kJJojhQff12XP/ZYzjKNRBMRERFxsuwj0TKSIG4XYG4u8GOvH3O9rOcPPR0dmYiIiDiQkmiOFJfHLkyvv16gy1NScpYpiSYiIiLiZJ6lwKe8bdnuSdYfa5SswY5Hd+R6qTYYEBERKbqURHOk3EaitWkDQ4fme2liYu7lSqKJiIiI3ADKdrc9PvwNrBkIWRmAOa1zYL2BOS4LfTuU7dHbHR6eiIiI2J+SaI6UfSRaiRKwfHmBFjaLisq9vHjx6w9LRERERK5TleE5yw59CbvGWw8n3TEpZx2g87edyTKyHBWZiIiIOIiSaI6UPYnm71/gS0+fzr08NPQ64hERERER+/CvAuX75CzfMQ7idgMQ7B3MkPpDclQ5mXAS11dd2Rmz08FBioiIiD0pieZI2adzBgQU+NLckmgjR4K39/WFJCIiIiJ20vSznNM6ARbWgH9Hmt1T9Z48L+/9Y28y/p3+KSIiIjc+JdEcKftItOtMok2Zcp3xiIiIiIj9uPlA63lQ5u6c585uAKBzlc40Kt0o18t3nd5F2NthJKQmODJKERERsRMl0Rwp+0i0q5jO+f77tsedOoHFYoeYRERERG5QEyZMoHHjxvj5+VGqVCm6d+9OZGSks8PKX6WcUzYvJtHcXNz4a+Bf3FnpzlwvPZN8hjdXv+nI6ERERMROlERzpGsciZaZCTuy7YpeqpSdYhIRERG5Qf31118MHz6ctWvX8vvvv5Oens6dd95JUlKSs0O7srK5TNk8v9n6o3cxb+bcP4cQn5BcLx+/cjy/7P2F9Mx0R0UoIiIidqAkmiNdYxLt/HnIyrZhU/36dopJRERE5Aa1ePFiBg4cSM2aNalbty4zZ87k6NGjbNq0ydmh5a/+ZNvjxAM2h/4e/qwdspZX2r6S6+V3z7qbwQsGYxiGoyIUERGR66QkmiNd43TO2NicZUOHXn84IiIiIkVJ3L9fSBYvXjzX86mpqcTHx9u8nMa3ou1x4sEcVSICIxjbZiynnj6VaxNfb/+a+XvmOyA4ERERsQcl0RzpOkaiXc7dHby87BSTiIiISBGQlZXFyJEjadGiBbVq1cq1zoQJEwgICLC+wsPDCznKy/hWsD1OPgHJx3OtGuobyoxuM3I913duX1YeWWnv6ERERMQOlERzJDuNRAsM1KYCIiIicmsZPnw4O3fuZPbs2XnWGTNmDHFxcdbXsWPHCjHCbHwrApd32AyYHw7bXoCMnGu6Daw3kHuq5lxL7ULGBVrPbM34FeM1tVNEROQGoySaI2XfTaqAI9FyS6KJiIiI3CpGjBjBL7/8wrJlyyhbtmye9Tw8PPD397d5OU0xfwjvmbN81xuwoDJk5dw04P3O7+NTzCfX5l5c9iIur7rQ9buuHI49bOdgRURE5FooieYoMTFw5oxt2TUm0YKC7BOSiIiIyI3MMAxGjBjBvHnz+PPPP6lQoUL+F91IGn8EfrflLE+JgtnukGa7Zke5gHIcfOIg3/T4Js8mF+1bxJNLnrR3pCIiInINlERzlJ9+yllWwCTa1q22xxqJJiIiIreC4cOH88033/Ddd9/h5+dHVFQUUVFRXLhwwdmhFYxnSWj3G3iVyf38gkoQt9umqJRPKfrW6cudle7Ms1ltNiAiInJjUBLNUQ4fzlnWsOEVL3nzTXMDgY8+si3PY0MqERERkZvKtGnTiIuLo23btoSFhVlf33//vbNDKzif8tB5M5RokvNc2nlYWAO2Ppdj04H7a9x/xWY/2vARW6O22jFQERERuVpKojnKqWxbl7doccUtNtesgeeeg5SUnOdatLBzbCIiIiI3IMMwcn0NHDjQ2aFdHc9ScOdaKNsj9/P/vAm/t4KUS0t/DKo3iBbheXf6hi8aToNPGmhUmoiIiBMpieYo2ZNoXbrkWTUzE5o3z7upBx+0U0wiIiIiUjgsFmg9FxpMyf180mHY/CT8uwOnq4srb9/59hWbNDDo8X0PjsU5cRdSERGRW5iSaI6SPYkWFpZn1ZdeyruZDh20sYCIiIhIkVXtSaj9Su7nDn8DW56xHjYu05hapWrl22S5qeU4GnfUXhGKiIhIASmJ5ijR0bbHoaF5Vp01K+9m7r3XTvGIiIiIiHNUewo8Q3I/t+dtiPwAABeLC8sHLOetDm8RERhxxSbLTy2P8e8oNhERESkcSqI5SkKC7XEeW2waRu57EFxksdgtIhERERFxhmK+0Pon8C6b+/lNj8OhbwAo4V2CZ1o8w+ahmwn2Dr5is92/727nQEVERORKlERzhKwsSE62LfPxybVq9lxbdu3b2ykmEREREXGe4KbQ7QjcGwNVHst5fs1D5oYD/wryCmLr/22lrH8eiTdgQeQCLK9Y6PlDT47GHWX65uk8veRptkdvd8Q7EBERueVZjFtsHHh8fDwBAQHExcXh7+/vmJskJYGvr23ZgQNQsWKOqnv2QPXquTfTty98840D4hMREZGrVih9CLkuReYzMgz4qTwk57JBQKv/Qfi9l1U1WHl0JW1mtilw8z7FfDj4xEFK+ZSyR7QiIiI3vYL2ITQSzRESE3OWZU+q/Sv7/gMA+/bB5s3w9dd2jktEREREnM9igTvXgG+lnOfWDIDUs5dVtdC6fGuMlw2m3zO9QM0npSfx4z8/2itaERER+ZeSaI6QlJSzLJfpnFlZ8MILtmVVq0LlylC/vtZDExEREblpeZeBuyIhop9teUYi/C8Y0mJzXPJw/YdZPmB5gZr/bsd31p+3Rm3lzVVvsvro6usIWERERNycHcBNKftINIsFvLxyVHvlFVizxrYsKMiBcYmIiIjIjcPFFZp9CQn74Ow623MrekCHZTkuaRNRsGmdq4+txvJKzm9kqwVX4+0736ZLlS7XFLKIiMitTCPRHCH7SDQfH3CxfdQJCfDqqzkvvZGX7xARERERO7O4wH++yFkesxxSTud6yTsd37nm2+05s4eu33Xlr8N/XXMbIiIityol0Rwh+0i0XKZybtiQ+6VKoomIiIjcYgJqQNnuOcsXVISN/4W9H0FWprV4RJMRPNLgEXzdc19ztyDaftmWW2x/MRERkeumJJojZE+i5bKpQG4bCgAEBDggHhERERG5sTX+KGdZRiLsfR82Doe/HzR39QTcXNz49O5PSRiTwP81/L9rvuXSQ0uv+VoREZFbkZJojpB9OmcuSbSoqNwv1Ug0ERERkVuQVxi0/inv80d/gFkusPN1m1FptUvVvuZb3vH1HXT6phM/7PrhmtsQERG5lWhjAUcowHROJdFERERExEbZe8xpncfn511n+0vmiLTaLwHg6uJ6XbdccmAJvx34je3R29lwcgN1Q+oyts3Y65oqKiIicrPSSDRHKMB0zrySaHFxDohHRERERIqG5t+CT4Ur19kxFlLOAFAuoNx139LAYPzK8fx24Dcm/T2JUpNKsTNm53W3KyIicrNREs0RCjCdMyYm90u9vR0Qj4iIiIgUDW7e0HEdNJgCDabmXW/zkwC0r9Cekt4lrcV9avXhlbavEOYbds0hXMi4QO1ptSkzpQznL5xn7u65/LrvV5LSkkjJSLnmdkVERIo6Ted0hAJM5zx/PvdL77/fAfGIiIiISNHhWRKqmUkyslJh6+icdQ5/A/5V8aj5AqseXsWUNVMI9g7mmebPEOAZwNg2Y1m4dyF3zbrLesmE9hM4GneUaRunFSiMkwknKf5W8RzldULq8HWPr6kTUuea3p6IiEhRpSSaIxRgOmduSbTx46FuXQfFJCIiIiJFT+X/g33TIOlwznPbX4LY7dzWYjYf3/VxjtNdqnThjXZvMHfPXP5T5j883uRxfNx9aFy6MQ8vePiaQ9oevZ1WM1qx67FdlPUve83tiIiIFDWazukIBZjOGRtre/zHH/D882CxOC4sERERESli3AOgy3ZoPR9C78x5/ugcWNIUMpJynLJYLIxpNYYNj2zg/S7v4+Nuzo4YVH8QxssG49uNv+aw4lPjCX8nnLf/ftumPC0zjczLdg8VERG5mSiJ5gj5TOc0jJxJtKAgx4YkIiIiIkVUMT8o2w1uXwxhnXKeP7cRdrxy1c2OaTmGqiWq2pT5e1zdVvGjfh+F5RULg38ajOUVCx6ve1D8reLM2jHLWudE/AnWHl+r5JqIiBR5SqLZm2HAvHm2ZdlGoiUnQ0aGbZXAQMeGJSIiIiJFnMUCredBRL+c53ZPgtOrwcjKeS4zBaKXQ5rtNvAWi4Vtw7Yxof0EhtQfwtrBa4l7Lo5HGz161aF9sfUL68/xqfE8OPdBmk9vztfbvqby+5VpNr0ZzaY3Iy0z7arbFhERuVFoTTR72749Z9llSbQdO2D//pxVlEQTERERkXy5ekLzryHsTljT3/bc7y0hqAF0WAbF/h1RlnIGFtWGlCgoFgCdNoFfJeslHm4ePNfyOZtmetXsxccbP8bAuK5Q1xxfw5rja6zHG05uYNaOWQyoN+C62hUREXEWjUSztz/+yFn277CzZ5+FOnXg3ntzVvG/upHzIiIiInIrq/AQhPfMWX5+M/xaHzIuwLlNsGOcmUADSI+DtYPybbptRFvmPjCXluVa0jy8Od/f9z1ZY7MwXjY4OvIoNUrWuOawB/40kPfWvUftabUZOH8gkWcir7ktERGRwmYxDOP6vmIqYuLj4wkICCAuLg5/R2Su3ngDXnjBtuyHH0jodH+eiTJv75x7EYiIiMiNxeF9CLlut9xnlHAAFtaErNSru87iBrcvgZDbr3lXq2ofVCPyrH0SYJWCKjGs0TD83P3YeHIjvWr24o5Kd9ilbRERkYIoaB9CI9HsLftiZwC3387Bg3lfkpXL0hUiIiIiIlfkVwkavnv11xkZ8Gd72PrsNd/6zQ5v4unmec3XX+7A+QM88/szDFs4jM+3fE7nbzuz5dQWu7QtIiJiT0qi2Vv2bTfLlYPgYFJS8r4kPd2hEYmIiIjIzarS4Nx37CyI3ZNhlhtsHwdXuXNmt2rdOPnUSSJHRDK0wVBrefsK7VnQe8G1xfOvTCOTzzZ/BpibFMzbPY+D5w+y7+w+dkTvuK62RUREroc2FrC3ONtdj+jRA4Dz5/O+5L//dWA8IiIiInLzcnGD1j/ByUWwssfVX29kws5XIPEg/GcGuLgW+NIgryCCvIL4qOtHdKrcieT0ZO6rcR8pGSkEegYSmxJ79fH8a9rGaQxrNIzus7tzKPaQzbn/a/h/fHzXx9fctoiIyLXSSDR7y55ECwgA8k6iFSsGjz3m4JhERERE5Obl6g7h3c2dNz1L5V3PIzjvc4e/hs1PXdvtXVzpUb0Hfev0xcPNgwDPAH7q/dM1tXW5uh/XzZFAA/hk0ycMWTCE+NR4m/Lpm6fT4JMG9JrTi8Oxh6/7/iIiItkpiWZvV5lE27QJKld2cEwiIiIicvMr3gC6n4SaL2YrbwgN3oF7o6H98ryv3/sezAmEJU1hSTPYPhaMa1u8t3X51hgvGyzovYDx7cazZ/ge2pRvY1OncvHKjG4x+pran75lOgETA+g3tx9vrnqTwT8NZsjPQ9gStYU5/8yh63ddmbl1Jh6ve2B5xcI327/hFttPTUREHEC7c9pbrVqwa9el488/h8GDefBBmDXLtuo//0D16vYPQUREROzvltv5sQjSZ5SNYeS++2biQTj6I0T9DlF/XLmNiIeg+Vd2CSfyTCQ1P6pJpmGuvza141RGNBnBPbPvYdG+RXa5x5X8eP+P9KzR0+H3ERGRoke7czrD4cO2CTSAsDCysnIm0Jo3VwJNRERERBwotwQagG9FqPEstPsdar9y5TYOfw3Ry+wSTtXgqiwbsMxc06zrxzze9HFcXVxZ+OBC9gzfg3cxb7vcJy8fbviQWTtm0W9uP+bvma+RaSIictW0sYA9bd1qe+zpCW3acOxYzqp33FEoEYmIiIiI5K3WS+BRAna8DKlnc6+ztB3UnWDuBOpZ8rpu16p8K1qVb5WjvGpwVfY/vp+HFzzM4v2Lr+seeVl2eBnLDpsJwW93fEvXKl2Z+8Bc3F3drXUS0xLxdfd1yP1FRKTo00g0e0pKsj2uUgV8fFi+PGfVYcMKJSIRERERkbxZLHDbcOh+Ahq+B4G1c6+3bQzMLQV/3QMb/wur+0LMCruGEuYXxq99f2Vp/6U25b/1+42l/ZcyqN4gu95v4b6FeLzuwYLIBaRnptNtdjf8J/hT/5P6RCdG2/VeIiJyc9CaaPb0+efwyCOXjps04eicdZQvb1utdm3Yvt2+txYRERHH0npbNz59RnZy+m/4vUX+9Swu0OYXc+MCj2Dz2E7OXzjPodhD1Auth8tl7R48f5CTCSdpM7MNWde46UFuKgVV4sD5A9bje6rew5z751hHqe09u5dpG6bh5+HH8MbDCfENsdu9RUTE+bQmmjNcuGB77OXFxx/nrKa10ERERETkhlWyuZkcI4811S4ysmB5F5gbAgsqQnyk3UII8gqiQVgDmwQaQMWgirQs15KFDy60270AmwQawILIBXi87sH4FeM5f+E8Lb9oydR1U3ltxWvU+bgO8anxdr2/iIgUDUqi2VP2JJq3NxMm5KxWpUrhhCMiIiIick3KdIX2y8x10Aoi6Qis6GbuCJqflBhIOJB/vSvoULEDt5W4zabMgoUw3zDWD1lPg7AG19X+RS8ue5HibxXndPJpa1lMUgzvrHlHGxOIiNyClESzp1xGouWmcuVCiEVERESkiFmxYgV33303pUuXxmKxMH/+fGeHdGsLaQNNP4fe6fnv4gnmSLRZLnBsbt7JtEPfwLwy8HNlWPdI7nUKwM3FjRUDVzCuzTimdpxKygspxI+J5+iTR2lcpjHf3vstd912F23Kt6FtRNtrvk9exv01DpdXXXj0l0et66fFpcSx/sR6ktKS8rlaRESKqhsiifbhhx8SERGBp6cnTZs2Zf369XnW/eyzz2jVqhVBQUEEBQXRoUOHK9YvVNmSaEYeSbSwsMIIRkRERKRoSUpKom7dunz44YfODkUu5+IGtcdCt8MQ0S//+it7msm0w7Mh7h+IWgqR70HiYdgyCowMs96Bz+HM2msOK8Q3hJfbvswT/3kCDzcPfN19cXNxA6BacDV+7vMzywcu58/+f/JYo8es141qNuqa75ndx5s+pvkXzVmyfwmBbwbS9POmVP+wOicTTjJrxyxe/PNFdsXssrnm2+3f8sCPDzBi0Qh2n95tt1hERMTxnL6xwPfff0///v35+OOPadq0KVOnTmXOnDlERkZSqlSpHPX79u1LixYtaN68OZ6enrz55pvMmzePXbt2UaZMmXzv59AFZ594At57z3qYPmAI7l9+lqNaQgL4audsERGRIkWL1hcui8XCvHnz6N69e4Gv0WdUSAwDVt1njji7XuE9odWP199OPgzDYM+ZPRRzLUbl4pWp93E9tkVvc/h9L2oR3oJ6ofU4e+Ess3fOtjl3T9V7+P6+7/F088xxXZaRxcjFI3l//fuU9ivNR10+olu1boUVtojILaOgfQinJ9GaNm1K48aN+eCDDwDIysoiPDycxx9/nOeeey7f6zMzMwkKCuKDDz6gf//++dZ3aOdq6FD47FLSLGHQ4/jPeM+mysyZMGCAfW8rIlKYMjMzSU9Pd3YYInZXrFgxXF1d8zyvBE3hKkgSLTU1ldTUVOtxfHw84eHh+owKQ1Y67PsYNv33OhuywN17wa9w1zuZv2c+9/1wH5lGZqHe90r+eOgP2ldsb1M2fOFwPtr4kfXYz92PqFFReBfzLuzwRERuagXt57kVYkw5pKWlsWnTJsaMGWMtc3FxoUOHDqxZs6ZAbSQnJ5Oenk7x4sVzPZ9b58phsk3nTMF2OqfFAg895Ljbi4g4kmEYREVFERsb6+xQRBwmMDCQ0NBQLJZ8diWUG8KECRN45ZUCrNUl9udSDKo+DmEdYWENuOZklAGbn4LW88FSeCvNdK/WncgRkRyOPUyLci34cP2HLNi7gHD/cJLSk5i/Z36hxXJRh687ALBp6Ca+2f4Nh2IP5YgjIS2BB358gPTMdO6tfi9DGw4t9DhFRG5lTk2inTlzhszMTEJCQmzKQ0JC2LNnT4HaGD16NKVLl6ZDhw65ni/UzlW2JNr3C2yTaH5+4HJDrEInInL1LibQSpUqhbe3t5IMclMxDIPk5GRiYmIACNMCpkXCmDFjeOqpp6zHF0eiSSHyvw06roOj/4OSzc11zzY9fnVtnPgZZrlCxUFw23AIql8oCbVKxStRqXglAJ5u/jRPN3/a5nz32d35KfInh8eRXcNPG17x/C97fwFgyYElHDp/iNfbvY6rS96jaK/W4v2LWX54OXdWupN2FdrZrV0RkZuBU5No12vixInMnj2b5cuX4+mZcw0BKOTOVbYk2rGztkk0Rw6CExFxpMzMTGsCrUSJEs4OR8QhvP7dECgmJoZSpUpdcWqn3Bg8PDzw8PBwdhhSvKH5usivMmwcDokHr66dgzPMl18VuP038I2wa5hX67ue3/H80udZe3wtu8/sJj71xuvMT1w9kUX7F7FuyDo83Tz53z//45sd31Dcszijmo9i4b6F/HHwD+6oeAcj/zMy12Tb2uNrmbd7Hg1LN8Tfw5/O33YG4M3Vb7Jy0EpalmvJppOb+HDDh5QPKM/olqNzXb9NRORW4NQkWnBwMK6urkRHR9uUR0dHExoaesVrJ0+ezMSJE/njjz+oU6dOnvUKtXOVLYl2gdx35xQRKWouroHm7a01WOTmdvF3PD09XUk0kWtVuhPccwAuRMPuSXByEcRn24XSxcPcpTO3aaAJ+2Dp7dBhOfiUL5SQc+NdzJupnaYCcCzuGOWnlsfAqctJ52p79HZ83/ClRska7IjZYS3/YusX1p+XHFjCsfhjVAisQNfbulK5eGVWHFnBnF1z+GDDB3m2PXbZWGb1nEWjzxpZy86nnLc+FxGRW41TJxe6u7vTsGFDli5dai3Lyspi6dKlNGvWLM/r3nrrLV577TUWL15Mo0aN8qxX6JREE5GbnKZwys1Ov+POlZiYyNatW9m6dSsAhw4dYuvWrRw9etS5gcm18QqBBpPhrn/gnoNQsiW4+ZjrqHU/Bi1mg3vu6xqTdBiW3wXpiYUacl7CA8L5qsdX1A+tzz1V72Fur7k0D29unvMP58vuX5L0fBJtI9o6Jb5MI9MmgZabd9e9y8glI6nyfhUsr1hoM7PNFRNoAMsOLyP0bdvBDe+ue5cjsUe4kH4hj6tERG5eTp/O+dRTTzFgwAAaNWpEkyZNmDp1KklJSQwaNAiA/v37U6ZMGSZMmADAm2++ydixY/nuu++IiIggKioKAF9fX3x9fZ32PgBITrY5zJ5EK8DmoSIiIiK3rI0bN3L77bdbjy8uyTFgwABmzpzppKjELnwrwB0rbcvK3Qelu8KBz2DTEzmvidsJc/yg2dcQ0dfcpcuJ+tXpR786/azHPar3yFHn2ebPsvzw8lyvL+5VnMalG7PkwBJrWZBnEOdTzts9VkeLeDeCsv5lWfTgImqH1HZ2OCIihcbpy9w/8MADTJ48mbFjx1KvXj22bt3K4sWLrZsNHD16lFOnTlnrT5s2jbS0NO677z7CwsKsr8mTJzvrLVwSFATBwaR7+JCFJUcSbfhwJ8UlIiJ2ExERwdSpUwtcf/ny5VgsFu1qKlIAbdu2xTCMHC8l0G5ibl5Q9b9wVySU7pJ7nTUPweKGELUUsjIKN76r1LlKZ1YNWsWkOybxTY9vKONXBoC+tfty5pkzLO63mNUPr2ZJvyVkvJTBudHncHNx+riGa3I8/jivr3wdwzA4mXCS00mnWXt8Lf+c/gfDuPppr/N2z6PtzLYMmD+A6MRLy/3M3zOfIQuG0OGrDjz4vweZtWOWPd+GiMhVsRjX8n+4Iiw+Pp6AgADi4uLw9/d3yD2GDoXPPjOwYGD8m6fctg2usHSbiMgNLSUlhUOHDlGhQoU8N3K50eQ3Le/ll19m3LhxV93u6dOn8fHxKfD6cGlpaZw7d46QkJBCmypYrVo1Dh06xJEjR/JdY1RsXel3vTD6EHJ99BndBBIOwJLGkJbH6Kyy3aDl/8COu1E6UlpmGsnpyQR6BuZZ56MNHzF80aVv2/vX7c+dFe/krtvuovO3nVlzfE0hRGpf5QPKs/rh1Xi4eRDsHQzAiiMrGPrzUJLTk3nrjrfoXau3tf7RuKNUeq8SGZclSc8+e5ZtUdto91XOHUJ/6v0T91S9x/FvRERuGQXtQxTNrz1ucKtWAVgwMP+x9PbbSqCJyM0lKwvOnnXe/UuUAJd8xlJfPor5+++/Z+zYsURGRlrLLl8CwDAMMjMzcXPL/6/FkiVLXlWs7u7uhZrIWrVqFRcuXOC+++7jyy+/ZPTo0YV279ykp6dTrFgxp8YgIkWIXyVo/ycs6wwpUTnPH/8JZrtBUH2o8zqUyWP02g3C3dUdd1f3K9YZ1mgYrhZXNp3aRO9avWlX4VLSaNXDqzgce5izyWdp8nkTR4drN0fijlD2nbIAtI1oy+0Rt/Py8pet5/v8rw+GYdAgrAHf7viW99a9Z5NAA3j4p4dJy0zLtf2B8wdybvQ5u8edmJaIYRj4efjZvW0RuTk4fTrnzSgq29/39es7Jw4REUc5exZKlXLeqyAJvNDQUOsrICAAi8ViPd6zZw9+fn78+uuvNGzYEA8PD1atWsWBAwfo1q0bISEh+Pr60rhxY/744w+bdrNP57RYLHz++ef06NEDb29vqlSpwoIFC6zns0/nnDlzJoGBgSxZsoTq1avj6+tLp06dbJJ+GRkZ/Pe//yUwMJASJUowevRoBgwYQPfu3fN939OnT+fBBx/koYce4osvvshx/vjx4/Tp04fixYvj4+NDo0aNWLdunfX8zz//TOPGjfH09CQ4OJgePS6t+WOxWJg/f75Ne4GBgdapdocPH8ZisfD999/Tpk0bPD09+fbbbzl79ix9+vShTJkyeHt7U7t2bWbNsp2Ok5WVxVtvvUXlypXx8PCgXLlyjB8/HoB27doxYsQIm/qnT5/G3d3dZnMiEblJBNWDjuvBv2redc5vgb+6wrJOELvr6tpPOQ1pcdcVoj25WFz4v0b/x6d3f2qTQLt4rmJQRRqXaczKQStxsZj/fHNzcWPjIxv5rd9vVAyqaK3/cL2HCzX2glh+eLlNAu2iB+c+SLUPq/HaiteIS835efwU+RO/7v811zbPp5znq21fWY+PxB5h0upJLN6/OEfdE/EnWLRvEbEpsUQlRnEi/gSfbfqMvw7/RZaRxaTVk2g2vRmer3viN8GPkpNK8tmmzwDzS7Zlh5bx6aZP2Xd231W97yX7l3D/nPsZu2ysNmEQuYloJJqdZWRA9mVvgoOdEoqIiOTjueeeY/LkyVSsWJGgoCCOHTtGly5dGD9+PB4eHnz11VfcfffdREZGUq5cuTzbeeWVV3jrrbeYNGkS77//Pn379uXIkSMUL577rnPJyclMnjyZr7/+GhcXF/r168eoUaP49ttvAXMTnW+//ZYZM2ZQvXp13n33XebPn2+z4HpuEhISmDNnDuvWraNatWrExcWxcuVKWrVqBZg7H7Zp04YyZcqwYMECQkND2bx5M1lZWQAsXLiQHj168MILL/DVV1+RlpbGokWLrum5vv3229SvXx9PT09SUlJo2LAho0ePxt/fn4ULF/LQQw9RqVIlmjQxR1aMGTOGzz77jHfeeYeWLVty6tQp9uzZA8CQIUMYMWIEb7/9Nh4eHgB88803lClThnbtck7zEZGbgE843LUHEg/Bql5wbmPu9U4tMV8tf4RyPfNvd/Mo2PO2uUtos68g/F77xu1ALcu1ZN2Qdaw8spJ2FdpRN7QuAAf+e4C0zDSS0pII8gqirH9ZXl3xqs217q7uuY7qqh9any1RWwolfnsbMH8AA+YP4Ld+v9Hrx17EpsQC8HKblzkWd4z4tHjOXzjP0kN5f9nSo1oP5u2ZZ1OWmpnK0F+GckelO/hl7y88/uvjNueblmnK862ev+J00oPnD9Lluy5kGebfr6+teI3nWjzH2DZj8Srmled1BZGakcq+c/v44+Af7D+3n0caPGL9XRARx9OaaHZ2+rQ5SuJyJ05A6dJ2v5WISKHJvk5Ubv+vK0wxMXA1sypnzpzJyJEjraPBli9fzu233878+fPp1q3bFa+tVasWw4YNs46EioiIYOTIkYwcORIwR2e9+OKLvPbaawAkJSXh6+vLr7/+SqdOnaz3On/+vHXU1qBBg9i/fz+VKlUC4KOPPuLVV1+17jgdGhrKqFGjGDVqFACZmZlUrFiR+vXr5xgJdrnPPvuMjz76iC1bzH8QXXzPF0eKffrpp4waNYrDhw/nmuBr3rw5FStW5Jtvvsm1fYvFwrx582xGxAUGBjJ16lQGDhzI4cOHqVChAlOnTuWJJ3LZae8yd911F9WqVWPy5MkkJCRQsmRJPvjgA4YMGZKjbkpKCqVLl+bjjz+mV69eANStW5d7772Xl1/OObrhemhNtKJNn9FNbMNjsG9a/vX8q0ON58zkWDFf23OJh2DBpVFb+FSAbgftG+cNIDYllubTm7P7zG7K+JVhaf+lVA2uyppja5i4eiIA73R8xzqC7UL6BTp+05GVR1dS2q80b3Z4k4fmPeTMt1Ak/PHQH6RkpNCiXAsMw8C7mDeHYg/x+ebPeXvN23leN7j+YI7FH8PV4sr/Nfw/zl44S7mAcjQr24z0rHSW7F+Cm4sbnSp3wsfdx+barVFbqf+J7TQnTzdPjj15zLr2XEJqAtM2TsOChUcbP8qZ5DPsObOHFuEtNE1V5Aq0JpqT5DbFqESJwo9DRETy16hRI5vjxMRExo0bx8KFCzl16hQZGRlcuHCBo0ePXrGdOpctfOnj44O/vz8xMTF51vf29rYm0ADCwsKs9ePi4oiOjraO0AJwdXWlYcOG1hFjefniiy/o16+f9bhfv360adOG999/Hz8/P7Zu3Ur9+vXzHCG3detWHnnkkSveoyCyP9fMzEzeeOMNfvjhB06cOEFaWhqpqanWzRl2795Namoq7du3z7U9T09P6/TUXr16sXnzZnbu3GkzbVZEbnKNPoDA2nD4Wzi9Ou968bth7QDz5VES2i4C77Kw7yPY/5lt3aRDkHwSPEOKzEYFBRHoGcj2R7cTeSaSiMAIayKmWXgzfur9U476XsW8+GvgX8QkxVDcqzguFhfeWfsOm09tLuzQi5QOX3e4puumb5lu/Tmv6aoAjUs3Zmn/pfx97G8al2nM6aTTORJoACkZKZScVJJHGz1KuYByjFk6xnru2T+etanbMKwhc+6fQ4WgCtcUu4goiWZ32ZNovr7w78wTEZGbRokS5mgwZ97fHnx8bL/hHTVqFL///juTJ0+mcuXKeHl5cd9995GWlvvCxhdlXzjfYrFcMeGVW/3rHRj+zz//sHbtWtavX2+zmUBmZiazZ8/mkUcewcvrylNI8jufW5zp6ek56mV/rpMmTeLdd99l6tSp1K5dGx8fH0aOHGl9rvndF8wpnfXq1eP48ePMmDGDdu3aUb58+XyvE5GbhMUFqjxqvgDOboAl+Sy0n3ra3OnzSuaXMf/bbimE3jzTw91c3KhZqmaB61ssFkJ8Q6zHCx9cyPTN01l3Yh3RSdFUCKzApDsmER4QDkBUYhQJqQnEpcbRbHozm00BVgxcQaPSjaj/SX0iz0bmuJcUzIaTG/CfaI6G8ffwp2FYwyvWn7Yx/5Gam05totO3ndjx6A6bDS92xexi6aGlNCvbDDcXN6KTotkZs5N7q99LxaCKGIbBRxs+4tsd39IgrAETO0zE190c6ZmSkcL4FePZHLWZB2s9SN86fa3tHok9QnRSNI1LNy60HcpFHE1JNDvL/o9KjUITkZuRi8vVTacsKlavXs3AgQOti+knJiZy+PDhQo0hICCAkJAQNmzYQOvWrQEzEbZ582bq1auX53XTp0+ndevWfPjhhzblM2bMYPr06TzyyCPUqVOHzz//nHPnzuU6Gq1OnTosXbqUQYMG5XqPkiVL2myAsG/fPpKTk/N9T6tXr6Zbt27WUXJZWVns3buXGjVqAFClShW8vLxYunRprtM5AWrXrk2jRo347LPP+O677/jggw/yva+I3MRKNIbm38HfD9qnvRXdoMsO8I2wT3tFXKhvKC+0fuGK50N9zZ2nNw/dzIojK2gT0YZapWpZ66wbso7fDvzG8fjjbDq1iW93fJujnUUPLuKf0//w/a7v2XByA482epSD5w+y5MCSHHW/u/c76oXWo+GnDbmQcWst1B+fGs+yw8vs0tbes3vxeP3SKI/iXsU5dyH3nU7HLR/Hvsf3cSj2ECN+NZe1WHN8DQsiF3B45GFz1OKad3h95esALNq3iC1RWwjxCeF08mkm/T0JgF41e/H9fd9fMa7UjFQ+WP8BMUkxPNr4USICIzgSewSLxUK5gLzXpc0ysnhz1ZvM3TOXZmWbMbHDRLyLeV/VMxG5Gkqi2dmv2Ubkli3rnDhEROTqValShblz53L33XdjsVh46aWX8p1C6QiPP/44EyZMoHLlylSrVo3333+f8+fP5/ktbnp6Ol9//TWvvvoqtWrVsjk3ZMgQpkyZwq5du+jTpw9vvPEG3bt3Z8KECYSFhbFlyxZKly5Ns2bNePnll2nfvj2VKlWid+/eZGRksGjRIuvItnbt2vHBBx/QrFkzMjMzGT16dI5RdbmpUqUKP/74I3///TdBQUFMmTKF6OhoaxLN09OT0aNH8+yzz+Lu7k6LFi04ffo0u3btYvDgwTbvZcSIEfj4+NjsGioit6iIPuBTDjYMh9ht19dWRiL80QraLobAgo/gEqgdUpvaIbVzlAd4BnB/zfutx2eSz9gkxwI8AuhcpTOdq3Tm6eZP21x7MuEkff7XhxVHVgDwattX6V2rNxaLhRNPnaDP//rkmmjLrnxAed5o/wZRiVE8/dvT+da/FeWVQANISk+iw9cdOJN8xqb8WPwxhiwYwqd3f8rzfz5vcy639eB+2PUDa46t4YMuH+TYkGHlkZXsO7ePCasmsP/cfgDeWfsOZf3Lcij2EAAvtnqR19q9lmuMS/Yvscaw8eRGwv3DeabFM3m+J8MwWHN8DecunKNT5U64ueSfEjl/4Tx+Hn4Fqis3P/0W2NmaNbbHXbo4Jw4REbl6U6ZM4eGHH6Z58+YEBwczevRo4uPjCz2O0aNHExUVRf/+/XF1dWXo0KF07NgRV9fc1+xZsGABZ8+ezTWxVL16dapXr8706dOZMmUKv/32G08//TRdunQhIyODGjVqWEevtW3bljlz5vDaa68xceJE/P39raPhAN5++20GDRpEq1atKF26NO+++y6bNm3K9/28+OKLHDx4kI4dO+Lt7c3QoUPp3r07cXFx1jovvfQSbm5ujB07lpMnTxIWFsawYcNs2unTpw8jR46kT58+ORb9F5FbVMkW0GUrRP0Bez8y1z+L+Qtit199W8nHYVEtCL/PTNCd+h1c3KDWS+BZCrLSwaUYpCdA2jnwLgeaolZgL7V+ySbx9fFdH+dZt7RfaZYNWGZdp+3yqYdBXkEs7reYg+cP0mtOLzad2kSdkDpsj7b9zNcPWU/jMpem8+6I2cHMrTNt6ri5uNlMRZWc/jn9T67lM7bOYMbWGQVu51j8MbrN7sZtJW4jKjGK20rcRq1StXJ8JgDpWenWBBrA6ytfZ/au2bQq14pTiafYeHIjaZlp+Ln7cSLhhM21z/7xLFGJUbze7vVcd0J9bcVrvLzc3JTojop38MP9P/DP6X+oG1LXZiOHLae28Nnmz6zTZCsFVWJBnwW4u7oTERhx3Qm1jKwMXC2umuZaBGl3TjsLD4fjxy8d//wz3HWX3W8jIlKorrRjoTheVlYW1atXp1evXtZdQG9Fhw8fplKlSmzYsIEGDRo45B7anbNo02ckVnH/wIHpcOgrSD2T87xPBchKgwsncp7Lzs0HvEpD4kEwMi+Vl+0Ozb7OuQuo5OmXvb/wc+TPtCzXkn51+tklgWAYBhaLhSlrplhHm3Wv1p25vebatH8i/gRDfxnK7tO7ebTRozzT4hkMw2DFkRW0/bKttV7dkLps/r/NDPtlGJ9t/gzvYt60r9Cen/f+XOCY7q9xPxM7TKTSe5XyrywOUy24Gr7uvmw8uREPVw8erv8wn276lMzL/xz/y9fdlwW9F9CqfCtOJ52m1rRaeY7SKxdQjlWDVnHw/EHWn1hPqG8ov+7/lTJ+ZXix9YsEeAZcMa7Jf09m/MrxhPmG8XWPr8nIyuB4/HHuqHQH/h7+JKYlsvHkRhqXbpxjh9ab2ZnkM2w8uZHapWpTxr9Mod+/oH0IJdHsLDAQLvtinb/+gsu+xBcRKZKURCtcR44c4bfffqNNmzakpqbywQcfMGPGDLZt20b16tWdHV6hS09P5+zZs4waNYpDhw6xevUVdua7TkqiFW36jCSH9AQ4MguMLAiqb25I4FMeynQ1NyuI3Qkr74WEfdd+j0pDIPQOKHc/RL5r7h5a7j4o18t2pFraechIMkfLiUPsiN5BXGocLcJbXFWCLiYphkmrJ5FpZPJ0s6et/4A/lXAKTzdPgryCrPXeWPkGH234iIysDO6rcR9v3/k2Pu4+JKcn89W2rwj2DqZ/3f54unkyYeUE61TDGiVr0K1qN5YeWsr6E+tzxPBCqxfYd24fP+z6wQ5PQpwlzDeM1uVbUy6gHJ5unmRkZVAvtB7pmem0LNeSpPQkak+rTZaR+3Ih7Sq0489Df1qPp98znZblWvLP6X9oG9GWQM/AfGO4mOLJ7c/AsbhjJKUnUS24Wr5tFOYouSOxR2jyeRNikmLw9/BnxcAV1A2tW2j3ByXR8uTIzpVhgJsbXL58zubNUD/nTsQiIkWKkmiF69ixY/Tu3ZudO3diGAa1atVi4sSJNlMrbyXLly/n9ttv57bbbuPHH3+kdu2ca+/Yi5JoRZs+I7km6YnwZwc4u86+7dafBNVHmT8fmwd/94PMZCj3ADSYDB4lwdXjym3IDSk2JZbk9GRK+5XOt+7qo6s5k3yGzlU6W6elbo3ayl+H/8LH3Yd6ofWoEFiBEt7mjnRH444yZ9cctkVvY84/c0jJSMm13QCPAOJS4/By8+J/vf5HteBqzNszL8fabzVK1uDAuQOkZqZe57uWG8HivoupXrI6b6x8g+ikaJ5u9jQty7W0nj8ef5w2M9tw8PxBAOqE1OGe2+7hwdoPMnjBYNYcN9efeqTBI3x696c52o9OjKbJ5004GneUFuEt+OH+H/L9Pf9136/sO7ePB2o+gIFBfGo8t5W4jYysDF7880WWHlrK7RG383q7122mZgNMWj2JeXvmWeO63CMNHmFa12m4uuS+nIm9KYmWB0d2rpKTwSfbaMt9+6ByZbveRkSk0CmJJrcKJdGKNn1Gcs3SYmHVAxD1m/3bDm4GZ3L+AxEXDyj/ADT93FxrLS8ZF+DIbMhKMaeQeoXZP8brkZVhjuTzq2KuISd2E58aj2EYBHgGcPesu/ll7y8AvNL2FV5o9QLbo7cT6htKmN+l34mtUVtp+YU54snP3Y+NQzdS0rske8/upVpwNfw9/Jm1cxZ95/a1uVeDsAasG7KOBp80YEfMjkJ9n3L9BtcfTOTZSFYdXVXga/aO2Eumkcl7697jdPJp+tfpzz2zbTd+6Fy5M4v6LmJ79HY+2vARn2z6hBJeJehftz/1Q+vTf37/XNvuX7c/zcs2Z9hC2/Vt5/aaS4/qPcjIyqDkpJLEpsReMcZP7vqEoQ2HFvg9XQ8l0fLgyM5VdDSEhuYsK1XKrrcRESl0SqLJrUJJtKJNn5Fct8xUc2OCdYPNjQYKi29FaPkDFG94qSwjGXZPgh3jLpW5eEBEX6jyKJzbBB7FIbynOTXVGS5Ew+8tIPGAuc5cx7XmJgxid5lZmfx+8Hf8PfxpHt78inUPnT/ExpMbaR7e/IprSx2NO8rnmz8nIyuDYY2GUS6gHIZhcOc3d/LHwT8o7Vea2T1n06p8K7zHe3Mh44L12k1DN/H1tq+Zum6qtezVtq8yoskI3FzciEuNY/nh5Tw076Frer8twlvw2u2vccfXd+S6hplcv2IuxUjPSs+33q99f6XLt10wsE/q6MvuXzJg/oAC1Y0IjODQE4fyr2gHSqLlwZGdq/37oUoV27LkZPDKuSmIiEiRoiSa3CqURCva9BmJ3RiGOfXy+AI4+IW5M2fYneaoMN8I83jDo/a9p6sntF0EIbfDrgmw7fmCX+tRAsr3MV8lm5vxYzg+ubbjFdskX6XB5sg6KfIyszIxMKy7UL637j1GLh6JgUHvWr2Z1XMW0YnR3DfnPtYdX0fPGj35qvtXFHO9NKoyIyuDZ357hvmR80lOT2byHZPpV6efdRRSXGqczT3D/cMZXH8wz7V8Dg83c6rzxFUTGbtsbIGSPXJzeq7Fc3yx9QviUuIY3ng4k++c7JD12pREy4MjO1dbtsDlm4W5ukJ6una+FpGiT0k0uVUoiVa06TOSQpWVCfs/ho0jLpWVaAop0ZB0+NradPWE23+HP1pdZ3AWKOZvjlordz8kHgL3ACjZGjyDr61Jw4DzW80dSosFwMlFsHlkznr3xUJKlLkO3PnN4Hcb1HwB3DSyoKjbfXo3CWkJNC7d+LqTGCkZKXy/83tOJ5+mZ/WeVAiqkGfduJQ4XF1c8Slmrp306/5f6TWnF0npSfSo1oOH6jzEvnP7KOtflhbhLWj+RXNOJpzMs70e1Xrw+8HfSUxLvGKMrhZX/h78N59s/IQvtn5xbW9U7G7loJU268DZi5JoeXBk52rFCmjT5tJxYCCcP2/XW4iIOIWSaHKrUBKtaNNnJE6TmQaXL5idEgOR78Gu8bb1/G6DgBpwfH6hhneJBSL6Qe2Xzd1Cz6wBVy9Ij4fU01BxEPjflvMyIwuWd4VTi6/91hX6mzujlu4KgbXgzDpz6mdgrfyvPb0Gto42R9bVeQ1KXZZkTE+EuH/Au4z5sqf0BPM9W1whrCO4+eR/jRSKs8lnOXfhHJWLV86R0NsatZUJqybgW8yXV25/BYCvtn1FpaBK9KzREzcXN3af3s2SA0uISoyibkhdqgZXZfLfk/n72N8ciTtC58qdGdpwKN2rdbe2G5cSR5uZbdgWvQ0wk2xhfmG0CG/B97u+L3DsdULq0LZ8W+ZHzudo3FGbcyW8SnDwiYOkZqQy6vdRfLXtq2t8Qjevh+s9zPRu0+3erpJoeXBk5+qXX+Duuy8dh4fD0aN51xcRKSqURJNbhZJoRZs+I7nhXDgF+z4xR5iVfwB8Lxttc2wurOxZ8LZc3M1NCk6vBiPD/rFeLrAueJf9dyTbfWbSb1Uvx93vrsjck3dgTp39qQJcOHGprPV8cPGE5Z1s64Z1hooDzCmxnqUgYT+c3wI+EVC8kTlF6MIpiP7LXIcuuEneMWWlw+JGELvdPPYsBXf8DX6VruedShFnGAYnEk5Qxq+MTfIuMyuT3w78xt6ze+lZoydl/cuSnpnO9ujtjP5jNPvP7adrla483fxpKgZVtF4XeSYSH3cfJv89mTPJZ3jyP0/SsLS5NmJSWhJPLXmKTzfn3EWzIGqXqs2snrMYtnDYVW04cKNrVa4VKwatsHu7SqLlwZGdq1mz4MEHLx3XqAG7dtn1FiIiTqEkmtwqlEQr2vQZSZG090PbKaG5uS/WnJ5psUDySXPzg9OrzXMJkRD1h8PDdLgyd0PaOaj4MFR6+FL5uc2wuGHe112P8HuhwRSIXg5ZqebUV/cg89yJhfDXXbb1Q++Adg7YwVUkHxfSL9Drx17WHVqrlqjKtmHb8HDz4HTSaR5b9Bg//vOjzTVRT0cR4htiPTYMg5/3/ky32d2ueC9XiytL+i2hw9cdrinWhmEN2XRqU4HrP1DzAf5T9j9MXDWR6KTofOuXDyjP4ZGHrym2K1ESLQ+O7Fx9+in83/9dOv7Pf2BNLrtZi4gUNbdyEq1t27bUq1ePqVOnAhAREcHIkSMZOXJkntdYLBbmzZtH9+7dr+ve9mpHCk5JtKJNn5EUSYYB+z+B3ZPNXS4v5+oF3Y6AZ8n829jwqNkOmNMOgxpA3E5z2mZR5F0OgurCiZ8L757BzaDlj7DsDnOKaG4CakLNFyGit33uaRgQH2kmSc9vhpOL/90oojf4VzPr5LX+WFos/DPRTKwWrw9lu9uOdpSbzsaTG9l/bj933XYXvu6+NufOJJ9h4d6F+Hn40a1qN1xdXPNtLy0zjY83fszTvz1NRlYG7q7ufNn9S3rX6o1hGPy6/1fOJJ+hVqlaHI07yuqjq5m8ZrL1+uJexTl34Zz1+MvuX9K/bn9iU2KZu3suaZlpFHMpxpCfh+R6f083T46OPEpJn0v/j5u3ex73/nDvFeM+++xZinsVz/f9XQ0l0fLgyM7V22/DqFGXju+4A37TFxUichMoikm0u+++m/T0dBYvzrl+y8qVK2ndujXbtm2jTp06V2wnexLt9OnT+Pj44O3tnec1V5v8GjduHPPnz2fr1q025VFRUQQFBeHh4VGgdq7HhQsXKFOmDC4uLpw4caJQ7nkjUhKtaNNnJEXeP2+Zu11mXjCPm3wKlR8p+PWZaeZUT7d//47KSjenL3qUgIwk2P4S7L+2qWFX5OoJXmUhcf+lstA7zJFd+z4211tLPmb/+zqVxVzfDcOc+hrWyVzzLfpPM7kV9RuknoPiDc2dXbNSzaSY323gVRoyEmDPu+bur/ltROF3G9R60UyMnvwF4veYP+/7yPz5clUeg0YfXHl3u9idsPJeSNhnHofcDj4VwDvc3BTC1du8n3tQ7u0YRsF2z8tMMde+868KXqH515cixzAMIs9GUsKrhE0iLLudMTvZfGoz7Sq0o5RPKaauncrB8wcZ2nAoDcIa5Khf66Na7DptO62vU+VONC7dmAZhDbiz0p14F8u7L34tCtqHcLPrXW9xCQm2x35+zolDRMThsrLg7Fnn3b9ECXBxuWKVwYMH07NnT44fP07ZsmVtzs2YMYNGjRrlm0DLTcmS+YwGsKPQ0MLrcP7vf/+jZs2aGIbB/PnzeeCBBwrt3tkZhkFmZiZubuqmiMgtpsaz5nTGmH/X7Cpe/+qud3UHLtvgwKUY+JQzf3bzgSafwG0jIGqpucZXSDszuRG7C5a2gdQC/N1e+f/MpFlWOlT9rxnnxXudWQ97pphJu1ovmW1fngRMPQsresDplVf3vvIT0dd8f6dXQ1xhradjmAmtiy6OAswucT8cLfii87lK2Atr+mcrnJl73X0fma+qT5rJsdB2kHoGPEpB8nGzzqLattdELwOW2ZZFvgNuvubvSPVnwCPYHBG5YTic+MlMCJbv/W+d9uaadsfmwalfwc0PijeAzU+bCVSA6qOg7kS4fHRUymkzaedfDfa8A4e+Mn93gltA5SHm71Z6wqXEb8SD4BWW8z2nnYfdb0PSEQjtYP4+uOTRh8hMg3MbzMSnT/nc61xJVqbte7jIMMz7ewRDMd+c529SFouFasHV8q1Xq1QtapW6tInIsy2evWL9Pwf8yYP/e5A1x9fQu2ZvPr370wKNrCsM6p3akZJoInLLOHsWSpVy3v1jYiCfZNZdd91FyZIlmTlzJi+++KK1PDExkTlz5jBp0iTOnj3LiBEjWLFiBefPn6dSpUo8//zz9OnTJ892s0/n3LdvH4MHD2b9+vVUrFiRd999N8c1o0ePZt68eRw/fpzQ0FD69u3L2LFjKVasGDNnzuSVV8ydoy4uUDtjxgwGDhyYY0Tbjh07eOKJJ1izZg3e3t707NmTKVOm4OtrdtYGDhxIbGwsLVu25O233yYtLY3evXszdepUihUrdsXnNX36dPr164dhGEyfPj1HEm3Xrl2MHj2aFStWYBgG9erVY+bMmVSqZC6w/MUXX/D222+zf/9+ihcvTs+ePfnggw84fPgwFSpUYMuWLdSrVw+A2NhYgoKCWLZsGW3btmX58uXcfvvtLFq0iBdffJEdO3bw22+/ER4ezlNPPcXatWtJSkqievXqTJgwgQ4dLq3RkZqaytixY/nuu++IiYkhPDycMWPG8PDDD1OlShWGDRvGqMuGiW/dupX69euzb98+KleufMVnIiLiFJ7BUO4qNhy4WoG1zZdNWU3oeebScVYmZMTDwZnmBggu7ubouAbvQHDTvNsObgItZ+d93qME3LHCHKHk4g7r/w8OfH518Qc1MKc9WlygXG9oNtNM4F2UnmCuM3d6lbmrZskWZuw7xpnnXYpBQG2zjZtZ5Dvm63pkJMKJBeYru/NbzVdB7Z4MZzdCuz/Mz2NFd4hemnvdmBXwzwTz9zR2x6Xyna9Blx3gE36pLCUG5l5a94vD38COV6Dpp2ZCDSDxkJmgc/OBPVMvbVJR7n6o/7Zte7kxDNj/MWx47FJZq/+Zv4sJe82Re3+2MxPLrt5Q93WoOtIcFepy5f4Xp9eYU7HTzpnJQJ/y4FcZQu+EwDrmFGN7JY+yMuH4PDi7zkx++lY0R1B6ljTfY9p5s/zynYYvREF6HPhVMf/MFZJSPqX4o/8fZBlZuBTifQtCSTQ7UhJNROTG4ebmRv/+/Zk5cyYvvPCCNUE1Z84cMjMz6dOnD4mJiTRs2JDRo0fj7+/PwoULeeihh6hUqRJNmlxhx65/ZWVlce+99xISEsK6deuIi4vLda00Pz8/Zs6cSenSpdmxYwePPPIIfn5+PPvsszzwwAPs3LmTxYsX88cf5sLQAQEBOdpISkqiY8eONGvWjA0bNhATE8OQIUMYMWIEM2fOtNZbtmwZYWFhLFu2jP379/PAAw9Qr149Hnkk7+lABw4cYM2aNcydOxfDMHjyySc5cuQI5cub39CeOHGC1q1b07ZtW/7880/8/f1ZvXo1GRnm7nDTpk3jqaeeYuLEiXTu3Jm4uDhWr16d7/PL7rnnnmPy5MlUrFiRoKAgjh07RpcuXRg/fjweHh589dVX3H333URGRlKunDmyon///qxZs4b33nuPunXrcujQIc6cOYPFYuHhhx9mxowZNkm0GTNm0Lp1ayXQRESuxMXVnMpX7UnzZW+u/06Xb/oZVH8WLhw3pxKe3war7sv7upovmAmKC9HmlNViufyDq5gf1Hwul2tfhPh/wL24OZ1y52uw4+X8Yy3VGqoMNxM7+z4s2PuT3MUsh9lXkYK4PIEGZjJn1X1Q5zVzRNzl04cvl3QI/rzDTJq5el8aDZfd0Tnmq9ZLUKG/OTqzmL859dlS7N+NPE6YCcDsn31eO+tmJsPmp8yXi7uZEIv79/eu4btQtpuZqIrdZo6w2zfN9vq4Xebr+E+XysLvM0fgeZc1E38WN0iJNkeZWtzMxGH0cnMUXHBTKNnSTHod+R4OzgDvMuBR0lxfMPv0XzCnCyfsNX92cYdSbcE9wHw2lwusDf7VzfeUmWKWhbQ34/IKy3/txsw0M5l9bhO4ekCxQHO07W2Pmwm6pMPmWoiXjSLMkUDLyjCT4wWZTuwgWhPNjvr0gdmXffEyZgy88YZdbyEi4hQ51ok6ffqGH4kGsGfPHqpXr24d8QTQunVrypcvz9dff53rNXfddRfVqlVj8mRz0dQrbSzw22+/0bVrV44cOULp0qUBWLx4MZ07d77immiTJ09m9uzZbNy4Ech7TbTLR6J99tlnjB49mmPHjuHj4wPAokWLuPvuuzl58iQhISEMHDiQ5cuXc+DAAVxdzW8te/XqhYuLC7Nn5z0y4IUXXuCff/5h3rx5AHTv3p169eoxbtw4AJ5//nlmz55NZGRkriPaypQpw6BBg3j99ddznLuakWjz58+nW7cr7xhVq1Ythg0bxogRI9i7dy9Vq1bl999/txmddtHJkycpV64cf//9N02aNCE9PZ3SpUszefJkBgwYkGv7WhOtaNNnJHITyMo0Rw2d+dv8R3tEXzOp4BkG/lXsf7+UM3Buo5k0jN0B6bFmIsWrDHiGmGuaXfwHu2GYU0ZjlpsJirid139/V0+o9hSU+I+ZAPSrDH+0gcSD19+2SGHyDDHX1rNY4My/OywWb2j+eYpeduVrL1eiiTmK0OJmTvd1cTfbSIkxE4Etf4RSLe0evtZEc4LsI9HUdxMRca5q1arRvHlzvvjiC9q2bcv+/ftZuXIlr776KgCZmZm88cYb/PDDD5w4cYK0tDRSU1OvuGnA5Xbv3k14eLg1gQbQrFmzHPW+//573nvvPQ4cOEBiYiIZGRlX/Q/83bt3U7duXWsCDaBFixZkZWURGRlJSIg5laFmzZrWBBpAWFgYO3bsyNHeRZmZmXz55Zc201D79evHqFGjGDt2LC4uLmzdupVWrVrlmkCLiYnh5MmTtG/f/qreT24aNWpkc5yYmMi4ceNYuHAhp06dIiMjgwsXLnD06FHAnJrp6upKmzZtcm2vdOnSdO3alS+++IImTZrw888/k5qayv3333/dsYqIiIO4uEKlQebrolKtHXc/z2Ao3cn8+UpTVcFMDpRqab5qvmBu2uDmbY6gO7sWijc220g9BxdOQonG5iYDrl5gZJp1z6wzR/14hpijhdx8wSvE9j6dt8Chb8zNB0o0NUdSuReH1Q+Y68qV+A+0WQDH/genFpt1qj5hbhhwZDYcmlmwXVkD65pJSr8q5jM+/A0c+MJc06vKCHO32AOfmWt9FRZXL3MTBiOr8O4p9pESbb4ud27T1bdzdr35ysvhbx2SRCsoJdHsKD7e9ljTOUXkplWihDkazJn3L6DBgwfz+OOP8+GHHzJjxgwqVapkTbpMmjSJd999l6lTp1K7dm18fHwYOXIkaWlpdgt1zZo19O3bl1deeYWOHTsSEBDA7Nmzefvtt+12j8tlT3RZLBaysvLuiC5ZsoQTJ07kWAMtMzOTpUuXcscdd+Dl5ZXn9Vc6B+Dy7wYQlw98T09Pz7Xu5QlCgFGjRvH7778zefJkKleujJeXF/fdd5/188nv3gBDhgzhoYce4p133mHGjBk88MADBU6SioiI5MliAe9/v0QLaWO+LnLzubTOlkdx2+tKNjNfV1LMH257LGd59xPmel7e5c1kY5Vh5uui4Cbmq+EUiN9r7vx5IcpMSJ1Zc2n6Y5VHofFHOduv+l/zdbmaz5tJtKRDkHTUjC2knbmm3Pnt5hpe+z+FlFPm+67zujmKz9XDXJ8u6nfYnMeUYBcPqDfRHIGXEg0R/cwpisknzfaTjkDCfoiceuXnJVenWIA5NbaoOvqDOTX28rXbCpGSaHakNdFE5Jbh4lKg6ZQ3gl69evHEE0/w3Xff8dVXX/Hoo49a10dbvXo13bp1o1+/foC5xtnevXupUaNGgdquXr06x44d49SpU4SFmbtFrV271qbO33//Tfny5XnhhResZUeO2H6j6+7uTmZmZr73mjlzJklJSdZk0+rVq3FxcaFq1aoFijc306dPp3fv3jbxAYwfP57p06dzxx13UKdOHb788kvS09NzJOn8/PyIiIhg6dKl3H777Tnav7ib6alTp6hf39xlLvu01bysXr2agQMH0qNHD8AcmXb48GHr+dq1a5OVlcVff/2V63ROgC5duuDj48O0adNYvHgxK1asKNC9RUREbjiuHpd2Q82P/21mgio7w7i69aQsFvCNMF+XC7ndfAGEd8/7+sCa5hpd+z81R8l5hkCJRubOnqW75L7wvnfpSwlKMNfl2/Y8HP3RHKWWmzL3QMOpgMXcBODMOkg+BuV6mWuC+VY0RwUe+NycJlzzBTOmmBXmbrh5tXu54o2hzc/m2mkpUeYoq9id5hpegXXNe6wbbO4+G9rRfD5br7wLJQDhPc1k5eanzanCF7l6mptguAea8Z1ZC1nX+EWvdzkIqAmh7c3Ea/JJWN07/w023HzMz698b3M31QsnzLXLMlPMKceJB81RloUp7Zy5cUhou8K977+URLMjJdFERG48vr6+PPDAA4wZM4b4+HgGDhxoPVelShV+/PFH/v77b4KCgpgyZQrR0dEFTqJ16NCB2267jQEDBjBp0iTi4+NzJKOqVKnC0aNHmT17No0bN2bhwoXWtccuioiI4NChQ2zdupWyZcvi5+eHh4eHTZ2+ffvy8ssvM2DAAMaNG8fp06d5/PHHeeihh6xTOa/W6dOn+fnnn1mwYAG1atWyOde/f3969OjBuXPnGDFiBO+//z69e/dmzJgxBAQEsHbtWpo0aULVqlUZN24cw4YNo1SpUnTu3JmEhARWr17N448/jpeXF//5z3+YOHEiFSpUICYmxma31CupUqUKc+fO5e6778ZisfDSSy/ZjKqLiIhgwIABPPzww9aNBY4cOUJMTAy9evUCwNXVlYEDBzJmzBiqVKmS63RbERGRW4YzFmQv0ch8Nf302q73KQfNv4HGH0PyUUiLM6ecBtTK/f3kljy8KOKyHdhrvQC8AOnx5uL/6QnmVNsDn5s7j5ZsAbXHmYksVw8zmXWRVxiUuct8Xa7DctvjKo/Cke/M0YBl7vr3PnGAi/lM3EuY7wWgw7/rhl0cvZ/9vaUnwNkNZtLOMwTObYH08+ZGGT4REFTXvPbEz+YLA0p3hfAeOZ+DfxXotNF8v24+5iL/rl7mLqMxK8z1yOq9CdWfyvtZXow1KxUS9pmxZV4wE6MZSeaxq5e52UJKtLnTaJm7zWRe0lHY+Jh5r7z4VjKnMXuXgYxkMNLNhF5EX/C/9i+Qr5eSaHb0ww9w7pyZTIuPh2xLu4iIiJMMHjyY6dOn06VLF5v1y1588UUOHjxIx44d8fb2ZujQoXTv3p24uIINcXdxcWHevHkMHjyYJk2aEBERwXvvvUenTp2sde655x6efPJJRowYQWpqKl27duWll16yLtoP0LNnT+bOncvtt99ObGwsM2bMsEn2AXh7e7NkyRKeeOIJGjdujLe3Nz179mTKlCnX/Fy++uorfHx8cl3PrH379nh5efHNN9/w3//+lz///JNnnnmGNm3a4OrqSr169WjRogUAAwYMICUlhXfeeYdRo0YRHBzMffdd2l3tiy++YPDgwTRs2JCqVavy1ltvceedd+Yb35QpU3j44Ydp3rw5wcHBjB49mvhsaydMmzaN559/nscee4yzZ89Srlw5nn/+eZs6gwcP5o033mDQoEGIiIhIEVXMFwIK9kXn1bXrD8H/MX8OuwNuG27Htn2h8tBLx95l878mr0RnMT/b0Ve5JZIsFih7j/kqyH2yt9HuT3M9Mu/S5lTdgrTh6mmO7gusnX/9iwJrQoe/bMsyks3/ut3Yy25od04REcnXlXYsFLnRrVy5kvbt23Ps2LF8R+1pd86iTZ+RiIiIXAvtzikiIiK3tNTUVE6fPs24ceO4//77r3naq4iIiIgIgIuzAxARERFxhFmzZlG+fHliY2N56623nB2OiIiIiBRxSqKJiIjITWngwIFkZmayadMmypQp4+xwRERERKSIUxJNREREREREREQkH0qiiYhIgd1ie9HILUi/4yIiIiKSFyXRREQkX8WKFQMgOTnZyZGIONbF3/GLv/PiHB9++CERERF4enrStGlT1q9f7+yQRERERLQ7p4iI5M/V1ZXAwEBiYmIA8Pb2xmKxODkqEfsxDIPk5GRiYmIIDAzE1dXV2SHdsr7//nueeuopPv74Y5o2bcrUqVPp2LEjkZGRlCpVytnhiYiIyC3MYtxi8xbi4+MJCAggLi4Of39/Z4cjIlJkGIZBVFQUsbGxzg5FxGECAwMJDQ3NNUmsPkThaNq0KY0bN+aDDz4AICsri/DwcB5//HGee+65K16rz0hERESuRUH7EBqJJiIiBWKxWAgLC6NUqVKkp6c7OxwRuytWrJhGoDlZWloamzZtYsyYMdYyFxcXOnTowJo1a3LUT01NJTU11XocHx9fKHGKiIjIrUlJNBERuSqurq5KNIiIQ5w5c4bMzExCQkJsykNCQtizZ0+O+hMmTOCVV14prPBERETkFqeNBURERESkSBozZgxxcXHW17Fjx5wdkoiIiNzENBJNRERERG4IwcHBuLq6Eh0dbVMeHR1NaGhojvoeHh54eHgUVngiIiJyi9NINBERERG5Ibi7u9OwYUOWLl1qLcvKymLp0qU0a9bMiZGJiIiI3IIj0S5uRqqFZ0VERORqXOw73GIbmxe6p556igEDBtCoUSOaNGnC1KlTSUpKYtCgQfleq36eiIiIXIuC9vNuuSRaQkICAOHh4U6ORERERIqihIQEAgICnB3GTeuBBx7g9OnTjB07lqioKOrVq8fixYtzbDaQG/XzRERE5Hrk18+zGLfY16lZWVmcPHkSPz8/LBaL3duPj48nPDycY8eO4e/vb/f25cr0/J1Pn4Fz6fk7l56/czn6+RuGQUJCAqVLl8bFRSti3IjUz7v56TNwLj1/59Lzdy49f+e6Ufp5t9xINBcXF8qWLevw+/j7++sPlhPp+TufPgPn0vN3Lj1/53Lk89cItBub+nm3Dn0GzqXn71x6/s6l5+9czu7n6WtUERERERERERGRfCiJJiIiIiIiIiIikg8l0ezMw8ODl19+GQ8PD2eHckvS83c+fQbOpefvXHr+zqXnL46m3zHn02fgXHr+zqXn71x6/s51ozz/W25jARERERERERERkaulkWgiIiIiIiIiIiL5UBJNREREREREREQkH0qiiYiIiIiIiIiI5ENJNBERERERERERkXwoiWZnH374IREREXh6etK0aVPWr1/v7JCKvAkTJtC4cWP8/PwoVaoU3bt3JzIy0qZOSkoKw4cPp0SJEvj6+tKzZ0+io6Nt6hw9epSuXbvi7e1NqVKleOaZZ8jIyCjMt3JTmDhxIhaLhZEjR1rL9Pwd78SJE/Tr148SJUrg5eVF7dq12bhxo/W8YRiMHTuWsLAwvLy86NChA/v27bNp49y5c/Tt2xd/f38CAwMZPHgwiYmJhf1WipzMzExeeuklKlSogJeXF5UqVeK1117j8n159PztZ8WKFdx9992ULl0ai8XC/Pnzbc7b61lv376dVq1a4enpSXh4OG+99Zaj35rcBNTPsz/1824s6uc5h/p5zqN+XuG6Kfp5htjN7NmzDXd3d+OLL74wdu3aZTzyyCNGYGCgER0d7ezQirSOHTsaM2bMMHbu3Gls3brV6NKli1GuXDkjMTHRWmfYsGFGeHi4sXTpUmPjxo3Gf/7zH6N58+bW8xkZGUatWrWMDh06GFu2bDEWLVpkBAcHG2PGjHHGWyqy1q9fb0RERBh16tQxnnjiCWu5nr9jnTt3zihfvrwxcOBAY926dcbBgweNJUuWGPv377fWmThxohEQEGDMnz/f2LZtm3HPPfcYFSpUMC5cuGCt06lTJ6Nu3brG2rVrjZUrVxqVK1c2+vTp44y3VKSMHz/eKFGihPHLL78Yhw4dMubMmWP4+voa7777rrWOnr/9LFq0yHjhhReMuXPnGoAxb948m/P2eNZxcXFGSEiI0bdvX2Pnzp3GrFmzDC8vL+OTTz4prLcpRZD6eY6hft6NQ/0851A/z7nUzytcN0M/T0k0O2rSpIkxfPhw63FmZqZRunRpY8KECU6M6uYTExNjAMZff/1lGIZhxMbGGsWKFTPmzJljrbN7924DMNasWWMYhvmH1cXFxYiKirLWmTZtmuHv72+kpqYW7hsoohISEowqVaoYv//+u9GmTRtr50rP3/FGjx5ttGzZMs/zWVlZRmhoqDFp0iRrWWxsrOHh4WHMmjXLMAzD+OeffwzA2LBhg7XOr7/+algsFuPEiROOC/4m0LVrV+Phhx+2Kbv33nuNvn37Goah5+9I2TtX9nrWH330kREUFGTz/5/Ro0cbVatWdfA7kqJM/bzCoX6ec6if5zzq5zmX+nnOU1T7eZrOaSdpaWls2rSJDh06WMtcXFzo0KEDa9ascWJkN5+4uDgAihcvDsCmTZtIT0+3efbVqlWjXLly1me/Zs0aateuTUhIiLVOx44diY+PZ9euXYUYfdE1fPhwunbtavOcQc+/MCxYsIBGjRpx//33U6pUKerXr89nn31mPX/o0CGioqJsPoOAgACaNm1q8xkEBgbSqFEja50OHTrg4uLCunXrCu/NFEHNmzdn6dKl7N27F4Bt27axatUqOnfuDOj5FyZ7Pes1a9bQunVr3N3drXU6duxIZGQk58+fL6R3I0WJ+nmFR/0851A/z3nUz3Mu9fNuHEWln+d23S0IAGfOnCEzM9PmLw+AkJAQ9uzZ46Sobj5ZWVmMHDmSFi1aUKtWLQCioqJwd3cnMDDQpm5ISAhRUVHWOrl9NhfPyZXNnj2bzZs3s2HDhhzn9Pwd7+DBg0ybNo2nnnqK559/ng0bNvDf//4Xd3d3BgwYYH2GuT3jyz+DUqVK2Zx3c3OjePHi+gzy8dxzzxEfH0+1atVwdXUlMzOT8ePH07dvXwA9/0Jkr2cdFRVFhQoVcrRx8VxQUJBD4peiS/28wqF+nnOon+dc6uc5l/p5N46i0s9TEk2KlOHDh7Nz505WrVrl7FBuGceOHeOJJ57g999/x9PT09nh3JKysrJo1KgRb7zxBgD169dn586dfPzxxwwYMMDJ0d38fvjhB7799lu+++47atasydatWxk5ciSlS5fW8xcRsSP18wqf+nnOp36ec6mfJ1dL0zntJDg4GFdX1xw71URHRxMaGuqkqG4uI0aM4JdffmHZsmWULVvWWh4aGkpaWhqxsbE29S9/9qGhobl+NhfPSd42bdpETEwMDRo0wM3NDTc3N/766y/ee+893NzcCAkJ0fN3sLCwMGrUqGFTVr16dY4ePQpceoZX+v9PaGgoMTExNuczMjI4d+6cPoN8PPPMMzz33HP07t2b2rVr89BDD/Hkk08yYcIEQM+/MNnrWev/SXK11M9zPPXznEP9POdTP8+51M+7cRSVfp6SaHbi7u5Ow4YNWbp0qbUsKyuLpUuX0qxZMydGVvQZhsGIESOYN28ef/75Z46hmQ0bNqRYsWI2zz4yMpKjR49an32zZs3YsWOHzR+433//HX9//xx/aYmt9u3bs2PHDrZu3Wp9NWrUiL59+1p/1vN3rBYtWhAZGWlTtnfvXsqXLw9AhQoVCA0NtfkM4uPjWbdunc1nEBsby6ZNm6x1/vzzT7KysmjatGkhvIuiKzk5GRcX278uXV1dycrKAvT8C5O9nnWzZs1YsWIF6enp1jq///47VatW1VROyZX6eY6jfp5zqZ/nfOrnOZf6eTeOItPPs8v2BGIYhrn1uYeHhzFz5kzjn3/+MYYOHWoEBgba7FQjV+/RRx81AgICjOXLlxunTp2yvpKTk611hg0bZpQrV874888/jY0bNxrNmjUzmjVrZj1/cevtO++809i6dauxePFio2TJktp6+xpdvmuTYej5O9r69esNNzc3Y/z48ca+ffuMb7/91vD29ja++eYba52JEycagYGBxk8//WRs377d6NatW67bQdevX99Yt26dsWrVKqNKlSraersABgwYYJQpU8a69fncuXON4OBg49lnn7XW0fO3n4SEBGPLli3Gli1bDMCYMmWKsWXLFuPIkSOGYdjnWcfGxhohISHGQw89ZOzcudOYPXu24e3tbbetz+XmpH6eY6ifd+NRP69wqZ/nXOrnFa6boZ+nJJqdvf/++0a5cuUMd3d3o0mTJsbatWudHVKRB+T6mjFjhrXOhQsXjMcee8wICgoyvL29jR49ehinTp2yaefw4cNG586dDS8vLyM4ONh4+umnjfT09EJ+NzeH7J0rPX/H+/nnn41atWoZHh4eRrVq1YxPP/3U5nxWVpbx0ksvGSEhIYaHh4fRvn17IzIy0qbO2bNnjT59+hi+vr6Gv7+/MWjQICMhIaEw30aRFB8fbzzxxBNGuXLlDE9PT6NixYrGCy+8YLNttp6//SxbtizX/+cPGDDAMAz7Pett27YZLVu2NDw8PIwyZcoYEydOLKy3KEWY+nn2p37ejUf9vMKnfp7zqJ9XuG6Gfp7FMAzj+seziYiIiIiIiIiI3Ly0JpqIiIiIiIiIiEg+lEQTERERERERERHJh5JoIiIiIiIiIiIi+VASTUREREREREREJB9KoomIiIiIiIiIiORDSTQREREREREREZF8KIkmIiIiIiIiIiKSDyXRRERERERERERE8qEkmoiIHVgsFubPn+/sMERERETEztTPE5GLlEQTkSJv4MCBWCyWHK9OnTo5OzQRERERuQ7q54nIjcTN2QGIiNhDp06dmDFjhk2Zh4eHk6IREREREXtRP09EbhQaiSYiNwUPDw9CQ0NtXkFBQYA5BH/atGl07twZLy8vKlasyI8//mhz/Y4dO2jXrh1eXl6UKFGCoUOHkpiYaFPniy++oGbNmnh4eBAWFsaIESNszp85c4YePXrg7e1NlSpVWLBggWPftIiIiMgtQP08EblRKIkmIreEl156iZ49e7Jt2zb69u1L79692b17NwBJSUl07NiRoKAgNmzYwJw5c/jjjz9sOk/Tpk1j+PDhDB06lB07drBgwQIqV65sc49XXnmFXr16sX37drp06ULfvn05d+5cob5PERERkVuN+nkiUmgMEZEibsCAAYarq6vh4+Nj8xo/frxhGIYBGMOGDbO5pmnTpsajjz5qGIZhfPrpp0ZQUJCRmJhoPb9w4ULDxcXFiIqKMgzDMEqXLm288MILecYAGC+++KL1ODEx0QCMX3/91W7vU0RERORWo36eiNxItCaaiNwUbr/9dqZNm2ZTVrx4cevPzZo1sznXrFkztm7dCsDu3bupW7cuPj4+1vMtWrQgKyuLyMhILBYLJ0+epH379leMoU6dOtaffXx88Pf3JyYm5lrfkoiIiIigfp6I3DiURBORm4KPj0+OYff24uXlVaB6xYoVszm2WCxkZWU5IiQRERGRW4b6eSJyo9CaaCJyS1i7dm2O4+rVqwNQvXp1tm3bRlJSkvX86tWrcXFxoWrVqvj5+REREcHSpUsLNWYRERERyZ/6eSJSWDQSTURuCqmpqURFRdmUubm5ERwcDMCcOXNo1KgRLVu25Ntvv2X9+vVMnz4dgL59+/Lyyy8zYMAAxo0bx+nTp3n88cd56KGHCAkJAWDcuHEMGzaMUqVK0blzZxISEli9ejWPP/544b5RERERkVuM+nkicqNQEk1EbgqLFy8mLCzMpqxq1ars2bMHMHdUmj17No899hhhYWHMmjWLGjVqAODt7c2SJUt44oknaNy4Md7e3vTs2ZMpU6ZY2xowYAApKSm88847jBo1iuDgYO67777Ce4MiIiIityj180TkRmExDMNwdhAiIo5ksViYN28e3bt3d3YoIiIiImJH6ueJSGHSmmgiIiIiIiIiIiL5UBJNREREREREREQkH5rOKSIiIiIiIiIikg+NRBMREREREREREcmHkmgiIiIiIiIiIiL5UBJNREREREREREQkH0qiiYiIiIiIiIiI5ENJNBERERERERERkXwoiSYiIiIiIiIiIpIPJdFERERERERERETyoSSaiIiIiIiIiIhIPv4fJlO+i6gSroAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "num_epochs = model_history.shape[0]\n",
    "ax[0].plot(np.arange(0, num_epochs), model_history['accuracy'], label='Training Accuracy', lw=3, color='blue')\n",
    "ax[0].plot(np.arange(0, num_epochs), model_history['val_accuracy'], label='Validation Accuracy', lw=3, color='red')\n",
    "ax[1].plot(np.arange(0, num_epochs), model_history['loss'], label='Training Loss', lw=3, color='green')\n",
    "ax[1].plot(np.arange(0, num_epochs), model_history['val_loss'], label='Validation Loss', lw=3, color='orange')\n",
    "ax[0].set_title('Training and Validation Accuracy')\n",
    "ax[1].set_title('Loss and Validation Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend()\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4000\n",
      "Accuracy: 0.9254\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "Como podemos observar, existe una gran evolución en la precisión de la red neuronal según van avanzando las épocas, además de observar una disminución de la función de pérdida de forma considerable hasta conseguir una estabilización a partir de las 400 épocas.\n",
    "\n",
    "Adicionalmente, el modelo es capaz de predecir correctamente el 92,54% de los resultados del dataset de entrenamiento por lo que podemos considerar que se trata de un modelo bastante preciso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6517ef4d065b964775f7ded66e8332ac26eb91a9f9628f14f6a82a0ec9e672ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
