{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines y Naive Bayes\n",
    "Actividad Lección 7 || Programación Python para Machine Learning\n",
    "\n",
    "Objetivos:\n",
    "* Conocer los principios de las Máquinas de Vectores Soporte (SVM)\n",
    "* Saber implementar en Python modelos de SVM para resolver problemas de clasificación y regresión\n",
    "\n",
    "Datos del alumno:\n",
    "* Víctor Luque Martín\n",
    "* Máster Avanzado en Programación en Python para Hacking, BigData y Machine Learning\n",
    "\n",
    "Fecha: 16/12/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de Contenidos\n",
    "1. [Importes](#importes)\n",
    "2. [Carga del dataset](#carga)\n",
    "3. [Conteo de Clases](#conteo)\n",
    "    1. [Analisis de los datos](#analisis)\n",
    "4. [Segmentación del conjunto de datos](#segmentacion)\n",
    "5. [Normalización](#normalizacion)\n",
    "6. [Máquinas de Vectores Soporte (SVM)](#svm)\n",
    "7. [Evaluación del modelo](#evaluacion)\n",
    "8. [Optimizando SVM](#optimizando)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importes <a name=\"importes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del dataset <a class=\"anchor\" name=\"carga\"></a>\n",
    "Se carga el dataset [Climate Model Simulation Crashes](https://archive.ics.uci.edu/ml/datasets/climate+model+simulation+crashes#) para trabajar la implementación de modelos SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Run</th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>...</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>0.298838</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.567947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.104226</td>\n",
       "      <td>0.869091</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.796997</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606041</td>\n",
       "      <td>0.457728</td>\n",
       "      <td>0.359448</td>\n",
       "      <td>0.306957</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.934851</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616870</td>\n",
       "      <td>0.975786</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.845247</td>\n",
       "      <td>0.864152</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.356573</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.512256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.618903</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.195928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.803413</td>\n",
       "      <td>0.643995</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.924775</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.365858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.421837</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.490828</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471463</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>0.362751</td>\n",
       "      <td>0.912819</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.475987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.844798</td>\n",
       "      <td>0.441502</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.487546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551543</td>\n",
       "      <td>0.743877</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.650223</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.132283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>0.657136</td>\n",
       "      <td>0.489375</td>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.411950</td>\n",
       "      <td>0.087780</td>\n",
       "      <td>0.356289</td>\n",
       "      <td>0.480204</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280546</td>\n",
       "      <td>0.384117</td>\n",
       "      <td>0.885948</td>\n",
       "      <td>0.768482</td>\n",
       "      <td>0.459479</td>\n",
       "      <td>0.334482</td>\n",
       "      <td>0.573002</td>\n",
       "      <td>0.610183</td>\n",
       "      <td>0.737706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>0.915894</td>\n",
       "      <td>0.842720</td>\n",
       "      <td>0.518947</td>\n",
       "      <td>0.090622</td>\n",
       "      <td>0.336981</td>\n",
       "      <td>0.893576</td>\n",
       "      <td>0.978703</td>\n",
       "      <td>0.674868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798108</td>\n",
       "      <td>0.353546</td>\n",
       "      <td>0.044796</td>\n",
       "      <td>0.990900</td>\n",
       "      <td>0.347027</td>\n",
       "      <td>0.512499</td>\n",
       "      <td>0.810549</td>\n",
       "      <td>0.593332</td>\n",
       "      <td>0.142565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.941185</td>\n",
       "      <td>0.769245</td>\n",
       "      <td>0.950776</td>\n",
       "      <td>0.189406</td>\n",
       "      <td>0.112743</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.527096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193103</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.101506</td>\n",
       "      <td>0.548878</td>\n",
       "      <td>0.381966</td>\n",
       "      <td>0.198811</td>\n",
       "      <td>0.867108</td>\n",
       "      <td>0.461632</td>\n",
       "      <td>0.652817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.779287</td>\n",
       "      <td>0.867468</td>\n",
       "      <td>0.704820</td>\n",
       "      <td>0.983282</td>\n",
       "      <td>0.420303</td>\n",
       "      <td>0.710612</td>\n",
       "      <td>0.174746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.436714</td>\n",
       "      <td>0.690132</td>\n",
       "      <td>0.825133</td>\n",
       "      <td>0.981656</td>\n",
       "      <td>0.113193</td>\n",
       "      <td>0.364799</td>\n",
       "      <td>0.201469</td>\n",
       "      <td>0.536535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.608075</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>0.598264</td>\n",
       "      <td>0.794771</td>\n",
       "      <td>0.145680</td>\n",
       "      <td>0.378183</td>\n",
       "      <td>0.461948</td>\n",
       "      <td>0.425291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480938</td>\n",
       "      <td>0.307816</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>0.464152</td>\n",
       "      <td>0.583558</td>\n",
       "      <td>0.969365</td>\n",
       "      <td>0.464331</td>\n",
       "      <td>0.760344</td>\n",
       "      <td>0.762439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Study  Run  vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  \\\n",
       "0        1    1     0.859036  0.927825  0.252866  0.298838  0.170521   \n",
       "1        1    2     0.606041  0.457728  0.359448  0.306957  0.843331   \n",
       "2        1    3     0.997600  0.373238  0.517399  0.504993  0.618903   \n",
       "3        1    4     0.783408  0.104055  0.197533  0.421837  0.742056   \n",
       "4        1    5     0.406250  0.513199  0.061812  0.635837  0.844798   \n",
       "..     ...  ...          ...       ...       ...       ...       ...   \n",
       "535      3  176     0.657136  0.489375  0.133713  0.411950  0.087780   \n",
       "536      3  177     0.915894  0.842720  0.518947  0.090622  0.336981   \n",
       "537      3  178     0.478600  0.941185  0.769245  0.950776  0.189406   \n",
       "538      3  179     0.007793  0.779287  0.867468  0.704820  0.983282   \n",
       "539      3  180     0.608075  0.031556  0.598264  0.794771  0.145680   \n",
       "\n",
       "     vconst_7   ah_corr  ah_bolus  ...  efficiency_factor  tidal_mix_max  \\\n",
       "0    0.735936  0.428325  0.567947  ...           0.245675       0.104226   \n",
       "1    0.934851  0.444572  0.828015  ...           0.616870       0.975786   \n",
       "2    0.605571  0.746225  0.195928  ...           0.679355       0.803413   \n",
       "3    0.490828  0.005525  0.392123  ...           0.471463       0.597879   \n",
       "4    0.441502  0.191926  0.487546  ...           0.551543       0.743877   \n",
       "..        ...       ...       ...  ...                ...            ...   \n",
       "535  0.356289  0.480204  0.029678  ...           0.280546       0.384117   \n",
       "536  0.893576  0.978703  0.674868  ...           0.798108       0.353546   \n",
       "537  0.112743  0.745645  0.527096  ...           0.193103       0.829563   \n",
       "538  0.420303  0.710612  0.174746  ...           0.761134       0.436714   \n",
       "539  0.378183  0.461948  0.425291  ...           0.480938       0.307816   \n",
       "\n",
       "     vertical_decay_scale  convect_corr  bckgrnd_vdc1  bckgrnd_vdc_ban  \\\n",
       "0                0.869091      0.997518      0.448620         0.307522   \n",
       "1                0.914344      0.845247      0.864152         0.346713   \n",
       "2                0.643995      0.718441      0.924775         0.315371   \n",
       "3                0.761659      0.362751      0.912819         0.977971   \n",
       "4                0.312349      0.650223      0.522261         0.043545   \n",
       "..                    ...           ...           ...              ...   \n",
       "535              0.885948      0.768482      0.459479         0.334482   \n",
       "536              0.044796      0.990900      0.347027         0.512499   \n",
       "537              0.101506      0.548878      0.381966         0.198811   \n",
       "538              0.690132      0.825133      0.981656         0.113193   \n",
       "539              0.231638      0.464152      0.583558         0.969365   \n",
       "\n",
       "     bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  outcome  \n",
       "0          0.858310          0.796997  0.869893        0  \n",
       "1          0.356573          0.438447  0.512256        1  \n",
       "2          0.250642          0.285636  0.365858        1  \n",
       "3          0.845921          0.699431  0.475987        1  \n",
       "4          0.376660          0.280098  0.132283        1  \n",
       "..              ...               ...       ...      ...  \n",
       "535        0.573002          0.610183  0.737706        1  \n",
       "536        0.810549          0.593332  0.142565        0  \n",
       "537        0.867108          0.461632  0.652817        1  \n",
       "538        0.364799          0.201469  0.536535        1  \n",
       "539        0.464331          0.760344  0.762439        1  \n",
       "\n",
       "[540 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pop_failures.dat', sep='\\s+')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conteo de Clases <a class=\"anchor\" name=\"conteo\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['outcome'].value_counts().plot(kind='bar')\n",
    "for i, v in enumerate(df['outcome'].value_counts()):\n",
    "    plt.text(i, v, str(v), color='black', ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los datos <a class=\"anchor\" name=\"analisis\"></a>\n",
    "* Como podemos observar, estamos ante un problema de clasificación binaria.\n",
    "* Además, existe un desequilibrio de clases, siendo la clase 1 la que más se repite y la clase 0 la que menos. \n",
    "* Esto puede ser un problema para el modelo, ya que puede aprender a clasificar la clase 1 y no la clase 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentación del conjnto de datos <a class=\"anchor\" name=\"segmentacion\"></a>\n",
    "* Las variables independientes son todas salvo \"outcome\", \"Study\" y \"Run\", según la descripción del dataset.\n",
    "* La variable dependiente es \"outcome\", que indica si el modelo ha fallado o no.\n",
    "* Se separa el conjunto de datos en dos conjuntos: uno de entrenamiento y otro de test.\n",
    "* El conjunto de entrenamiento se utilizará para entrenar el modelo.\n",
    "* El conjunto de test se utilizará para evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['outcome', \"Study\", \"Run\"])\n",
    "y = df[\"outcome\"]\n",
    "seed = random.seed(time.time())\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización de los datos <a class=\"anchor\" name=\"normalizacion\"></a>\n",
    "* Los datos del dataset se encuentran escalados entre 0 y 1.\n",
    "* Se utilizará StandardScaler para normalizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquinas de Vectores Soporte (SVM) <a class=\"anchor\" name=\"svm\"></a>\n",
    "Las Máquinas de Vectores Soporte son un tipo de modelo supervisado de Machine Learning para resolver problemas de clasificación y de regresión con carácter no lineal. Para declarar un SVM se debe importar el tipo de SVM de la librería sklearn, al tratar con un problema de clasificación, haremos uso de `sklear.svm.SVC`.\n",
    "\n",
    "Los hiperparámetros **kernel**, **$\\gamma$** y **C**, influyen en el comportamiento del modelo, inicialmente se seleccionan unos aleatorios y posteriormente se optimizará el modelo encontrando los valores más optimos de estos tres hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='sigmoid', gamma=0.1, C=1.0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo <a class=\"anchor\" name=\"evaluacion\"></a>\n",
    "Utilizando la validación cruzada K-Fold, se evaluará el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KFold Balanced Accuracy Mean</th>\n",
       "      <th>KFold Balanced Accuracy Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.84266</td>\n",
       "      <td>0.045777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     KFold Balanced Accuracy Mean  KFold Balanced Accuracy Std\n",
       "SVM                       0.84266                     0.045777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = random.seed(time.time())\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='balanced_accuracy')\n",
    "df_results = pd.DataFrame({'KFold Balanced Accuracy Mean': results.mean(), \n",
    "                           'KFold Balanced Accuracy Std': results.std()}, \n",
    "                          index=[\"SVM\"])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizando SVM <a class=\"anchor\" name=\"optimizando\"></a>\n",
    "Reutilizando la validación cruzada K-Fold, se emplarán diferentes valores de para ver cuál es el que mejor rendimiento tiene. Los parámetros para realizar el entrenamiento son:\n",
    "* **kernel**: linear, poly, rbf, sigmoid\n",
    "* **C**: Del 1 al 10\n",
    "* **$\\gamma$**: Del 1 al 10\n",
    "\n",
    "Se generarán un total de 400 modelos y se seleccionará aquel cuyo error en la métrica de la precisión balanceada sea menor.\n",
    "\n",
    "$$\\text{Error} = 1 - \\text{Preción Balanceada}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>Error Precisión Balanceada</th>\n",
       "      <th>Desviación Estándar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.096315</td>\n",
       "      <td>0.048255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  C  gamma  Error Precisión Balanceada  Desviación Estándar\n",
       "7  linear  1      8                    0.096315             0.048255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=[\"kernel\", 'C', 'gamma', 'Error Precisión Balanceada', \"Desviación Estándar\"])\n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for C in range(1, 10):\n",
    "        for gamma in range(1, 10):\n",
    "            model = SVC(C=C, kernel=kernel, gamma=gamma, class_weight='balanced')\n",
    "            res = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='balanced_accuracy')\n",
    "            results.loc[len(results)] = [kernel, C, gamma, 1 - res.mean(), res.std()]\n",
    "\n",
    "results.nsmallest(1, ['Error Precisión Balanceada', \"Desviación Estándar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo de entre los 400 generados es aquel cuyos hiperparámetros son:\n",
    "* **kernel**: linear\n",
    "* **C**: 1\n",
    "* **$\\gamma$**: 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1634370e120a9c1df39eabce3cbeacd65fdf9bf1deaa79a301a3f714c9fcff5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
