{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y Evaluación\n",
    "Actividad Lección 2 || Fundamentos de IA y Machine Learning\n",
    "\n",
    "Objetivos:\n",
    "* Aplicar conceptos teóricos vistos en clase\n",
    "\n",
    "Datos del alumno:\n",
    "* Víctor Luque Martín\n",
    "* Máster Avanzado en Programación en Python para Hacking, BigData y Machine Learning\n",
    "\n",
    "Fecha: 21/10/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de contenidos:\n",
    "1. [Métricas de regresión](#m-regresion)\n",
    "    1. [Error absoluto medio](#m-regresion-mae)\n",
    "    2. [Error cuadrático medio](#m-regresion-mse)\n",
    "    3. [Raíz cuadrada del error cuadrático medio](#m-regresion-rmse)\n",
    "    4. [Coeficiente de determinación](#m-regresion-r2)\n",
    "    5. [Comparación de modelos](#m-regresion-comparacion)\n",
    "2. [Métricas de clasificación binaria](#m-clasificacion-b)\n",
    "    1. [Matriz de confusión](#m-clasificacion-b-mc)\n",
    "    2. [Precision Global (CCR)](#m-clasificacion-b-pg)\n",
    "    3. [Sensibilidad (TPR)](#m-clasificacion-b-s)\n",
    "    4. [False Positive Rate (FPR)](#m-clasificacion-b-fpr)\n",
    "    5. [Especificidad (TNR)](#m-clasificacion-b-e)\n",
    "    6. [Precision (PPV)](#m-clasificacion-b-p)\n",
    "    7. [F1 Score](#m-clasificacion-b-f1)\n",
    "    8. [Kappa](#m-clasificacion-b-k)\n",
    "    9. [Comparación de modelos](#m-clasificacion-b-cm)\n",
    "3. [Métricas de clasificación multiclase](#m-clasificacion-m)\n",
    "    1. [Matriz de confusión para cada clase](#m-clasificacion-m-mc)\n",
    "    2. [Precision Global (CCR)](#m-clasificacion-m-pg)\n",
    "    3. [Sensibilidad (TPR)](#m-clasificacion-m-s)\n",
    "    4. [False Positive Rate (FPR)](#m-clasificacion-m-fpr)\n",
    "    5. [Especificidad (TNR)](#m-clasificacion-m-e)\n",
    "    6. [Precision (PPV)](#m-clasificacion-m-p)\n",
    "    7. [F1 Score](#m-clasificacion-m-f1)\n",
    "    8. [Kappa](#m-clasificacion-m-k)\n",
    "    9. [Valoración del modelo](#m-clasificacion-m-vm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos uso de la librería de Pandas para poder trabajar con los datos de forma más cómoda.\n",
    "No obstante las operaciones se harán de manera manual aplicando las fórmulas vistas en clase, sin utilizar librerías adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Métricas de regresión <a class=\"anchor\" id=\"m-regresion\"></a>\n",
    "Dado un conjunto de 30 datos de test, con la variable objetivo real y la salida proporcionada por dos modelos, se pide:\n",
    "* Calcular las métricas de regresión para cada modelo\n",
    "* En función de los resultados, decidir qué modelo es mejor.\n",
    "\n",
    "Utilizaremos el siguiente set de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y objetivo</th>\n",
       "      <th>Predicciones M1</th>\n",
       "      <th>Predicciones M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.00</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.56</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.00</td>\n",
       "      <td>7.80</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.90</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.60</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.50</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.20</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y objetivo  Predicciones M1  Predicciones M2\n",
       "0         2.50             3.00              2.0\n",
       "1         3.00             2.90              2.0\n",
       "2         1.60             2.00              2.0\n",
       "3         8.00             8.10              7.0\n",
       "4         4.56             4.00              5.0\n",
       "5         5.25             5.00              5.0\n",
       "6         7.00             7.80              8.0\n",
       "7         5.25             6.00              5.0\n",
       "8         6.50             6.00              7.0\n",
       "9        10.50            10.00             11.0\n",
       "10       25.00            10.00             24.0\n",
       "11        2.30             2.00              2.0\n",
       "12        5.40             5.00              6.0\n",
       "13        6.80             7.00              8.0\n",
       "14        7.90             8.50              8.5\n",
       "15        4.50             4.00              5.0\n",
       "16        3.50             4.00              5.0\n",
       "17        3.00             4.50              4.5\n",
       "18        2.00             2.50              3.0\n",
       "19        1.00             1.23              0.9\n",
       "20        0.00             1.00              0.5\n",
       "21        5.60             5.00              6.0\n",
       "22        7.00             6.80              7.3\n",
       "23        8.50             9.60              9.0\n",
       "24        9.00            10.20             10.0\n",
       "25       10.20            10.00             10.0\n",
       "26        5.00             4.90              5.2\n",
       "27        4.30             4.00              4.6\n",
       "28        2.00             0.00              1.9\n",
       "29        4.30             4.00              5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regresion = pd.read_csv(\"l2p1.csv\")\n",
    "df_regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Error absoluto medio <a class=\"anchor\" id=\"m-regresion-mae\"></a>\n",
    "El **error absoluto medio (Mean Absolute Error, MAE)** es la media de las diferencias absolutas entre el valor predicho y el real. Da una idea de cómo de erróneas fueron las predicciones, y de la magnitud de error pero no de su dirección. Un inconveniente es que no penaliza los grandes errores. Así, siendo 𝑛𝑛 el número de patrones del conjunto, el MAE se define como:\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formula de MAE en Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_absoluto_medio(y_objetivo, prediccion):\n",
    "    # Declaramos la variable del sumatorio\n",
    "    sumatorio = 0\n",
    "    # Utilizamos zip() para recorrer las dos columnas a la vez\n",
    "    for y, m in zip(y_objetivo, prediccion):\n",
    "        # Calculamos el valor absoluto de la resta y lo sumamos al sumatorio\n",
    "        sumatorio += abs(y - m)\n",
    "\n",
    "    # Calculamos el error absoluto medio\n",
    "    return sumatorio / len(y_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error absoluto medio del modelo 1:  1.0396666666666665\n",
      "Error absoluto medio del modelo 2:  0.6113333333333333\n"
     ]
    }
   ],
   "source": [
    "mae_m1 = error_absoluto_medio(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M1\"])\n",
    "mae_m2 = error_absoluto_medio(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M2\"])\n",
    "print(\"Error absoluto medio del modelo 1: \", mae_m1)\n",
    "print(\"Error absoluto medio del modelo 2: \", mae_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Error cuadrático medio <a class=\"anchor\" id=\"m-regresion-mse\"></a>\n",
    "El **error cuadrático medio (Mean Squared Error, MSE)** es la media de las diferencias de los errores al cuadrado. Es muy utilizado ya que es derivable y además, penaliza los errores más grandes. El MSE se define de la siguiente forma:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función de MSE en Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_cuadratico_medio(y_objetivo, prediccion):\n",
    "    # Declaramos la variable del sumatorio\n",
    "    sumatorio = 0\n",
    "    # Utilizamos zip() para recorrer las dos columnas a la vez\n",
    "    for y, m in zip(y_objetivo, prediccion):\n",
    "        # Calculamos el cuadrado de la resta y lo sumamos al sumatorio\n",
    "        sumatorio += (y - m) ** 2\n",
    "\n",
    "    # Calculamos el error absoluto medio\n",
    "    return sumatorio / len(y_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio del modelo 1:  7.98305\n",
      "Error cuadrático medio del modelo 2:  0.5219533333333334\n"
     ]
    }
   ],
   "source": [
    "mse_m1 = error_cuadratico_medio(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M1\"])\n",
    "mse_m2 = error_cuadratico_medio(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M2\"])\n",
    "print(\"Error cuadrático medio del modelo 1: \", mse_m1)\n",
    "print(\"Error cuadrático medio del modelo 2: \", mse_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Raíz cuadrada del error cuadrático medio <a class=\"anchor\" id=\"m-regresion-rmse\"></a>\n",
    "La **raíz cuadrada del error cuadrático medio (Root Mean Squared Error, RMSE)** es la raíz cuadrada del MSE. Es una medida de error muy utilizada ya que es interpretable en las mismas unidades que la variable objetivo. El RMSE se define como:\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función RMSE en Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raiz_cuadrada_error_cuadratico_medio(y_objetivo, prediccion):\n",
    "    # Obtenemos el error cuadrático medio\n",
    "    mse = error_cuadratico_medio(y_objetivo, prediccion)\n",
    "    # Devolvemos la raíz cuadrada del error cuadrático medio\n",
    "    return mse ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raíz cuadrada del error cuadrático medio del modelo 1:  2.825429170940231\n",
      "Raíz cuadrada del error cuadrático medio del modelo 2:  0.7224633785413164\n"
     ]
    }
   ],
   "source": [
    "rmse_m1 = raiz_cuadrada_error_cuadratico_medio(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M1\"])\n",
    "rmse_m2 = raiz_cuadrada_error_cuadratico_medio(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M2\"])\n",
    "print(\"Raíz cuadrada del error cuadrático medio del modelo 1: \", rmse_m1)\n",
    "print(\"Raíz cuadrada del error cuadrático medio del modelo 2: \", rmse_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Coeficiente de determinación <a class=\"anchor\" id=\"m-regresion-r2\"></a>\n",
    "El **coeficiente de determinación (R2)** nos proporciona una medida de calidad del modelo para predecir los resultados. Está acotado entre 0 y 1, según no se ajuste o se ajuste a los datos, respectivamente. Se calcula de la siguiente forma:\n",
    "\n",
    "$$R^2= \\frac{\\sigma_{y,\\hat{y}}^2}{\\sigma_{y}^2\\sigma_{\\hat{y}}^2} = \\frac{\\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función R2 en Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeficiente_de_determinacion(y_objetivo, prediccion):\n",
    "    # Calculamos la media de y_objetivo\n",
    "    media_y = sum(y_objetivo) / len(y_objetivo)\n",
    "    numerador = 0\n",
    "    denominador = 0\n",
    "\n",
    "    for y, m in zip(y_objetivo, prediccion):\n",
    "        # Calculamos el numerador\n",
    "        numerador += (m - media_y) ** 2\n",
    "        # Calculamos el denominador\n",
    "        denominador += (y - media_y) ** 2\n",
    "\n",
    "    # Calculamos el coeficiente de determinación\n",
    "    return numerador / denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de determinación (R^2) del modelo 1:  0.4313000476245028\n",
      "Coeficiente de determinación (R^2) del modelo 2:  0.9498102406115213\n"
     ]
    }
   ],
   "source": [
    "r2_m1 = coeficiente_de_determinacion(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M1\"])\n",
    "r2_m2 = coeficiente_de_determinacion(df_regresion[\"Y objetivo\"], df_regresion[\"Predicciones M2\"])\n",
    "\n",
    "print(\"Coeficiente de determinación (R^2) del modelo 1: \", r2_m1)\n",
    "print(\"Coeficiente de determinación (R^2) del modelo 2: \", r2_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Comparación de modelos <a class=\"anchor\" id=\"m-regresion-comparacion\"></a>\n",
    "En función de los resultados obtenidos, podemos concluir que el modelo 1 es mejor que el modelo 2 porque al calcular los errores MAE, MSE y RMSE, el modelo 2 tiene resultados más cercanos a 0 y el coeficiente de determinación en el modelo 2 es mucho más cercano a 1 que en el modelo 1. \n",
    "\n",
    "A continuación, se muestran los resultados obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo 1</th>\n",
       "      <td>1.039667</td>\n",
       "      <td>7.983050</td>\n",
       "      <td>2.825429</td>\n",
       "      <td>0.43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelo 2</th>\n",
       "      <td>0.611333</td>\n",
       "      <td>0.521953</td>\n",
       "      <td>0.722463</td>\n",
       "      <td>0.94981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE       MSE      RMSE      R^2\n",
       "Modelo 1  1.039667  7.983050  2.825429  0.43130\n",
       "Modelo 2  0.611333  0.521953  0.722463  0.94981"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\"MAE\": mae_m1, \"MSE\": mse_m1, \"RMSE\": rmse_m1, \"R^2\": r2_m1},\n",
    "    {\"MAE\": mae_m2, \"MSE\": mse_m2, \"RMSE\": rmse_m2, \"R^2\": r2_m2}, \n",
    "]\n",
    "df_metricas_regresion = pd.DataFrame(data, index=[\"Modelo 1\", \"Modelo 2\"])\n",
    "df_metricas_regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Métricas de clasificación binaria <a class=\"anchor\" id=\"m-clasificacion-b\"></a>\n",
    "Dado un problema de clasificación binaria (sólo existen dos clases), tenemos la salida de cada uno de 30 patrones en test para dos modelos distintos.\n",
    "* Montar la matriz de confusión de cada modelo.\n",
    "* Calcular las métricas de clasificación, excepto el AUC.\n",
    "* Determinar qué modelo es mejor.\n",
    "\n",
    "Utilizaremos el siguiente set de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clase Objetivo</th>\n",
       "      <th>Predicciones M1</th>\n",
       "      <th>Predicciones M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Clase Objetivo  Predicciones M1  Predicciones M2\n",
       "0                0                1                0\n",
       "1                0                0                0\n",
       "2                0                0                0\n",
       "3                1                1                1\n",
       "4                1                1                1\n",
       "5                1                1                1\n",
       "6                0                0                0\n",
       "7                0                0                1\n",
       "8                1                0                1\n",
       "9                1                0                1\n",
       "10               0                0                1\n",
       "11               1                1                0\n",
       "12               0                0                1\n",
       "13               1                1                1\n",
       "14               1                0                1\n",
       "15               1                1                1\n",
       "16               1                0                1\n",
       "17               0                0                0\n",
       "18               0                0                0\n",
       "19               0                0                0\n",
       "20               0                0                0\n",
       "21               0                0                1\n",
       "22               0                0                1\n",
       "23               0                0                0\n",
       "24               0                0                0\n",
       "25               0                0                0\n",
       "26               0                0                1\n",
       "27               0                0                0\n",
       "28               0                0                1\n",
       "29               0                0                1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clasificacion_binaria = pd.read_csv(\"l2p2.csv\")\n",
    "df_clasificacion_binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Matriz de confusión <a class=\"anchor\" id=\"m-clasificacion-b-mc\"></a>\n",
    "La **matriz de confusión** es una tabla que muestra el número de predicciones correctas e incorrectas para cada clase. Se utiliza para evaluar la calidad de un modelo de clasificación.\n",
    "\n",
    "Viene definida de la siguiente forma:\n",
    "\n",
    "<table><thead><tr><th></th><th></th><th colspan=\"2\">Clase Predicha</th></tr></thead><tbody><tr><td></td><td></td><td>Clase Positiva</td><td>Clase Negativa</td></tr><tr><td rowspan=\"2\"><br>Clase<br><br>Real</td><td>Clase<br>Positiva</td><td>TP</td><td>FN</td></tr><tr><td>Clase<br>Negativa</td><td>FP</td><td>TN</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para crear la tabla de la Matríz de confusion**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_confusion(y_objetivo, prediccion):\n",
    "    # Declaramos los campos TN, FP, FN y TP\n",
    "    tn, fp, fn, tp = 0,0,0,0\n",
    "    # Calculamos para cada par y, m si se trata de un TN, FP, FN o TP\n",
    "    # Siendo y, el valor de la columan y_objetivo\n",
    "    # Siendo m el valor de la columna de predicción (modelo)\n",
    "    for y, m in zip(y_objetivo, prediccion):\n",
    "        # Si el par es 0, 0 => TN\n",
    "        if y == 0 and m == 0:\n",
    "            tn += 1\n",
    "        # Si el par es 0, 1 => FP\n",
    "        elif y == 0 and m == 1:\n",
    "            fp += 1\n",
    "        # Si el par es 1, 0 => FN\n",
    "        elif y == 1 and m == 0:\n",
    "            fn += 1\n",
    "        # Si el par es 1, 1 => TP\n",
    "        elif y == 1 and m == 1:\n",
    "            tp += 1\n",
    "    # Construcción de la matriz de confusión\n",
    "    matriz = pd.DataFrame([[tp, fp], [fn, tn]], index=[\"Positivo\", \"Negativo\"], columns=[\"Positivo\", \"Negativo\"])\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positivo</th>\n",
       "      <th>Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positivo  Negativo\n",
       "Positivo         6         1\n",
       "Negativo         4        19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_m1 = matriz_confusion(df_clasificacion_binaria[\"Clase Objetivo\"], df_clasificacion_binaria[\"Predicciones M1\"])\n",
    "matriz_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positivo</th>\n",
       "      <th>Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positivo  Negativo\n",
       "Positivo         9         8\n",
       "Negativo         1        12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_m2 = matriz_confusion(df_clasificacion_binaria[\"Clase Objetivo\"], df_clasificacion_binaria[\"Predicciones M2\"])\n",
    "matriz_m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Precisión Global (CCR) <a class=\"anchor\" id=\"m-clasificacion-b-pg\"></a>\n",
    "La precisión global es el porcentaje de patrones correctamente clasificados. También se conoce por Accuracy o CCR por sus siglas en inglés.\n",
    "\n",
    "$$\\text{CCR} = \\frac{\\text{Suma Diagonal Principal}}{\\text{Suma Elementos Matriz}} = \\frac{\\sum_{i=1}^n a_{ii}}{\\sum_{i=1}^n\\sum_{j=1}^n a_{ij}}$$\n",
    "\n",
    "En un problema multiclase, la precisión global se calcula como la suma de los elementos de la diagonal principal (instancias bien clasificadas) entre la suma de todos los elementos de la matriz de confusión (número total de patrones).\n",
    "\n",
    "Es una métrica muy útil cuando la base de datos está balanceada. Sin embargo, en problemas no balanceados tiene la siguiente limitación. Supongamos un problema con dos clases, donde hay 9990 patrones de la clase 1 y sólo 10 patrones de la clase 2. Si el modelo siempre dice que los ejemplos son de la clase 1, su precisión global es del 99.9%. En este caso, la métrica es totalmente engañosa ya que nunca se detectará ningún patrón de la clase 2, que posiblemente sea la más interesante de clasificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular la precisión global**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_global(matriz):\n",
    "    confusion = matriz.copy()\n",
    "    columnas = confusion.columns\n",
    "    filas = confusion.index\n",
    "    suma_matriz = confusion.sum().sum()\n",
    "    numerador = 0\n",
    "    for c, f in zip(columnas, filas):\n",
    "        # Si la posición de la columna es igual a la posición de la fila\n",
    "        # Sumamos el valor de la posición a numerador\n",
    "        if columnas.get_loc(c) == filas.get_loc(f):\n",
    "            numerador += confusion[c][f]\n",
    "    # Finalmente divimos entre la suma de todos los valores de la matriz\n",
    "    return numerador / suma_matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCR del modelo 1:  0.8333333333333334\n",
      "CCR del modelo 2:  0.7\n"
     ]
    }
   ],
   "source": [
    "ccr_m1 = precision_global(matriz_m1)\n",
    "ccr_m2 = precision_global(matriz_m2)\n",
    "print(\"CCR del modelo 1: \", ccr_m1)\n",
    "print(\"CCR del modelo 2: \", ccr_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Sensibilidad (TPR) <a class=\"anchor\" id=\"m-clasificacion-b-s\"></a>\n",
    "La **sensibilidad** es el porcentaje de patrones de la clase positiva que son correctamente clasificados.<br>\n",
    "También se conoce por Recall o TPR por sus siglas en inglés.<br>\n",
    "\n",
    "$$\\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular la sensibilidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensibilidad(confusion):\n",
    "    # TP / (TP + FN)\n",
    "    return confusion[\"Positivo\"][\"Positivo\"] / \\\n",
    "           (confusion[\"Positivo\"][\"Positivo\"] + confusion[\"Negativo\"][\"Positivo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad (TPR) del modelo 1:  0.8571428571428571\n",
      "Sensibilidad (TPR) del modelo 2:  0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "tpr_m1 = sensibilidad(matriz_m1)\n",
    "tpr_m2 = sensibilidad(matriz_m2)\n",
    "print(\"Sensibilidad (TPR) del modelo 1: \", tpr_m1)\n",
    "print(\"Sensibilidad (TPR) del modelo 2: \", tpr_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. False Positive Rate (FPR) <a class=\"anchor\" id=\"m-clasificacion-b-fpr\"></a>\n",
    "El **False Positive Rate** es el porcentaje de patrones de la clase negativa que son clasificados como positivos.<br>\n",
    "También se conoce por FPR por sus siglas en inglés.<br>\n",
    "\n",
    "$$\\text{FPR} = \\frac{\\text{FP}}{\\text{TN} + \\text{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular el False Positive Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive_rate(confusion):\n",
    "    # FP / (FP + TN)\n",
    "    return confusion[\"Positivo\"][\"Negativo\"] / \\\n",
    "           (confusion[\"Negativo\"][\"Negativo\"] + confusion[\"Positivo\"][\"Negativo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate (FPR) del modelo 1:  0.17391304347826086\n",
      "False Positive Rate (FPR) del modelo 2:  0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "fpr_m1 = false_positive_rate(matriz_m1)\n",
    "fpr_m2 = false_positive_rate(matriz_m2)\n",
    "print(\"False Positive Rate (FPR) del modelo 1: \", fpr_m1)\n",
    "print(\"False Positive Rate (FPR) del modelo 2: \", fpr_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Especificidad (TNR) <a class=\"anchor\" id=\"m-clasificacion-b-e\"></a>\n",
    "La **especificidad** es el porcentaje de patrones de la clase negativa que son correctamente clasificados.<br>\n",
    "También se conoce por TNR (Tasa Negativa Verdadera).<br>\n",
    "\n",
    "$$\\text{TNR} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular la especificidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def especificidad(confusion):\n",
    "    # TN / (TN + FP)\n",
    "    return confusion[\"Negativo\"][\"Negativo\"] / \\\n",
    "           (confusion[\"Negativo\"][\"Negativo\"] + confusion[\"Positivo\"][\"Negativo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Especificidad (TNR) del modelo 1:  0.8260869565217391\n",
      "Especificidad (TNR) del modelo 2:  0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "tnr_m1 = especificidad(matriz_m1)\n",
    "tnr_m2 = especificidad(matriz_m2)\n",
    "print(\"Especificidad (TNR) del modelo 1: \", tnr_m1)\n",
    "print(\"Especificidad (TNR) del modelo 2: \", tnr_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Precisión (PPV) <a class=\"anchor\" id=\"m-clasificacion-b-p\"></a>\n",
    "La **precisión** es el porcentaje de patrones clasificados como positivos que son de la clase positiva.<br>\n",
    "También se conoce por PPV (Positive Predictive Value).<br>\n",
    "\n",
    "$$\\text{PPV} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular la precisión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(confusion):\n",
    "    # TP / (TP + FP)\n",
    "    return confusion[\"Positivo\"][\"Positivo\"] / \\\n",
    "           (confusion[\"Positivo\"][\"Positivo\"] + confusion[\"Positivo\"][\"Negativo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (PPV) del modelo 1:  0.6\n",
      "Precision (PPV) del modelo 2:  0.9\n"
     ]
    }
   ],
   "source": [
    "ppv_m1 = precision(matriz_m1)\n",
    "ppv_m2 = precision(matriz_m2)\n",
    "print(\"Precision (PPV) del modelo 1: \", ppv_m1)\n",
    "print(\"Precision (PPV) del modelo 2: \", ppv_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. F1 Score <a class=\"anchor\" id=\"m-clasificacion-b-f1\"></a>\n",
    "El **F1 Score** es una medida que combina las métricas de Sensibilidad y Precisión. Es útil para comparar los distintos modelos. Al utilizar la media armónica, se penaliza los valores extremos, es decir, para una precisión de 1 y una sensibilidad de 0 está métrica nos diría que el clasificador es muy malo.<br>\n",
    "\n",
    "$$\\text{F1} = \\frac{2 \\cdot \\text{Sensibilidad} \\cdot \\text{Precisión}}{\\text{Sensibilidad} + \\text{Precisión}} = \\frac{\\text{2TP}}{\\text{2TP} + \\text{FP} + \\text{FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular el F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(confusion):\n",
    "    return 2 * (precision(confusion) * sensibilidad(confusion)) / \\\n",
    "           (precision(confusion) + sensibilidad(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score del modelo 1:  0.7058823529411764\n",
      "F1 Score del modelo 2:  0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "f1_score_m1 = f1_score(matriz_m1)\n",
    "f1_score_m2 = f1_score(matriz_m2)\n",
    "print(\"F1 Score del modelo 1: \", f1_score_m1)\n",
    "print(\"F1 Score del modelo 2: \", f1_score_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Kappa <a class=\"anchor\" id=\"m-clasificacion-b-k\"></a>\n",
    "La métrica mide el acuerdo o la relación entre los valores reales y los predichos. Se dice que es una medida más robusta que la precisión global. Puede tomar valores en el rango [-1,1], donde:\n",
    "* 1 es igual a acuerdo perfecto, es decir, clasificación perfecta.\n",
    "* 0 no existe relación.\n",
    "* -1 es a igual a un completo desacuerdo.\n",
    "\n",
    "Se calcula de la misma manera para problemas binarios y multiclase.\n",
    "\n",
    "$$\\text{Kappa} = \\frac{p_o - p_e}{1 - p_e}$$\n",
    "\n",
    "Siendo:\n",
    "\n",
    "$$p_o = \\text{CCR} = \\frac{1}{n}\\sum_{i=1}^{n}a_{ii}$$\n",
    "\n",
    "y:\n",
    "\n",
    "$$p_e = \\frac{1}{n^2}\\sum_{j=1}^{n}n_j n_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función para calcular el Kappa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(matriz):\n",
    "    confusion = matriz.copy()\n",
    "    p0 = precision_global(confusion)\n",
    "    confusion.loc[\"Total\"] = confusion.sum()\n",
    "    confusion[\"Total\"] = confusion.sum(axis=1)\n",
    "    total_col = confusion[\"Total\"]\n",
    "    total_row = confusion.loc[\"Total\"]\n",
    "    total = confusion.loc[\"Total\", \"Total\"]\n",
    "    # remove total from total_row and total_col\n",
    "    total_row = total_row.drop(\"Total\")\n",
    "    total_col = total_col.drop(\"Total\")\n",
    "    pe = 0\n",
    "    for c, f in zip(total_col.index, total_row.index):\n",
    "        pe += (total_col[c] * total_row[f])/(total*total)\n",
    "    k = (p0 - pe) / (1 - pe)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa del modelo 1:  0.5945945945945947\n",
      "Kappa del modelo 2:  0.42553191489361697\n"
     ]
    }
   ],
   "source": [
    "kappa_m1 = kappa(matriz_m1)\n",
    "kappa_m2 = kappa(matriz_m2)\n",
    "print(\"Kappa del modelo 1: \", kappa_m1)\n",
    "print(\"Kappa del modelo 2: \", kappa_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Comparación de modelos <a class=\"anchor\" id=\"m-clasificacion-b-cm\"></a>\n",
    "Finalmente, tras obtener las métricas para ambos modelos, podemos concluir que el modelo 1 mejor que el modelo 2 por las siguientes razones:\n",
    "- El CCR del modelo 1 es mayor que el del modelo 2\n",
    "- La Sensibilidad del modelo 1 permite determinar con mayor fiabilidad casos positivos como realmente positivos\n",
    "- El F1 Score es ligeramente mayor en el modelo 1 que en el modelo 2\n",
    "- El Kappa en ambos casos es moderado, no obstante el Kappa del modelo 1 es mayor que el del modelo 2\n",
    "- Pese a que la precisión y el ratio de falsos positivos del modelo 2 es mejor que en el modelo 1, el resto de métricas indican que el modelo 2 puede dar mejores resultados que el modelo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisión Global</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Modelo 1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelo 2</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.425532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precisión Global  Sensibilidad  False Positive Rate  Especificidad  \\\n",
       "Modelo 1          0.833333      0.857143             0.173913       0.826087   \n",
       "Modelo 2          0.700000      0.529412             0.076923       0.923077   \n",
       "\n",
       "          Precision  F1 Score     Kappa  \n",
       "Modelo 1        0.6  0.705882  0.594595  \n",
       "Modelo 2        0.9  0.666667  0.425532  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"Precisión Global\": ccr_m1, \"Sensibilidad\": tpr_m1, \n",
    "        \"False Positive Rate\": fpr_m1, \n",
    "        \"Especificidad\": tnr_m1, \"Precision\": ppv_m1, \n",
    "        \"F1 Score\": f1_score_m1, \"Kappa\": kappa_m1\n",
    "    },\n",
    "    {\n",
    "        \"Precisión Global\": ccr_m2, \"Sensibilidad\": tpr_m2, \n",
    "        \"False Positive Rate\": fpr_m2, \n",
    "        \"Especificidad\": tnr_m2, \"Precision\": ppv_m2, \n",
    "        \"F1 Score\": f1_score_m2, \"Kappa\": kappa_m2\n",
    "    }\n",
    "]\n",
    "\n",
    "df_metricas = pd.DataFrame(data, index=[\"Modelo 1\", \"Modelo 2\"])\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Métricas de clasificación multiclase <a class=\"anchor\" id=\"m-clasificacion-m\"></a>\n",
    "Dada la siguiente matriz de confusión para un problema multiclase, se pide hallar todas las métricas de clasificación para cada clase, excepto el AUC. Recuerde que, para calcular las métricas de una clase, se considera dicha clase como positiva y el resto como la negativa.\n",
    "\n",
    "Utilizaremos el siguiente set de datos de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gato</th>\n",
       "      <th>Perro</th>\n",
       "      <th>Loro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gato</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perro</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loro</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gato  Perro  Loro\n",
       "Gato     20     10     5\n",
       "Perro     5     30     0\n",
       "Loro      5      5    25"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [20, 10, 5], [5, 30, 0], [5, 5, 25]\n",
    "]\n",
    "df_clasificacion_multiple = pd.DataFrame(data, index=[\"Gato\", \"Perro\", \"Loro\"], columns=[\"Gato\", \"Perro\", \"Loro\"])\n",
    "df_clasificacion_multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Matriz de confusión para cada clase <a class=\"anchor\" id=\"m-clasificacion-m-mc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crearemos una función que permita crear la matriz de confusión para cada clase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_sub_matriz(matriz, clase):\n",
    "    matriz = matriz.copy()\n",
    "    matriz[\"Negativo\"] = matriz.sum(axis=1) - matriz[clase]\n",
    "    matriz[\"Positivo\"] = matriz[clase]\n",
    "    matriz = matriz[[\"Positivo\", \"Negativo\"]]\n",
    "    # La fila Positivo es la clase que se está evaluando\n",
    "    matriz = matriz.rename(index={clase: \"Positivo\"})\n",
    "    # Agrupar las filas de las clases que no son la clase que se está evaluando en una fila llamada Negativo\n",
    "    matriz.loc[\"Negativo\"] = matriz.sum(axis=0) - matriz.loc[\"Positivo\"]\n",
    "    # Eliminar las filas que no son Positivo ni Negativo\n",
    "    matriz = matriz.drop(matriz.index.difference([\"Positivo\", \"Negativo\"]))\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La matriz de confusión para la clase Gato es:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positivo</th>\n",
       "      <th>Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positivo  Negativo\n",
       "Positivo        20        15\n",
       "Negativo        10        60"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_gato = crear_sub_matriz(df_clasificacion_multiple, \"Gato\")\n",
    "matriz_gato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La matriz de confusión para la clase Perro es:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positivo</th>\n",
       "      <th>Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positivo  Negativo\n",
       "Positivo        30         5\n",
       "Negativo        15        55"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_perro = crear_sub_matriz(df_clasificacion_multiple, \"Perro\")\n",
    "matriz_perro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La matriz de confusión para la clase Loro es:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positivo</th>\n",
       "      <th>Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positivo  Negativo\n",
       "Positivo        25        10\n",
       "Negativo         5        65"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_loro = crear_sub_matriz(df_clasificacion_multiple, \"Loro\")\n",
    "matriz_loro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobamos que la suma de los elementos de cada matriz de confusión es igual a la suma de todos los elementos de la matriz de confusión original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma original:  105\n",
      "Suma gato:  105\n",
      "Suma perro:  105\n",
      "Suma loro:  105\n"
     ]
    }
   ],
   "source": [
    "suma_original = df_clasificacion_multiple.sum().sum()\n",
    "suma_gato = matriz_gato.sum().sum()\n",
    "suma_perro = matriz_perro.sum().sum()\n",
    "suma_loro = matriz_loro.sum().sum()\n",
    "print(\"Suma original: \", suma_original)\n",
    "print(\"Suma gato: \", suma_gato)\n",
    "print(\"Suma perro: \", suma_perro)\n",
    "print(\"Suma loro: \", suma_loro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Precisión global (CCR) <a class=\"anchor\" id=\"m-clasificacion-m-pg\"></a>\n",
    "Reutilizaremos la función que calcula la [precisión global](#m-clasificacion-b-pg) ya que puede ser utilizada en problemas de clasificación binario o multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCR multiclase:  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "ccr_multiclase = precision_global(df_clasificacion_multiple)\n",
    "print(\"CCR multiclase: \", ccr_multiclase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Sensibilidad (TPR)<a class=\"anchor\" id=\"m-clasificacion-m-s\"></a>\n",
    "Reutilizaremos la función que calcula la [sensibilidad](#m-clasificacion-b-s) para problemas binarios y la aplicaremos para cada matriz de confusión generada para tratar problemas multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad matriz gato:  0.5714285714285714\n",
      "Sensibilidad matriz perro:  0.8571428571428571\n",
      "Sensibilidad matriz loro:  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "tpr_gato = sensibilidad(matriz_gato)\n",
    "tpr_perro = sensibilidad(matriz_perro)\n",
    "tpr_loro = sensibilidad(matriz_loro)\n",
    "print(\"Sensibilidad matriz gato: \", tpr_gato)\n",
    "print(\"Sensibilidad matriz perro: \", tpr_perro)\n",
    "print(\"Sensibilidad matriz loro: \", tpr_loro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. False Positive Rate (FPR)<a class=\"anchor\" id=\"m-clasificacion-m-fpr\"></a>\n",
    "Reutilizaremos la función que calcula el [False Positive Rate](#m-clasificacion-b-fpr) para problemas binarios y la aplicaremos para cada matriz de confusión generada para tratar problemas multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate matriz gato:  0.14285714285714285\n",
      "False Positive Rate matriz perro:  0.21428571428571427\n",
      "False Positive Rate matriz loro:  0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "fpr_gato = false_positive_rate(matriz_gato)\n",
    "fpr_perro = false_positive_rate(matriz_perro)\n",
    "fpr_loro = false_positive_rate(matriz_loro)\n",
    "print(\"False Positive Rate matriz gato: \", fpr_gato)\n",
    "print(\"False Positive Rate matriz perro: \", fpr_perro)\n",
    "print(\"False Positive Rate matriz loro: \", fpr_loro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Especificidad (TNR) <a class=\"anchor\" id=\"m-clasificacion-m-e\"></a>\n",
    "Reutilizaremos la función que calcula la [especificidad](#m-clasificacion-b-e) para problemas binarios y la aplicaremos para cada matriz de confusión generada para tratar problemas multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Especificidad matriz gato:  0.8571428571428571\n",
      "Especificidad matriz perro:  0.7857142857142857\n",
      "Especificidad matriz loro:  0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "tnr_gato = especificidad(matriz_gato)\n",
    "tnr_perro = especificidad(matriz_perro)\n",
    "tnr_loro = especificidad(matriz_loro)\n",
    "print(\"Especificidad matriz gato: \", tnr_gato)\n",
    "print(\"Especificidad matriz perro: \", tnr_perro)\n",
    "print(\"Especificidad matriz loro: \", tnr_loro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Precisión (PPV) <a class=\"anchor\" id=\"m-clasificacion-m-p\"></a>\n",
    "Reutilizaremos la función que calcula la [precisión](#m-clasificacion-b-p) para problemas binarios y la aplicaremos para cada matriz de confusión generada para tratar problemas multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision matriz gato:  0.6666666666666666\n",
      "Precision matriz perro:  0.6666666666666666\n",
      "Precision matriz loro:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "ppv_gato = precision(matriz_gato)\n",
    "ppv_perro = precision(matriz_perro)\n",
    "ppv_loro = precision(matriz_loro)\n",
    "print(\"Precision matriz gato: \", ppv_gato)\n",
    "print(\"Precision matriz perro: \", ppv_perro)\n",
    "print(\"Precision matriz loro: \", ppv_loro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. F1 Score <a class=\"anchor\" id=\"m-clasificacion-m-f1\"></a>\n",
    "Reutilizaremos la función que calcula el [F1 Score](#m-clasificacion-b-f1) para problemas binarios y la aplicaremos para cada matriz de confusión generada para tratar problemas multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score matriz gato:  0.6153846153846153\n",
      "F1 Score matriz perro:  0.75\n",
      "F1 Score matriz loro:  0.7692307692307692\n"
     ]
    }
   ],
   "source": [
    "f1_score_gato = f1_score(matriz_gato)\n",
    "f1_score_perro = f1_score(matriz_perro)\n",
    "f1_score_loro = f1_score(matriz_loro)\n",
    "print(\"F1 Score matriz gato: \", f1_score_gato)\n",
    "print(\"F1 Score matriz perro: \", f1_score_perro)\n",
    "print(\"F1 Score matriz loro: \", f1_score_loro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8. Kappa <a class=\"anchor\" id=\"m-clasificacion-m-k\"></a>\n",
    "Reutilizaremos la función que calcula el [Kappa](#m-clasificacion-b-k) ya que puede ser utilizada en problemas de clasificación binario o multi-clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa multiclase:  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "kappa_multiclase = kappa(df_clasificacion_multiple)\n",
    "print(\"Kappa multiclase: \", kappa_multiclase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9. Valoración del modelo <a class=\"anchor\" id=\"m-clasificacion-m-vm\"></a>\n",
    "Para valorar el modelo empleado en un problema de clasificación multi-clase, se debe calcular la media de cada métrica, exceptuando el CCR y el Kappa. La formula sería la siguiente.\n",
    "\n",
    "$$\\text{Modelo} = \\text{CCR}, \\bar{\\text{TPR}}, \\bar{\\text{FPR}}, \\bar{\\text{TNR}}, \\bar{\\text{PPV}}, \\bar{\\text{F1}}, \\text{Kappa}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1f14a_row3_col0, #T_1f14a_row3_col1, #T_1f14a_row3_col2, #T_1f14a_row3_col3, #T_1f14a_row3_col4, #T_1f14a_row3_col5, #T_1f14a_row3_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1f14a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1f14a_level0_col0\" class=\"col_heading level0 col0\" >Preción Global</th>\n",
       "      <th id=\"T_1f14a_level0_col1\" class=\"col_heading level0 col1\" >Sensibilidad</th>\n",
       "      <th id=\"T_1f14a_level0_col2\" class=\"col_heading level0 col2\" >False Positive Rate</th>\n",
       "      <th id=\"T_1f14a_level0_col3\" class=\"col_heading level0 col3\" >Especificidad</th>\n",
       "      <th id=\"T_1f14a_level0_col4\" class=\"col_heading level0 col4\" >Precision</th>\n",
       "      <th id=\"T_1f14a_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_1f14a_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1f14a_level0_row0\" class=\"row_heading level0 row0\" >Matriz Gato</th>\n",
       "      <td id=\"T_1f14a_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_1f14a_row0_col1\" class=\"data row0 col1\" >0.571429</td>\n",
       "      <td id=\"T_1f14a_row0_col2\" class=\"data row0 col2\" >0.142857</td>\n",
       "      <td id=\"T_1f14a_row0_col3\" class=\"data row0 col3\" >0.857143</td>\n",
       "      <td id=\"T_1f14a_row0_col4\" class=\"data row0 col4\" >0.666667</td>\n",
       "      <td id=\"T_1f14a_row0_col5\" class=\"data row0 col5\" >0.615385</td>\n",
       "      <td id=\"T_1f14a_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f14a_level0_row1\" class=\"row_heading level0 row1\" >Matriz Perro</th>\n",
       "      <td id=\"T_1f14a_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_1f14a_row1_col1\" class=\"data row1 col1\" >0.857143</td>\n",
       "      <td id=\"T_1f14a_row1_col2\" class=\"data row1 col2\" >0.214286</td>\n",
       "      <td id=\"T_1f14a_row1_col3\" class=\"data row1 col3\" >0.785714</td>\n",
       "      <td id=\"T_1f14a_row1_col4\" class=\"data row1 col4\" >0.666667</td>\n",
       "      <td id=\"T_1f14a_row1_col5\" class=\"data row1 col5\" >0.750000</td>\n",
       "      <td id=\"T_1f14a_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f14a_level0_row2\" class=\"row_heading level0 row2\" >Matriz Loro</th>\n",
       "      <td id=\"T_1f14a_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_1f14a_row2_col1\" class=\"data row2 col1\" >0.714286</td>\n",
       "      <td id=\"T_1f14a_row2_col2\" class=\"data row2 col2\" >0.071429</td>\n",
       "      <td id=\"T_1f14a_row2_col3\" class=\"data row2 col3\" >0.928571</td>\n",
       "      <td id=\"T_1f14a_row2_col4\" class=\"data row2 col4\" >0.833333</td>\n",
       "      <td id=\"T_1f14a_row2_col5\" class=\"data row2 col5\" >0.769231</td>\n",
       "      <td id=\"T_1f14a_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f14a_level0_row3\" class=\"row_heading level0 row3\" >Modelo</th>\n",
       "      <td id=\"T_1f14a_row3_col0\" class=\"data row3 col0\" >0.714286</td>\n",
       "      <td id=\"T_1f14a_row3_col1\" class=\"data row3 col1\" >0.714286</td>\n",
       "      <td id=\"T_1f14a_row3_col2\" class=\"data row3 col2\" >0.142857</td>\n",
       "      <td id=\"T_1f14a_row3_col3\" class=\"data row3 col3\" >0.857143</td>\n",
       "      <td id=\"T_1f14a_row3_col4\" class=\"data row3 col4\" >0.722222</td>\n",
       "      <td id=\"T_1f14a_row3_col5\" class=\"data row3 col5\" >0.711538</td>\n",
       "      <td id=\"T_1f14a_row3_col6\" class=\"data row3 col6\" >0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bbf42c2a60>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_tpr = (tpr_gato + tpr_perro + tpr_loro) / 3\n",
    "media_fpr = (fpr_gato + fpr_perro + fpr_loro) / 3\n",
    "media_tnr = (tnr_gato + tnr_perro + tnr_loro) / 3\n",
    "media_ppv = (ppv_gato + ppv_perro + ppv_loro) / 3\n",
    "media_f1_score = (f1_score_gato + f1_score_perro + f1_score_loro) / 3\n",
    "data = [\n",
    "    {\n",
    "        \"Preción Global\": None, \"Sensibilidad\": tpr_gato, \n",
    "        \"False Positive Rate\": fpr_gato, \n",
    "        \"Especificidad\": tnr_gato, \"Precision\": ppv_gato, \n",
    "        \"F1 Score\": f1_score_gato, \"Kappa\": None\n",
    "    },\n",
    "    {\n",
    "        \"Preción Global\": None, \"Sensibilidad\": tpr_perro, \n",
    "        \"False Positive Rate\": fpr_perro, \n",
    "        \"Especificidad\": tnr_perro, \"Precision\": ppv_perro, \n",
    "        \"F1 Score\": f1_score_perro, \"Kappa\": None\n",
    "    },\n",
    "    {\n",
    "        \"Preción Global\": None, \"Sensibilidad\": tpr_loro, \n",
    "        \"False Positive Rate\": fpr_loro, \n",
    "        \"Especificidad\": tnr_loro, \"Precision\": ppv_loro, \n",
    "        \"F1 Score\": f1_score_loro, \"Kappa\": None\n",
    "    },\n",
    "    {\n",
    "        \"Preción Global\": ccr_multiclase, \"Sensibilidad\": media_tpr, \n",
    "        \"False Positive Rate\": media_fpr, \n",
    "        \"Especificidad\": media_tnr, \"Precision\": media_ppv, \n",
    "        \"F1 Score\": media_f1_score, \"Kappa\": kappa_multiclase\n",
    "    }\n",
    "]\n",
    "df_metricas_multiclase = pd.DataFrame(data, index=[\"Matriz Gato\", \"Matriz Perro\", \"Matriz Loro\", \"Modelo\"])\n",
    "df_clasificacion_multiple = df_metricas_multiclase.style.apply(lambda x: [\"background: yellow\" if x.name == \"Modelo\" else \"\" for i in x], axis=1)\n",
    "df_clasificacion_multiple"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "99fa938bcf4b34b1206b0f41b70a2b220efb480c4d7300e3999b5d2201d31215"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
